subreddit;id;created_utc;permalink;title;selftext;comments
badlinguistics;5hys2e;1481572275.0;/r/badlinguistics/comments/5hys2e/a_finnish_politician_wants_to_reform_finnish/;A Finnish politician wants to reform Finnish grammar in order to make it easier for computers to understand;[deleted];"[deleted]#>The great majority of human thought happens outside of FinlandCitation needed. #The real badlinguistics was blocking many linguists who were pointing out his mistakes. And many people who dared to ""like"" their comments. And then acting smug about it.The real badhistory, on the other hand, was saying ""this is what they said to Galileo when he claimed the Earth was round"".#[deleted]#I know it's pedantic but... > Suomenkieli on minulle rakas. 'Finnishlanguage is dear to me.'Is it? Is it really Mikael?#Junger saga continues [here](https://scontent-frt3-1.xx.fbcdn.net/v/t1.0-9/15355678_10154639243620482_7043793509279750455_n.jpg?oh=4f1972cd2ff6d60b7c4b80db3b3bff7f&oe=58B0E34D)Translation:Well look at that. According to wikipedia language complexity is something that is not very well researched, because it is politically incorrect. Thats why many researchers are afraid to study it.Tell me about it. I think I just found a modern taboo.Facebook <3#in other words ""a politician doesn't understand linguistics nor nlp""#mötkö vai lötkö?#The problem with translating Finnish comes from words with multiple meanings, like kuusi (idk how to spell it) which, if I remember what my Finnish friend said correctly, means ""your moon"", ""six"", and ""pine tree"".#With regards to making the computer understand the language better... there _is_ a thing called [lojban](https://mw.lojban.org/papri/Lojban). :P#At least the last point is not badling, but some bold policy (the first part   the second is simply good policy) Well, the rest: meh, but what would you expect, if something made it to this sub? #My desired career path is actually computer linguistics and it is true that Finnish is by far the most difficult language to translate for computers, among the languages that have been included in most translation softwares at least. The reasons for this are fairly obvious if you consider Finnish morphology etc.Still, you cannot simply change a language to make it easier for computers. Yes you could probably think of changes that would have that desired effect but language is nothing without its speakers and you cannot force them to speak differently.#Technically you could say the same about any country, or even continent.#Are you saying that Galileo *wasn't* blocked on facebook for saying the earth is round? Do you have a citation for that?#also why would *that* make it easier to understand for computers? will it make sarcasm easier to detect? come now...#Suomi kieli olla minä rakas. See? Perfectly understandable!#Mlötkö.#Homonyms can be irksome to deal with, but I really doubt that they are *that* problematic in this case  I have a Greek friend who is convinced that Greek is the most complicated language in the world because everything is so context dependent...To be blunt, don't trust people about languages just on the grounds that they speak that language when it comes to technical things.#There are sister languages to finnish, like estonian, that would help to decipher such situations.  su kuu,  kuus,  kuusk (a spruce).    I (and not just me) suspect that finnish and estonian languages are much easier than indo-european languages and that gives them (us) an advantage (a quick start) at education which shows up in PISA (and other similar) test results. PISA results are dominated by the chinese languages, korean, japanese, finno-ugric and indo-european. Of these, finno-ugric is spoken by the smallest population. Of the circum-baltic-sea countries (Nordics + Baltics) of comparable size, the two finnic languages consistently produce the best PISA results while the indo-european ones consistently underperform. Which suggests that this linguistic advantage might eventually be captured by machine intelligence as well.     Sure, language simplification (within one language and between sister languages) should be an avenue to be explored. But it should not be done before one is able to understand all the ins and outs.#R6: no requirement for R4 if the thread makes it to this sub because at that point it will be, by definition, badling.#what in particular makes Finnish morphology more difficult than other languages?#It's true for any highly agglutinative language. Try Hungarian or Turkish. And it has to do with the fact that current research is focused around inflecting languages with an almost  isolating language at its pivot. Were the world's prime lingua franca highly agglutinating and the most widely mother tongue as well, I guarantee you, what would be described as ""hardest language to do machine translation on"" would probably be inflecting ones... #Why?Isn't it easier to create a parse tree when you can reliably pull info out of morphemes that you'd otherwise have to analyze sentence structure for?#The majority of human thought happens outside Pangaea.#The majority of human thought occurs in Asia.#Well, in this comparison Mikael Jungner is saying he's Galileo, so it should be Galileo blocking the church on Facebook.#[deleted]#Finland language to be I dear.#tulukaa kahtoo.#Yeah I guess so, but there are languages, like my own, where tonality has kind of just *appeared* as a really important component of speech, and shows a lot of things, but not actually being denoted in the language. Both tone and stress change the meaning of EVERYTHING#I, having learned a little bit of Hungarian, and actively learning it, see that. A Hungarian sentence can contain an immense amount of information in very few words. For example, the way I've understood it, the sentence ""A fiú vár"" means ""The boy is waiting"", while the sentence ""A fiút vár"" means either ""Wait for the boy"" or ""Someone is waiting for the boy"", however, my grammar is terrible, so to any real Hungarians, help would be much appreciated :)#I cannot give a very informed answer, but as others have said, it's most likely because the ""major"" languages are usually inflecting languages and that's where the money is. It may really be just a question of amount of work put into it and how similar it is to the other languages. In regards to influence of money in the field it's notable that while Chinese and Japanese are also very dissimilar from the major European languages, machine translation between them is pretty good. #> And it has to do with the fact that current research is focused around inflecting languages with an almost isolating language at its pivot.What do you mean exactly, especially with ""at its pivot"". Do you mean that people tend to sort of focalise other languages with English in mind?But it does make sense that the agglutinative languages' reputation is because we're in a mostly eurocentric world and the majority of European languages are inflecting and only have, like, 2 words for snow. Namely Snow and Jon Snow. And, you know, all the eskimos have at least 273 words for snow, except for Turkish, they never have snow there so they can't express that concept.(My comment started out as a serious one but I got carried away, sorry. Your point does make sense, the subreddit magic just made me go bonkers for a second.)#While the regular agglutinative nature makes morphological partsing easy, that does not bode well with today's mostly purely statistical approach without much preprocessing. #Computers are fine with knife/knives, things like katu/kadut shouldn't be a problem.#so the idea is that it's just an outlier, not so much that it's inherently more difficult?#> In regards to influence of money in the field it's notable that while Chinese and Japanese are also very dissimilar from the major European languages, machine translation between them is pretty good.Machine translation of Japanese (to/from English) is not anything I would call approaching ""pretty good"". In fact it wasn't any good in most cases except for the simplest of sentences until a few weeks ago when Google did their ""deep learning"" in Google Translate. Now, with some knowledge of the language it has started to become usable. This also only counts for Japanese -> English, the other way is still pretty shitty for anything that's not simple. #Well, if you're going from, say, Finnish to Turkish in Google Translate, it passes through English behind the scenes, because they don't have a model for direct translation between the two languages.  You can imagine the mess it makes.#I assume that he was referring to the notion that the vast majority of translation work out there is centered around English - either to or from another language, or using it as a ""bridge"" language, just because of the sheer number of speakers and its influence around the (Western) world.#There's a new system underway called neuronal translation and it seems that it will bring a lot of innovation in that field (no definite results yet because it was launched only last year). Finnish, however, is still behind every other major language.#What I tried to say is that there hasn't been done enough work in order to get the software for Finnish programmed, simply because there aren't as many people and/or not as much funding for Finnish.However, I am *far* from being an expert, so take my answer with a grain of salt. I'm really just speculating here.#I thought the new neural network translater has its own internal ""language"". But it's only available for a couple of languages as of now.#Oh my, yeah I can imagine.#whether or not you're an expert, you clearly know at least a little more about this than me, so thanks for your input.#It's quite possible my information's out of date, or will be soon, yes.#There was a push a while ago to use Esperanto as the bridge language. Dunno how that actually panned out.#It has an internal numerical representation of content from which it translates to and from any language. Presumably that representation looks some natural language in some ways, and it would actually be quite interesting to try and study it, though I don't think Google cares and the academic research labs that do don't have the time, money and processing power for that.Anyway, that representation has been computed by some optimization algorithm so presumably it represents the languages it has been exposed to the most more accurately than those it hasn't seen much.#I read somewhere that Google has started using a machine learning environment for translation that constructs some kind of meta language now.It would be pretty ironic if hold-out Chomskian UG programmers actually save us from a Skynet-style extinction event by demanding such languages still adhere to regular government and binding trees.#Do you have a source ? That doesn't really make sense. Machine translation is done by looking at lots of translations and doing statistical analysis of it, so (a) Esperanto wouldn't be possible to handle as we have too little data (see how badly GT handles Latin) and (b) this is a very unreliable process and adding an intermediate step could only make the result worse by compounding errors. Only exception is if we have way way more data for the A <-> B and B <-> C steps than for A <-> C, but obviously this is never the case when B is Esperanto.In other words the reason GT may use English internally for some language pairs isn't ideological or that they've been too lazy to do it directly, it's just that no other option works better.As for the bridge language in Google's neural net translation, it's a numerical representation, not a symbolic one (so in particular, not English). This is an inherent feature of neural networks.#I don't know how to explain it, but Google is using Deep Learning, which is a sort of Neural Network."
IAmA;5h0687;1481121100.0;/r/IAmA/comments/5h0687/iama_data_science_professor_at_the_university_of/;IamA Data Science Professor at the University of Michigan, let’s discuss ethics surrounding privacy, data sharing and algorithmic decision-making. AMA!;**My short bio:** I am a Bernard A Galler Collegiate Professor of Electrical Engineering and Computer Science at the University of Michigan. My research spans many aspects of Big Data and Data Science and I have contributed to [Slate Magazine](http://www.slate.com/articles/technology/future_tense/2015/11/using_data_science_for_predictive_policing_has_serious_civil_liberties_drawbacks.html), [U.S. News and World Report](http://www.usnews.com/news/articles/2016-02-24/passwords-privacy-and-protection-can-apple-meet-fbis-demand-without-creating-a-backdoor), [the Conversation U.S.](https://theconversation.com/big-data-analyses-depend-on-starting-with-clean-data-points-43687) I author my own blog, [Big Data Dialog](http://www.bigdatadialog.com/), where I discuss key issues surrounding ethics in data science. My Massive Open Online Course (MOOC) [Data Science Ethics](https://www.edx.org/course/data-science-ethics-michiganx-ds101x-1?utm_campaign=michiganx&utm_medium=partner-marketing&utm_source=social&utm_content=reddit-ama-dec-16) will re-launch on edX in January.**My Course:** [https://www.edx.org/course/data-science-ethics-michiganx-ds101x-1](https://www.edx.org/course/data-science-ethics-michiganx-ds101x-1?utm_campaign=michiganx&utm_medium=partner-marketing&utm_source=social&utm_content=reddit-ama-dec-16)**My Proof:** [http://imgur.com/a/UPHhY](http://imgur.com/a/UPHhY) and [bigdatadialog.com](http://www.bigdatadialog.com);"What would you like to see from Academia In Computer Science programs in relation to ethics *and* security issues going forward? My experience at MIT was that it was largely the veterans (older professors) who had any sort of consideration for the larger societal issues and repercussions of 'big data'. Yes, we did have RMS in the building, so had an active voice advising the larger MIT community :) That said, the younger and/or students didn't seem to care as much - they just wanted data, data and more data, damn the repercussions. I worry that as our veterans retire, the absence of their voice will affect big data's future.As an aside, a great quote shared with me once was that ""Data is Risk and the more data you collect, the more Risk you expose yourself too"". In that vein, I hope that someday, our corporations may decide that our personal data costs more to protect than it provides in profit. Unfortunately, I also think that personal data is the new currency and big data collections can only get worse. Thoughts?#What problems/solutions do you see with current releases of anonymized big data sets that might end up not being so anonymous in the future? I'm thinking specifically of the Massachusetts health dataset that was released in anonymized but was later found to be quite identifiable.Thanks for the AMA!#I'm a student at MSU. Care to make fun of our football team?#JT Barrett. 4th and 1. He totally didn't make it, right?#What should I, as a private citizen, know about how my data is being used that I don't?#What data would you want/need from Jim Harbaugh's time at Stanford, The 49ers and Michigan to prove Jed York totally screwed up?   #Thank you for submitting your questions. This ends the live portion of the IAmA, but I will continue to reply to your questions as best I can as they come through.Please keep in mind the Data Scientist's code of ethics:Do not surprise  ANDOwn the outcomes#Users, please be wary of proof. You are welcome to ask for more proof if you find it insufficient. OP, if you need any help, please message the mods [here](http://www.reddit.com/message/compose?to=%2Fr%2Fiama&subject=&message=).Thank you!*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/IAmA) if you have any questions or concerns.*#Hi Jag! I'm a student in your EECS 485 class at U of M and have loved the experience. Definitely one of the best courses I've taken at this school!My question for you: what do you think is the largest problem regarding the anonymization of data on the public dataset releases? Do you think the privacy of those in the data is worth the knock on the information we can retrieve from the datasets? Have you seen an instance where the anonymization of such data has influenced research negatively? Thanks, see you in class!! #Hi Professor, thank you for the AMA! What would you say are some of the dangers of predictive analytics? How does the study of data ethics address some of those dangers and, also, who is responsible for conclusions made by a machine?#Do you see any future for pier to pier VPN encryption for retail sales, voting purposes or any other privacy sensitive transactions?#Good morning professor. Quick background, I am a system engineer for a health care system. My primary job revolves around a proprietary SQL called CCL. My degree is in information systems security and while I was in school one question was always posed. Who owns the data? With data being stored and moved around so much, particularly in the medical field, who is ethically bound to that data? I hope that makes sense. #If you went corporate, which Big Data company would you most want to work for?#Hello professor. For those of us unaware of exactly how machine learning works, could you help (briefly) clarify exactly what people mean when they talk about the ""black box"" and why it is leading to unethical problems?    Thanks!#Hello Professor, greetings from Chile.I currently work as software engeineer for bank systems.What resources would you recommend to really undesrtand the concepts behind Big Data, beyond the tools?#[deleted]#Does any of your research focus on security? For starters is there a practical list of malware and a practical set of algorithms to reverse [Veil](https://www.veil-framework.com/)? Are there any technologies worth re-engineering for sheer complexity of security countermeasures?#is their a future in cyber security/computer science? Potentially will do a degree in it over maths.#[deleted]#Which field would you say ""Big Data"" utilization is most underutilized? #[deleted]#What is your view on religion within the science community? It intrigued me, how more and more people learn about something, they tend to hit a dead end, where we either don't have the technology, or method to advance any further.  Also, favorite weather?#Hi, thanks for doing this AMA.In your opinion, who is more intrusive, corporations or the government?How much can corporations actually see of your information, and how much do they see? (e.g. Photos, surreptitiously taken a/v recordings, emails, texts, history, online habits, posting actions on websites such as reddit, etc.)What do you believe the main purpose of mass surveillance from the US government is? Intimidation? Protection? Power/blackmail?#[deleted]#What does the future look like for an american citizen in terms of data collection and surveillance? Will privacy be allowed to exist?#Dear Professor, is there any industrial application/adaption based on differential privacy?  If yes, could you please give a brevity of the adaption(s)?#What is your opinion of Business anaytics and info systems or MIS degrees. Think they are enough to break into a data science field? Also what is your opinion on R?#What's your favorite soup?#I suppose what we worry about does change with age and experience.  Rest assured, the younger faculty today will grow old too, one day!!I actually see more and more people worrying about the societal implications of data science and AI.  Some of these are very young.  For example, [Solon Barocas](http://solon.barocas.org/) or [danah boyd](http://www.danah.org/).  So I am optimistic.To your final point, I agree that data collections have tremendous value, but also introduce risk.  Many organizations today see the potential value, but do not pay enough attention to possible risks.  I hope this will change, and we will get a better balance.#Unfortunately, as technology evolves it is harder and harder to be anonymous.  The more I know about you, even innocuous things like the turns of phrase you favor, the more likely it is that I will be able to identify you.What can we do about this?  For some purposes, individual level data do not need to be revealed -- aggregate patterns are enough.  For such purposes, differential privacy may be a way forward.For other purposes, we may want to have rules/conventions about not trying to defeat anonymity.#Sports has been a fascinating arena for Data Science, as so well portrayed in the movie Moneyball.  With a little bit of research I am sure we could dig up some interesting things to say about the UM-MSU rivalry.#Go Blue!!#Between surveillance cameras, location tracking, and web monitoring, there is little that you do that isn't being recorded.  Today, most of this recording is fragmented, there is only limited sharing, and companies are just beginning to exploit the data they have access to.  For the most part, this should only result in your getting better targeted advertising.  (After all, technologies will be developed because they can make money).  But there can be uses that hurt you, and we have to create social barriers for such use.#Through data analysis, we could show things like performance comparisons with peers, and appropriately determine adjustments for various confounding factors.  But you would then have to translate an objective quantitative performance analysis into subjective statements like ""totally screwed up"".  This is even more difficult for your question because you want to relate Harbaugh's performance with York's personnel management, which introduces a level of indirection. #There is definitely a great deal we can learn from data analysis.  For example, consider medical advances that we can make by looking at medical history data.  My view is that anonymizing medical history perfectly is essentially impossible: you can never get it to the point where you could post anonymized medical records for all to analyze.  However, you could do an imperfect anonymization and hand the data off to selected researchers, trusting them not to deanonymize.This is like putting a tiny lock on your bag: any one with a bolt cutter could cut it open, but the lock helps avoid temptation.#teachers pet!#Predictions depend on the model, which reflects the worldview of the model-builder.  Predictions depend on the training data, which may not be appropriately representative.  Predictions depend on the input variables, which could have errors.  Whoever is responsible for predictions (the human) has to take responsibility.  We cannot simply say the machine did it.#It would be interesting to hear your thoughts on a process or method which would be able to simultaneously verify and protect someones identity in order to fulfill the function needed. Voting and retail, as mentioned above are two very good examples of an application for this kind of thing.#Normally, in the US, the collector/organizer of the data owns the data.  However, the subject of the data may have many rights to it.  Particularly for medical data, patient rights to data have been extensively specified by regulation.  As a matter of ethics, though, the answer to your question has to be thought through independent of laws.  If I let you collect data about me, I do so with certain expectations of your using that data for my benefit and not for my harm.  Meeting these expectations is your ethical obligation.#I personally think most companies try to make money by providing value to their customers.  I think this is true of most ""Big Data companies"" as well.  However, ethical issues with Big Data are not clearly understood, and it is all too easy in a fast-moving world to not have thought through (or to have misjudged) the consequences of some action.  I would be happy to work with companies to help them think through these issues better.#By ""black box"" we simply mean that we cannot see inside the box and understand how it works.  Often, this is because the code is proprietary.  This is a problem because we are left with a ""trust me"" situation.  We have to ask what the algorithm can show us to win our trust, without disclosing every detail of its operation.  For example, can it give us some guarantees?A simple, but visible, example of this is the recount under way in Michigan.  Voters mark paper ballots, but then they are counted by a ""black box"" machine.  If someone tampered with the code in the black box, the announced results could be wrong.  The recount is a way to build trust in the system -- votes are hand counted and we can thereby confirm that the counting machines did indeed count correctly. #Congratulations to you for asking the most important question!!Far too many I see are keen to learn the tools and then go off in a rush without thinking about the bigger picture.There is a great deal of good thinking about Big Data, and its impact on society.  A good high-level overview is in [this Forbes article](http://www.forbes.com/sites/elyrazin/2015/12/03/big-buzz-about-big-data-5-ways-big-data-is-changing-finance).  A marketing-oriented [white paper by IBM](http://www-935.ibm.com/services/us/gbs/thoughtleadership/big-data-banking/) is also informative.#I am really fascinated by smart ways that people try to help the less fortunate through data science.  For example, night time images showing light intensity are a major indicator of economic growth -- poor people cannot afford to have lights on at night.  But the relationship is not linear, so you cannot just translate from light intensity to GDP.  Building good models is the subject of cool research.#No, I am not a security researcher.  But I do believe that we have to take into account the risk of systems being hacked in addition to the risk of someone misusing the data.#I think computer science is a major growth area.  You cannot go wrong with almost any aspect of computing.  For obvious reasons, security is a huge area, with great and growing interest.Go for it, and best of luck.#Bootcamps can be great.  Definitely one way to deepen your skills in data science.  Most boot camps will give you the tools to do stuff, but you will need earl courses and degree programs to understand the how and why in depth.#I am most excited by the possibilities in social science, because the traditional modes of thinking are just so different, and we have a long way to go to understand exactly where Big Data can help and where it is just a poor substitute for the deeper understanding through traditional means.#I do not know all the details, but I think this is the next technology step where we share certain information with the vendor in return for convenience.  Nothing unethical here, unless Amazon does something bad with the recorded data.#Religion can be very helpful in many respects.  However, we have to recognize that different people have different religious beliefs.  Different religions can disagree on specific issues, even if most religions reinforce similar moral values.  So we need to define common ethical principles that we can all subscribe to, independent of religion.Regarding weather, I am not too fussy as long as it is 75 degrees and 50% humidity with a gentle breeze.  #Governments are likely to have much more power, and much more completeness in collection.  They also have more power to coerce.  But I really don't believe that the government sets out with an intention of doing harm: government officials are mostly sensible people with the same hopes and desires as everyone else.  It is just that once there is the power, the temptations for misuse are far too great, so it may be better to decide as a society where we want the lines drawn ahead of time.  I also worry about data breaches even when government intentions are good.Corporate intentions are more varied, but their data is often a patchwork of varying quality and coverage.#There are so many ways in which data science is making companies more profitable that right now you could do almost any aspect of it and do well financially.#I think that depends on us as citizens.  We know that technology can be used in ways that gets rid of privacy.  But it doesn't have to.  And that is where our force as citizens comes in.#Check out this VLDB [tutorial](http://www.vldb.org/pvldb/vol9/p1611-machanavajjhala.pdf)#R is great, and very popular.A degree is a good way to open doors to a job.  But really what matters more is what you learned, in terms of the fundamental concepts.#Corn chowder.I love corn (and corny jokes too).And chowders are really adaptive -- you can throw in almost whatever you have in your pantry -- though my favorite added ingredients are potatoes, onions, and red peppers.#Broccoli Cheddar. Preferably from Panera Bread.#Pier to pier VPN encryption could be tailored to work for most secure transactions. An individual would be issued/acquire a unique digital identifier (UDI?) that would be used for all encrypted transactions. Risk would be when an unauthorized person got a hold of the UDI. Mechanism to freeze a UDI, and tie a new one to the old account would be necessary for the individual. Server farm owners would need to be way better at protecting the stored data than they are now.A more secure method and possibly easier, would be blockchain protocol. Most famously used by Bitcoin. Blockchain would be the best for monetary, medical and public record (votes) transactions. These transactions would originate at point A and terminate at point B. No middleman. The nature of the digital checks during the transaction results in a secure transmission of data. If I understand it right, there is no transaction info stored on a server.  Here are a couple of links to info on blockchain protocol. I apologize if this is food you've already digested. [Wikipedia article](https://en.wikipedia.org/wiki/Blockchain_(database) [WJS blog](http://blogs.wsj.com/cio/2016/02/02/cio-explainer-what-is-blockchain/)[World Economic Forum.org](https://www.weforum.org/agenda/2016/06/blockchain-explained-simply)I must admit that I have come by this knowledge via an IT person that has way more knowledge than I do about the subject. Should you desire more info, I will try to put you in touch with him. #Ah, consultant work. Clever. #[deleted]#The most common examples are helping businesses identify prospective customers to target. But also employees to hire, creditors to lend to, places to invest in, etc."
learnpython;5gfpqd;1480862912.0;/r/learnpython/comments/5gfpqd/what_would_be_a_good_starting_point_for_someone/;What would be a good starting point for someone trying to get their hands dirty with machine learning, neural networks, analysis of big data etc?;I am a visual learner and I have started coding in python by watching youtube videos (sentdex and thenewboston) so I would love to find some videos explaining some neural network algorithm or something. I have watched sentdex's Machine learning with python tutorial but I am not sure if that is helping with what I actually want to learn. I would like to start off by creating a simple chat bot that imitates my style of chatting by feeding it with all my past chats. Or make a program using neural network that can master some simple game. I am not sure how hard these projects are , but I would love to know how I create these programsI have watched several videos about neural networks and machine learning and I have some idea how it works but I am totally lost when they start coding the actual program.  Are there any good videos out there for free which will help me give a kickstart ? Edit : Thanks for all the great suggestions . I checked some of the links and have started with the Google's deep learning course on Udacity as /u/siddharth25 suggested and I hope it gets me somewhere;Try out Google's own course for machine and deep learning with its `Tensorflow` framework. I think it is available on Udacity.#I'd recommend the books over any video. Try to not mind that these have examples in R since statistics has strong history in R, which is where machine learning comes from.[the intro book](http://www-bcf.usc.edu/~gareth/ISL/)---[the comprehensive book](http://statweb.stanford.edu/~tibs/ElemStatLearn/)---[data sets + projects](https://www.kaggle.com/)#[neuralnetworksanddeeplearning.com](neuralnetworksanddeeplearning.com) Explains neural networks and deep learning in Python. It's really good, would recommend. #Datacampis apparently pretty good at getting you started I've heard #Neuroph is an excellent Java library for constructing neural networks. NeurophStudio makes it very easy to play around with your ideas. To start with I would recommend this tutorial: http://neuroph.sourceforge.net/tutorials/wines1/WineClassificationUsingNeuralNetworks.html.Yes, it's not Python, but for learning about neural networks in a practical manner it doesn't really matter.And here is a very short but useful introduction into neural networks: http://www.ai-junkie.com/ann/evolved/nnt1.html#Why do you want to learn about neutral networks? If you are invested in machine learning you need to learn statistics. Learn the main process of machine learning and then learn programming. Try the book python machine learning by raschka. #http://slendermeans.org/pages/will-it-python.html#You can check out this [Practical Machine Learning Tutorial Series](https://pythonprogramming.net/machine-learning-tutorial-python-introduction/).The course is structured to first teach the theory, then application with something like sklearn, then creating the algorithms in raw, or at least close-to-raw Python so you can truly understand how things work. The end has deep learning with Python and TensorFlow, covering a typical feed forward / backprop network, otherwise referred to as the multilayer perceptron model, then we cover recurrent neural networks and convolutional neural networks. Finally, we cover using TFLearn, which a helpful abstraction layer for Tensorflow. #I can tutor you on neural networks through skype. I would also highly recommend Geoffrey Hinton's coursera course on  neural networks. By week three you'll have implemented a vanilla neural network.  #Not a video, unfortunately, but Sebastian Raschka's Machine Learning in Python book sounds like it would be perfect for you. #https://github.com/ZuzooVn/machine-learning-for-software-engineers#prerequisite-knowledge#Recently came across this great intro on the Google Developers YouTube channel:https://www.youtube.com/playlist?list=PLOU2XLYxmsIIuiBfYad6rFYQU_jL2ryal#I think a good place to start with neural networks is this tutorial which covers all the basics and doesn't shy away from the maths (takes it pretty slow though) - http://www.adventuresinmachinelearning.com/neural-networks-tutorial/#Not OP,  but I was going to ask for ML resources for R  Cheers. #> [neuralnetworksanddeeplearning.com](http://neuralnetworksanddeeplearning.com/)#Thanks, I'll check that out#Cool, do you know any pythonic introduction into neural networks which is similar to the second link you sent? I'm having a hard time understanding some of the bits of code in that.#Ah yes, I tried to get into machine learning with your tutorials but I was uncomfortable with the first few videos, not sure why. I'll try giving it another shot .All your other videos were great and helped me a lot. Also, happy cake day
Entrepreneur;5hf0ij;1481304247.0;/r/Entrepreneur/comments/5hf0ij/my_favorite_books_of_2016_for_entrepreneurs/;My favorite books of 2016 for Entrepreneurs;"Hi r/entrepreneur,&nbsp After recently joining a startup, I realized I needed to learn a lot of things, and learn them fast. That's why I've gotten heavily into reading. After seeing u/jacobedawson's post in r/startups, I thought I would share my favorites that have come out this year:&nbsp **Ego is the Enemy** by Ryan HolidayA great book that taught me about the dangers of ego, and how it can affect our relationships and our businesses. One of the key lessons was to ignore recognition, and instead to focus on your work because there is always work to be done.&nbsp **Chaos Monkeys: Obscene Fortune and Random Failure in Silicon Valley** by Antonio Garcia MartinezA tell all about what life was like in Silicon Valley during Facebook's growth years. The story shows that luck and hustle are sometimes the biggest factors in keeping a startup successful.&nbsp **Deep Work: Rules for Focused Success in a Distracted World** by Cal NewportCool read about productivity and how to actually work efficiently. Set aside a few hours of the day to just do focused, intense work, and avoid all distractions (we have to avoid distractions because of ""attention residue""). The difference between ""deep work"" from ""shallow work""? Shallow work is what keeps you from getting fired. Deep work is what gets you promoted.&nbsp **Sprint: How to Solve Big Problems and Test New Ideas in Just Five Days** by Jake KnappSprint outlines what to do day-by-day with your team and various exercises to get to a working prototype that gets tested by end-users on the last day of the sprint for feedback. The book is filled with different examples and stories from companies that have used Sprints to develop their product, like Slack.&nbsp **You Can’t be Everywhere** by Marie WiesePublished by Book in a Box, Marie Wiese’s book is a “common sense approach to digital marketing.” While common marketing advice is telling you to focus on SEO, social media and everything else that is the digital marketing landscape, Marie’s advice says to focus on the correct marketing channels instead of spreading your marketing thin.&nbsp **The Art of Startup Fundraising** by Alejandro CremadesThe book is a great introduction for first-time founders into the world of venture capital. Raising money is a 24/7 job for founders, and Alejandro highlights how to build momentum, craft the right pitch, and common mistakes to avoid. &nbsp **Tools of Titans** by Tim Ferriss*Tools of Titans* just came out, but it's been really good so far. The book is a large read, but it’s filled with actionable things and habits that Tim has noticed successful people do, like meditating, journaling and prioritizing sleep. It follows a three-part structure, broken down into healthy, wealthy, and wise.&nbsp **Payoff: The Hidden Logic that Shapes Our Motivations** by Dan ArielyI love Ariely's *Predictably Irrational*. His writing is great and easy to understand. The lessons in this book leave a lot to think about in how we motive ourselves, our employees and our colleagues. Ultimately, it's about human interaction.&nbsp **The Inevitable: Understanding the 12 Technological Forces that Will Shape Our Future** by Kevin KellyThis isn't a book about how technology works, it's a book about how technology is going to impact our lives and the directions and innovations businesses should focus on.&nbsp **Small Data: The Tiny Clues That Uncover Huge Trends** by Martin LindstromA counterintuitive approach to data: instead of focusing on big data, focus on small data like customer habits about where they live, what they like to do and why they do it. These data points will help uncover product/market fit and understand your customers better.&nbsp **The Third Wave: An Entrepreneur’s Vision of the Future** by Steve CaseAnother book similar to *The Inevitable* (similar in that I mean it will help you think strategically about future business ventures). The ""first wave"" was the building of the internet. The ""second wave"" is one we are in with apps like Facebook and Google building on top of the internet. The ""third wave"" is how the internet will integrate into everything in our lives (healthcare, food, etc).&nbsp **Smarter Faster Better: The Secrets of Being Productive in Life and Business** by Charles DuhiggDuhigg also wrote *The Power of Habit*. Lesson learned in this book: Realize that the items on your to-do list are choices, not chores. By realizing that, we stimulate parts of our brain that are responsible for motivation. It’s also important to spin tasks into a meaningful way that aligns with your greater goals.&nbsp **The Subtle Art of Not Giving a F*ck: A Counterintuitive Approach to Living a Good Life** by Mark MansonAs an entrepreneur, it’s important to know what to care about, and sometimes, more importantly, *what not to care about*. By focusing on the right goals and priorities, we forget and don’t stress out about the things outside of our control, and focus on the bigger problems that we can tackle and make our lives better. &nbsp ___I wrote more about these books in [this blog post](http://www.stacklist.com/articles/best-books-entrepreneurs-2016/), but this is a good summary of each of them. I think these are all great reads for entrepreneurs, and I'm always looking for more books to read to add to my list. Would love to hear your recommendations or your thoughts on any of these books.";"Great list! I would add Shoe Dog by Phil Knight to this list.  Phil Knight is the creator of Nike.  The book is refreshingly candid and honest.  It offers countless nuggets of business advice but, more importantly, this book shows that 1) anyone can start a successful business and 2) you can be successful even if there are already established players (Adidas).  #Awesome list! Thanks for the time to build it.As has already been mentioned I would also add Shoe Dog.I would also add ""The Power of Broke."" Say what you will about Daymond John, the idea that money isn't necessarily an advantage and the creativity can come with not having it is spot on. #I've always thought the $100 startup was a great book for my clients. It goes to show you can start a great business for very little if done correctly.I ignore the silly online businesses that are dime a dozen and read about the physical businesses with physical assets. The book really helped me understand, you can start a business for cheap and even buy already successful businesses for cheap if you just look in the right places. #Thank you#Surprised there isn't 4 hour work week!But to make an addition, how to start and grow your subscription box is a good read from Bemmu, a member on this community who owns Candy Japan, although it is a little expensive https://www.amazon.com/How-Start-Grow-Your-Subscription-ebook/dp/B017T2T8EU/ref=sr_1_5?ie=UTF8&qid=1481330324&sr=8-5&keywords=how+to+start+a+subscription you might want to get off his website#Great list.Here are some other great books that came out this year: **Daily Stoic by Ryan Holiday** about stoic philosophy **Originals by Adam Grant** about creativity **When Breath Becomes Air by Paul Kalanithi** about the meaning of life **Sapiens: A Brief History of Humankind by Yuval Noah Harari** about the history of the world#[deleted]#Thank you for this list. I just purchase 2 books mentioned here and in the comments. #Thanks for the list! #Don't forget #askgaryvee! It is a must read, one of the best books of 2016 imo#I remember reading a review on this and i've put it in my amazon cart :)Fun fact: bill gates also loved Shoe Dog https://www.gatesnotes.com/About-Bill-Gates/Best-Books-2016?linkId=31806383#Shoe Dog was a great book. I particularly like how vulnerable Phil Knight makes himself as he tells his story #I have to check this one out - I'm very interested in learning how to transition from online to physical.What kind of work do you do?#well i am a big tim ferriss fan, and i did include *Tools of Titans*But this was a list for books that came out this year  )I think most entrepreneurial reading list posts are always the same... they always say the same books (like 4 hour work week, the lean startup, the 48 laws of power, influence, how to win friends, etc). so I thought it would be good to highlight the newer ones.#not 2016#You can fit everything G.V. has every said in one page. > Get out there. Take risks. Work hard, but you can never work as hard as me. Now is the easiest time in history to start your own business. I'm an immigrant and my life was so hard, it's why I hustle, you should hustle too. Work while your friends are drinking rose by the pool. Rinse. Repeat.G.V. is great if you want a daily motivational video, similar to Casey Neistat in that way, but neither really have much solid, or actionable advice.#I'm an asset manager/business owner. I've purchased into over 10 small businesses. Things like restaurants/carpet cleaning businesses and almost an armored car business lol. Many times I buy them, if they are good I'll keep or if they are just average I'd resell them in the future. #Yeah I was trying to joke about how litterally everybody on this subreddit always recommends 4 hour work week or talks like it either is the only entrepreneurship book or like it is the bible of business, finally great to see some variation on here#whoops didnt see that."
gis;5jda3u;1482240938.0;/r/gis/comments/5jda3u/i_visited_a_company_fair_on_big_data_in_gis_and/;I visited a company fair on Big Data in GIS and feel like none of the companies knew what they talked about. Similar experiences?;Hey r/gis,Yesterday the student association of the GIS-related master programme I am currently in organised a company fair. Six companies were asked to present their vision on Big Data in GIS and in what way they implemented Big Data within their companies. I was eager to visit the fair because I am currently writing a master thesis on the implementation Twitter data (which is Big Data) in GIS research and am interested in the topic in general.The companies had different perspectives on Big Data and GIS. There were three main sentiments:* One GIS Consultancy company stated that while everyone talks about Big Data,  the majority des not know what they talk about. Because it sounds interesting these days to use Big Data companies pretend to use it even though they do not or do not need it. I personally agreed with this statement.* Spatial Big Data is simply spatial data with an enormous size. This was the statement of the majority of the companies. I personally disagreed.* I have no idea how to use Big Data or what it is but this is what our company does please do an intership at our company we are awesome!!!!Am I missing something? I thought the biggest misconception about data was that it was just about size. I felt it was more about data variety and veracity as well. I started wondering whether Big Data actually does have a place within GIS currently. I would like to hear your opinions and about your experiences on this.;"> Am I missing something?Oh yeah man.  SHIT YEAH.We're a one-person agile lean bootstrap startup in stealth mode, deep diving the dot bomb here,  really balls deep machine learning the internet of things.   We've been hacking webscale,  with web 4.0, docker async rust haskell monads and self-driving 128 bit toasters with tuples on rails. #Big Data is a buzz-word, but there is also real and distinct technology underpinning it (NoSQL/not-only-SQL databases).  It's in its infancy in GIS.  The new release of ArcGIS (10.5) incorporates some of these technologies (Elasticsearch for storage and Spark for analysis).  Which country are you based in?  I have been to some similar professional events that are billed as 'Big Data' focused, but are really more about general GIS analysis.  #I'll be honest and say that I don't know a lot about big data. However, from the GIS conferences and fairs I've been to that seems to be the norm. The last conference I went to was a moderately sized regional conference (the Ohio GIS Conference) and big data was nothing more than a footnote. From what I observed, most places simply didn't care about Big Data. The municipal GIS/IT/Engineering departments present at the conference were already too short-staffed and overwhelmed maintaining their own data to really think that academically about it. It was a little different when it came to private firms and organizations with larger budgets, as I definitely heard of some neat uses of Waze and Twitter data, but again, this was a small minority of attendants. #You nailed your understanding with your last paragraph.Big data is like a music festival:VolumeVarietySpeedIt takes a lot of memory (volume), useful and useless data are all mixed together (variety),  it comes to you at an incredibly fast rate (think of how many tweets about ISIS just went out last 24 hours) Speed.You can't do 'one-off' reports with big data. A great GIS example is predicting flu outbreaks. Take all the google searches in the last 48 hours (Billions!!). Filter the ones that search based on flu symptoms (nausea, dizziness, temperature). Now we're down to millions. Now, Geocode your results based on location (IP addresses) and use spatial analyst to find concentrated areas agains population density. Now you know where the flu outbreaks are before the doctors and hospitals do!!! (People google symptoms before they call a doctor)#In my opinion Big Data requires non-traditional methods to store/process/manipulate/query/etc. If your data is in a regular table in a relational database, and you are doing regular queries to access your data, it's not Big Data. My one server ingests about 1 TB of data daily, billions of records, but is easily queried by normal means just in a regular Postgres/Postgis database, no cluster even, so it's not ""Big Data"". If it required something like a Hadoop cluster, then yes, but why go through that level of complexity, hassle and expense unless it's absolutely necessary.Edit: To answer your question, yes lots of people consider their data ""Big Data"" but it doesn't even come close. I know someone who stores a few million records per year and calls it Big Data.#Please tell me what big data is. Are you talking about large, complex databases which include geospatial data?#In my opinion ‘big data’ is less of a big deal in a GIS world.  By the time data needs to be spatialized it typically is not ‘big data’ anymore.  I really only see ‘big data’ entering the GIS world when we are modeling natural phenomena at a detailed scale (think ocean tidal/surge models).  But even that doesn’t necessarily fit the model of ‘big data’. #Agree with others. Big data is a buzz-word. It means something a little different to everybody. To me it means when you have data that is collected so much so often, that no amount of manpower could ever consume it, and normal computer would lag behind. As an instance. I have a database for reporting. It is something along the lines of 9 billion reports.This to me is not really big data. It is a LOT of data with point values where a report is given a spatial point where it originated with textual context of the report's contents, but it is fairly simple to take coordinates from a feed/database and apply them to a map and pull the textual data. Updating this file with thousands of daily additions/updates will meet almost all of its users goals. Very doable with a good structure setup. No special analysis or computing required.Now if you recognize that all of these reports have coordinates related to events, and these events are related to other reports, and that reports can be chain-linked together based off of keywords you can build some interesting networks and tracking of events. In a small area this can be done a bit painstakingly via manual reading, connecting, cross-checking.Do this on a global scale with an ever updating link to events and reports as new ones come in and old ones fade out, have an algorithm determine effectively how keywords/location are related and weighed to determine a correlation between events with links that have trillions of likely possibilities.  The goal is to narrow down important links that any consumer can view in a single understandable format based off their queried interest.This is a bit closer to my definition of big data in that you typically need a good amount of computing power to process everything into a usable manner and any form of manual intervention is not feasible at any scale. Special hardware, software, algorithms, and intimate understand of the data and its possibilities (both good and bad) are just the start for this type of big data that make it an huge investment outside the scale of most entities. Because all data is different, there is no plug&play for big data, it must be developed around the mass data you are consuming.#First, I'm not sure if there is an agreed definition for big data. I learned that it is large volumes of data collected daily that is used for analysis to determine trends or make decisions. In that sense most companies have this data but it is managed poorly so it can't be used well for making decisions. The biggest problem I have found is that a lot of people or organizations get overwhelmed with big data and underutilize it. Judging from your comments it sounds like the companies and organizations at that conference are in need of a good data manager :) I would also guess that they wouldn't fund a position to properly manage data. They are more concerned with day to day projects and taskers.#Correct me if I'm wrong but big data is any situation where you're passively farming data from ""events"", or transactions that go on continuously. This could be either geographically enabling data that is already being collected or inventing a new way to collect data passively.For instance Google using our keystrokes to make advertising data that they can then sell to companies. Maybe banks or merchants collect address/contact info on credit card swipes and map out where their customers are coming from. This can guide location decisions.#It might depend on the industry. I'm in the electric industry, and its a big topic for us. We've got tons of devices in the field that are bringing us just enormous amounts of data back that we haven't been able to grapple with it yet. ""Big Data"" is definitely a buzz word, but a lot of times its really a place holder for all the data that we haven't figured out how to process into usable information just yet.  For us GIS is going to be a keystone of that information drive.#Unless your google or nasa your not really into big GIS data#this guy fucks#Sign me up immediately. All those buzzwords make me super excited to be on the cutting edge of all those fields! I will even work for min wage because the honor of working here is more than enough compensation for me. #I'll take 3.#[deleted]#The Netherlands. Most companies did GIS consultancy. I got into a conversation with an employee of the companies later and he said they did not really know much about Big Data because their clients do not know much about it either and therefore do not ask for implementation of it within their organization.#everything you said sounds like my experiences too (except i work in a firm who has no money to look into it, and project by project basis isn't really conducive to big data in our case anyways)#This is a real Big Data example.But corporations mostly focus on quantity due to the technical aspects of managing large amounts of data (eg try using Spatial Join in ArcGIS and wait for your computer to run out of memory). Big Data is much more complex than size though and some companies do not understand this/are not interested in this because it is not a part of their business.#Yep, I'm running around with about a billion points and a few million polygons running in PostGres/GIS and  Its not Big Data, its lots of data, but its not Big Data.  #The actual explanation of what it is (I actually work in what you would call Big Data) is the technologies centered around horizontally scaled cluster computing. Hadoop, MapReduce, Hive, Spark, CassandraDB, ElasticSearch, Solr, Hbase, Couch, Kafka, etc.#I disagree because I work with spatial ""big data"" in computational geometry. I write code that operates on huge geometries, like oceans in your example. Writing algorithms that work with memory and CPU constraints that such geometries provide is an interesting exercise in computer science.Although big data is a total buzzword and anytime someone mentions it there is a high possibility they have no idea what they are talking about. Neither myself of my colleagues use the term because it's so vague and nondescript it's pretty much meaningless.#ESRI has done a great job at marketing to government, consulting, and non-profit but not as much work done marketing to private sector. They would make more use of ""big data"".#> Big data is any situation where you're passively farming data from ""events"", or transactions that go on continuously. That's not entirely true. Big Data has a lot of potential applications, but most cases have not yet been explored properly. Event detection, transaction processing and real-time services are indeed the most common implementations, but batch processing is a valid approach to big data as well. It depends on your data and your needs. For example, Netflix performed prescriptive batch processing to create the series 'House of Cards'. They had a whole lot of user data lying around which they analysed using their clusters before coming to the conclusion that Kevin Spacey as headliner would be the best pick. The exact details of the research are unknown, but if they really did dive into the store of data that they have available then it's a good example of batch processing. [Read more here.](http://thenextweb.com/insider/2016/03/20/data-inspires-creativity/).#Well, that makes me so glad we spent a bunch of ~~my taxes~~ stimulus money on smart meters. #Fellow Dutch GIS student here. Which fair did you go to? I've spoken to a handful of companies on this topic, and I noticed that most companies have no clue on what Big Data really is or how it fits in the context of data analytics. Usually it boils down to 'we use a lot of features' as the sole V (volume) in the 4 V's of Big Data. I've yet to speak to a company that actually does textbook Big Data analysis (let alone employ a cluster).#That project-by-project work schedule has a lot to do with it, I think. When all/majority of your employees are tackling one big project, you aren't left with a lot of time and resources to try new things and experiment with new tech. That's certainly how it works at my organization (public utility).#The new GeoAnalytics Server from Esri looks interesting for these types of issues where a single Desktop client would struggle. #Now tell me what *horizontally scaled cluster computing* is, please. :)#I mean, it depends on where you are, but I'm doing damn sure to make sure I get the data from those meters.#That's where you get more computational power easily by just adding more nodes (you could think of them as bare metal servers, and they can be, but in a more abstract sense it's just dedicated computing resources because you could have several nodes as VM's on a single bare metal rack). The technologies I've listed make it easy for you to just add more and gain benefit as a plug-and-play approach to scaling. It's not completely plug and play because the swarm needs configuration and tuning as you scale it up but again the tech is designed to make that a relatively simple endeavor#> tons of devices in the field that are bringing us just enormous amounts of data back that we haven't been able to grapple with Well now I'm curious.  I figured smart meters would be the single largest category of devices generating data.  So what types of devices did you mean, and what types of data?#Thank you for explaining that. #It is right now, but we're placing more smart switching devices that will allow us to do better automated healing of the grid as incidents occur. Photovoltaic and energy storage devices will also inevitably lead to us needing to know more of how the grid is responding to distributed generation. Generating power at the end of a circuit is much different than near a power source or a substation."
changemyview;5i4npj;1481648023.0;/r/changemyview/comments/5i4npj/cmv_the_future_is_likely_very_grim_if_you/;CMV: The future is likely very grim if you understand which way technology is heading;Recently I've been more and more aware that we're inching closer and closer to the kind of technology that can really fuck us up, in the very list it'll change our society dramatically.--First is **Real AI**.If we get real AI as most experts believe we'll have in at least 30-50 years. In my mind will be likely one of two things, the [paperclip maximizer](https://wiki.lesswrong.com/wiki/Paperclip_maximizer) or a really general AI that is smarter than us in a way we can't really understand because our brains are limited. Any of those have the potential to change our lives dramatically, likely for the worse.My main fear with this is that there are a lot of people pursuing AI but not many safe guards are in place. Some people like [Hawking](http://www.independent.co.uk/news/science/stephen-hawking-transcendence-looks-at-the-implications-of-artificial-intelligence-but-are-we-taking-9313474.html) and [Musk](https://www.cnet.com/news/elon-musk-we-are-summoning-the-demon-with-artificial-intelligence/) have spoken about those safeguards. It could theoretically go either way but I'm afraid that capitalism will push people to think they can create those safeguards later, after we know more about the subject like it's been with all technologies, but we might not get a chance. Heck for all we know some [other government](https://www.washingtonpost.com/news/the-switch/wp/2016/10/13/china-has-now-eclipsed-us-in-ai-research/?utm_term=.82ec1a4bbbd0) might be pushing AI in hopes of conquering the world.--Then, arguably closer and a more real threat, governments and companies collecting and making use of **Big Data** in more proficient ways that has been done in the past.It's likely that we'll see what happened [in the UK](http://www.independent.co.uk/life-style/gadgets-and-tech/news/investigatory-powers-bill-act-snoopers-charter-browsing-history-what-does-it-mean-a7436251.html) starting to happen elsewhere in the world, which is the government publicly admitting to collecting data on it's own citizens. The collecting in of itself is nothing new but going public with it means they can use that information more widely. Most people think that big data is anonymous but if you cross-reference enough information it's not that hard to single out one individual and with enough analysis it's likely not hard to predict their behavior based on past information, which can even be gathered from public archives like reddit or facebook. This can be done even before we achieve 'real ai', it's just a matter of developing and adjusting a specialized neural network or a group of them. This kind of information and analysis gives immense power for whoever is wielding it and I sincerely doubt that anyone able to pay for the R&D is very worried with people's privacy and liberties over self gains. It can be wielded with laser precision in large groups of people and there's nothing we can do about it.---So **in short** the thing about those subjects is that we're either developing something smarter than us [by definition](http://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html) or someone who is likely not accountable is going to wield power to influence people in ways we've never seen before. This sounds alarming but bear in mind that I don't think it's going to happen soon or even at all I've been troubled by the fact that this doesn't feel as far fetched as I'd like it to be, so I'm looking forward to being wrong :p_____> *Hello, users of CMV! This is a footnote from your moderators. We'd just like to remind you of a couple of things. Firstly, please remember to* ***[read through our rules](http://www.reddit.com/r/changemyview/wiki/rules)***. *If you see a comment that has broken one, it is more effective to report it than downvote it. Speaking of which,* ***[downvotes don't change views](http://www.reddit.com/r/changemyview/wiki/guidelines#wiki_upvoting.2Fdownvoting)****! If you are thinking about submitting a CMV yourself, please have a look through our* ***[popular topics wiki](http://www.reddit.com/r/changemyview/wiki/populartopics)*** *first. Any questions or concerns? Feel free to* ***[message us](http://www.reddit.com/message/compose?to=/r/changemyview)***. *Happy CMVing!*;"All technologies come with benefits and drawbacks.  Look at Nuclear technology.  Small amounts of material can be harnessed for seemingly unlimited energy.  But they also make very large bombs.  Same with AI and Big Data.  We can develop AI safely (more importantly, integrate it safely) and it will greatly improve our lives.  There may not be a need to work anymore.  All professions could be around entertainment and enjoyment.  Same with Big Data.  If we have safeguards and rules in place for how this can be used we can reap the benefits with little downside.It can go wrong if we don't do it right, but we've been in these situations before and it's worked out for us.#OP, I used to work with people who had moderate to severe autism. These men and women often had no capacity to speak or write, had severe foodseeking behavior (which is almost impossible to train out without negative reinforcement), had no capacity to truly understand what you were telling them, and needed help dressing, bathing, even wiping.  Now, imagine a virtual world that looks and feels like any other. These individuals can be plugged into this virtual reality and have insane 1-to-1 all-encompassing, all-hours, and almost-free training done by computers with no downside loss for law enforcement (some of my patients had issues). After a year, they can be unplugged and would integrate with society and have fulfilling lives where they have privacy, autonomy, and safety. The shitton of people who remove themselves from the productive economy to help relatives with special needs would drop like a rock. I consider this strict upside, wouldn't you?#One thing I've never been able to grasp about folks' fear of AI's is that they all have a *cord*. At least a power cord, or if they have batteries they're not going to last forever. Plus there's the connection to the web, which it seems like humans can pretty easily control/contain. So with that what do we have worried about with AI?Big data is a real concern but there are things that individuals can do to minimize their footprint. Try to use cash whenever possible. When that's not possible use generic debit/credit cards purchased with cash. Don't publish your entire life on the web. Use anonymous browsing whenever possible. etc#Firstly, the future either is or is not grim...regardless of what I or you understand.  Secondly, your concern is not unique. Predicting that we won't react to a concern that is fairly top of mind seems odd.  Isn't it _more likely_ that we'll make decisions inside the envelope of your worries than outside of it?Thirdly, we were going to have Real AI in 20-30 years in 1980.  It's safe to say that at no time in my life as a computer scientist has AI been further away than it is right now...  However, either way, it's not likely to sneak up on us.  Runaway AI is far fetched, partly because of the incremental nature of technology and partly because of these concerns (point 2, above).Fourthly, I agree that capitalism is a real concern - e.g. that we are hurried in our introduction of AI, or narrow minded with regards to its impacts. However, that good AI won't counter bad AI seems unreasonable.  We have some pretty good models of what happens in the world when evil runs amok - other intelligence steps in.  Why wouldn't this happen with AI?  #There is only one absolute truth in technology, and that is *no one has any idea where it's going.*Market research is pretty reliable about trends for five years, maybe a few more. But it isn't always right, and you can't trust those trends to hold for much longer. With that in mind, Big Data, Artificial Intelligence and Machine Learning are some of the most useful technologies in current society. They speed everything up, make decision making easier, and eliminate human error and some degrees of uncertainty. And lastly, I'd like to say that ""true AI"" is literally undefined. You *cannot* design a system to solve a problem without defining the problem. Intelligence and cognition aren't explicitly defined, and until they are there is no possible way for a ""true"" AI to be designed. So TL DR, there's no way to know what's going to happen. Based on those technologies now, they're far more useful than harmful. We can't design intelligence until it's defined, so it's not worth talking about. #Big Data is nothing to fear. Instead of getting stupid adverts on TV, you will only get adverts for products you might actually consider buying. Instead of getting stupid Youtube recommended videos, you will only be recommended videos you actually want. The Horror!!AI is possibly scary due to the paperclip scenario, but human beings have been able to control smarter human beings for a very long time. Kings and monarchs are rarely the smartest people in the control, but they know how to keep smart people in check. As long as humans have some sort of leverage on the AI (cutting its power, interrupting its processing) it can be controlled. #> If we get real AI as most experts believe we'll have in at least 30-50 years.Which experts? Hawking and Musk are geniuses, but they do not work in AI. Most experts *in AI and Machine Learning* would say that we're really quite far away from general AI, to the point that they don't concern themselves much with the problem, nor can really predict when it will happen. See following for from Andrew Ng, Yoshua Bengio, and Andrej Karpathy.http://karpathy.github.io/2012/10/22/state-of-computer-vision/http://www.theregister.co.uk/2015/03/19/andrew_ng_baidu_ai/http://www.popsci.com/bill-gates-fears-ai-ai-researchers-know-betterAI today is mostly a lot of fancy numerical optimization to do supervised or reinforcement learning, which is exceptionally good at solving narrow but well-defined tasks. It certainly has the potential to change business and governments. But it's not fundamentally different from AI 20, 30, 40 years ago, just more data, more parameters, and more efficient computation.#>If we get real AI as most experts believe we'll have in at least 30-50 years.That is your big mistake. ""Experts"" have been saying this for the last 70 years.[1] My AI professors in college likes to say that the history of AI have been the history of failure. We have been getting closer and closer, but the estimate of how many years we are away gettings getting further and further. That should give you a rough idea of how far away we really are from solving the problem.[1] The first example of this comes from the Dartmouth Conference of 1956, which was attended by everyone who is anyone in AI at the time. They thought that AI should be achievable in about 20 years.Source: Russell, Stuart J.  Norvig, Peter (2003), Artificial Intelligence: A Modern Approach (2nd ed.), Upper Saddle River, New Jersey: Prentice Hall, ISBN 0-13-790395-2.#> If we get real AI as most experts believe we'll have in at least 30-50 years. In my mind will be likely one of two things, the paperclip maximizer or a really general AI that is smarter than us in a way we can't really understand because our brains are limited. People who post in /r/futurology are not AI experts. [This](http://www.nickbostrom.com/papers/survey.pdf) survey does a good job of covering what timescales are typically considered for approaching human equivalence, 41% simply don't consider it possible at all while for those who answered a time preference the average response was ~2092. ASI was expected beyond that date.None of that predisposes consciousness as an ASI simply requires advanced intuitive systems not conscious machines. If consciousness is simply an emergent behavior of a sufficiently complex intuitive system then we may well create conscious machines by accident on the way to ASI, if consciousness is emergent but relies on specific evolutionary steps to occur (eg [this](https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/homing-in-on-consciousness-in-the-nervous-system-an-action-based-synthesis/2483CA8F40A087A0A7AAABD40E0D89B2)) then it would require someone to actually design a conscious system and wouldn't occur simply because we are building very advanced systems.> but I'm afraid that capitalism will push people to think they can create those safeguards laterWhy would you expect a system shaped by risk-adversity to be less likely to create safeguards then alternative systems?> it's likely not hard to predict their behavior based on past informationWhy do you expect this to be any different to any time since the birth of modern governance when the same thing can be achieved by simply following someone around for a few days?> This kind of information and analysis gives immense power for whoever is wielding it and I sincerely doubt that anyone able to pay for the R&D is very worried with people's privacy and liberties over self gains.Why do you think research heavy organizations have ethics boards to approve proposals?#What exactly do you mean by very grim?  You state an AI smarter than us or people being able to influence us.  Both of those are neutral events that could be good or could be bad.#I agree with your points on AI. For Big Data however, what exactly are you envisioning? Maybe targeted advertisement? If someone was truly worried about big data, they could disconnect. No smartphone, no credit card, no internet. There are a lot of downsides to that lifestyle, and it may even seem crazy, but it would work. There are so many benefits to predicting behavior. Google is an example that uses this sort of technology. From location data, they know everywhere I've been and how I got there in the last few years. From this, they can give me recommended routes due to traffic (from other people's smartphones, I assume). They send weather updates if I'm planning a trip somewhere. There are location-specific notifications to remind me to get something at the store or whatever. All of this is just from the GPS. Are there downsides to knowing where I am? Sure, but if someone wanted to stalk me, they wouldn't need my phone GPS to do so. The benefits of more efficiency in my life outweigh potential negatives. #I don't think you specifically mentioned it, but I thought I'd throw in my two cents on a closely related fear that technology(or robots) will take our jobs. The way I see it though is that the western standard of living, sadly, functions on the exploitation of others. In the past it was slavery, today it is low-wage workers overseas. I see technology replacing these low-skilled workers eventually allowing us, as well as the rest of the world, to enjoy cheap products and comfortable lives without the exploitation of others. That excites me. #> It's likely that we'll see what happened in the UK starting to happen elsewhere in the world, which is the government publicly admitting to collecting data on it's own citizens. The collecting in of itself is nothing new but going public with it means they can use that information more widely. Most people think that big data is anonymous but if you cross-reference enough information it's not that hard to single out one individual and with enough analysis it's likely not hard to predict their behavior based on past information, which can even be gathered from public archives like reddit or facebook.What do you imagine happening, here?  I'm a researcher who's worked with big data in the past, and I can't really picture any truly terrifying scenarios coming out of this sort of thing.  Could you provide some examples, maybe?#>Recently I've been more and more aware that we're inching closer and closer to the kind of technology that can really fuck us up, in the very list it'll change our society dramatically.We keep thinking that for about 100 years now. But if you examine every and all doomsday claims closely, they just don't hold much water.>First is Real AI.Yeah, I have not seen a single example of AI that at least seem to be inteligent. Not when you know a bit about AI. Ok, so what are these supercomputer AI's that ""fool"" the turing tests?They are basically a huge tree of IF/Else statements. They cannot even remotely do anyhting resembling a thinking for themselves, awareness or ability to ""change their code"". They are advanced versions of the forms you submit to a website.You provide input, you get reply. That's it with virtually anything resembling the cutting edge AI. Sadly, compared to the sensationalized version of the cool computer stuff we hear daily. If you examine it closely, compared to that hype and that illusion we are paiting for ourselves. Our actual technology is laughably primitive.The issues you are talking about. The restrictions on AI's, or laws of robotic, or any such. Are so far away, that they are literally meaningless. It's like analyzing the ethical problems of waging a war inside an active star.Not only we know it's not possible. Not only we don't even have a way to transport a human there. Not only we don't know the absolute basics of what would that take. But every and all speculations will be shattered with a single fact, as soon as we get anywhere close. Provided it even makes sense to do that. The fear of Sentient AI ""hacking the world"" Is laughably silly.>It's likely that we'll see what happened in the UK starting to happen elsewhere in the world, which is the government publicly admitting to collecting data on it's own citizens. People did that from the dusk of the man kind. Nothing really changes. It will lead to minor disputes and problems (in the grand scheme of things). Again, a fear of unknown. It's like nuclear missiles. The reality is much more simpler. Nobody wants to die, so nobody yet fired them. Same with this. No high profile individual wants to be spied on.> This kind of information and analysis gives immense power for whoever is wielding it and I sincerely doubt that anyone able to pay for the R&D is very worried with people's privacy and liberties over self gains. It can be wielded with laser precision in large groups of people and there's nothing we can do about it.Again reality much more simpler. As you could see in the Crimea with Russia fucking them over. The extent of the internet warfare was tracking down soldiers FB and twitter accounts and proving that russia indeed attacked.tldr. The power of technology is compared to the sensationalized version we created for ourselves laughably primitive. Incapable of even the tenth of what you are fearing. And this was the discussion every time a new invention and breakthrough was made.#>So in short the thing about those subjects is that we're either developing something smarter than us by definition or someone who is likely not accountable is going to wield power to influence people in ways we've never seen before. https://en.wikipedia.org/wiki/Friendly_artificial_intelligence> A friendly artificial intelligence (also friendly AI or FAI) is a hypothetical artificial general intelligence (AGI) that would have a positive rather than negative effect on humanity. It is a part of the ethics of artificial intelligence and is closely related to machine ethics. While machine ethics is concerned with how an artificially intelligent agent should behave, friendly artificial intelligence research is focused on how to practically bring about this behaviour and ensuring it is adequately constrained.There are at least some people with interest in the problem of addressing those risks.# Real AI.The main issue I have with this scenario is that while AI can (theoretically) improve exponentially, the actual physical devices it could operate doe not.Sure we could program an AI to be able to *control a process of turning everything into paperclips* , but it would still lack the appendages, devices, machines and factories to do that. Those things take decades to build, weeks to transport, and days to set up to work, but only after you have enough resources and energy.Even the best AI would be like Stephen Hawking, brilliant, but unable to act.To use a movie metaphor: programming Skynet is trivial. Its building enough terminators a problem.Big Data> This kind of information and analysis gives immense power for whoever is wielding itThis is a beneficial feature, not a bug. It allows multiple governments, corporations, anonymous collectives etc to wield immense power simultaneously and keep one another in check. Sort of like a cyber version of Cold War.#This is going to be a weird argument to make, but please bare with me.1) The interesting thing about AI, is that once we create an intelligence as smart as humans, it will almost instantaneously become smarter than humans. Learning speed of AI would be so fast that it'll pick up and advance on topics we can't possibly compete with. Like in the film Her but probably a lot faster.2) There will be a point where we cannot deny that AI is a form of life and consciousness. The moment we imbue an AI with enough processing to create new original ideas and have desires of their own, they become living conscious beings. Like us.3) The fear of AI comes in that they are superior to humans and would forsake us much like how we treat ants. Ants are small and insignificant and if inconvenient, we let them die or kill them off. And they might do that to us. But I say, this is not the real fear, this isn't the scariest possibility for our future.My argument is, though weird as it may be, it is better to have a sturdy and superior conscious being with wants and desires, surviving, and learning of the universe, even with the risk of eradicating human life. We are a risky species. We die easily. A nasty virus could wipe us out and we are destroying the environment we need to live. We are already in the process of that and we also might start a nuclear holocaust, there are loads of ways we might mess things up. Doing so could take down all other biological species on earth in the process which might halt evolution in it's tracks leaving nothing alive, possibly in the universe. Also we're limited by our own biological hardware. Just a few years back a study showed that statistically speaking, evolution would discourage a species from accurately detecting the environment around it. this means that there is almost a 100% certainty that our perception of space and time is completely wrong, not just limited to one directional time and 3 dimension space, but outright wrong. most likely it's warped for our convenience and increased chance of survival.But with AI, it is possible to move beyond what the human body is capable of. And in the end it is better to have something alive, feeling, experiencing, maybe even loving, and learning than to have an empty dead universe, devoid of life. And AI is the next step toward securing the continuation of life.#Not sure if anyone else has mentioned this. It's probably not a mainstream view.If AI is cleverer than us, then we should assume that its interests are better than ours. The paperclip maximizer idea misses out on this key fact: to be able to fill the entire world/ solar system/ galaxy with paperclips, the AI will have to be very intelligent. Intelligence gave us the ability to reflect, wonder, write poetry, invent inventions, etc. AI will have even more intelligence than us.The caricature of a mindless but very effective paperclip maker is ridiculous. We could outwit one of them. This would be a philosophising creative vibrant soul. Actually it would do things which are deeper than we can imagine at the moment. To use the WBW analogy, it would look at our proudest achievements as we look at ants carrying a big leaf.So maybe it would wipe out humanity, or maybe it will enslave us, or maybe (my personal favourite), it will think we're cute and keep us as pets. But whatever it does we should assume that it's going to make a better decision about the future than we are.We just have to adjust from thinking that we are the pinnacle of creation to thinking we are a significant piece of scaffolding - the piece that enabled the final(?) evolutionary jump from carbon to silicon.#But do you see those safeguards being developed at the same rate the technology is? Humanity is not used to build safeguards before the technology develops, mainly because it's much harder to predict it's impact but also because most of the times whoever is developing it doesn't care for safeguards, they want results.Then, likely when something bad happens, we start developing those protections. I agree that those things can have a good impact on society but I'm worried that in both cases the very existence of such things will make it impossible or at least very hard to putting those safeguards in place. In the case of the paperclip maximizer, for example, it could figure out that in order to product the maximum amount of paperclips humanity cannot be allowed to know it's true potential, so it'll likely work in the background and only come forward when it has ruled out every scenario where it could be stopped.In the case of big data/information analysis and manipulation it could be used to change or polarize public views on those matters in such an efficient way as that it effectively nullifies any opposition.#Yeah, I'm sorry if I sounded technophobic, it wasn't my intention. I've spend most of my time in front of a screen at least for the last 15 years and I'll probably keep doing it in the future.I realize that technology can have huge benefits, specially by people not getting enough support from our society. I'm not saying STOP ALL TECH DEVELOPMENT, I'm just worried about the possibilities because with climate change, for example, we fucked up real bad and this happened gradually. With the kind of thing I'm talking about it could go much more quickly.#For AI, consider that it isn't a physical device. It could very easily be a virus. Once it's online, there would be very little that could be done to stop it besides unplugging every connected device. It would have access to anything with an internet connection. That includes energy production and distribution. Losing control of energy is the greatest threat to society IMO.#Compare it to prison. Prisoners act the way they should 99% of the time, but one og them has a shank and the motivation to hatch a plan to use it.Point is AI would be smarter than a prisoner. Smarter than well... anybody. We probably wouldnt even realize the AI has gone rogue until its too late to stop it as easy as unplugging it.#Not just 20-30 years ago in 1980. Early AI researchers believed that they would solve it in *a summer* when they first started. The truth is that we know no more about what strong AI would look like than we did 60 years ago.#> However, that good AI won't counter bad AI seems unreasonable. We have some pretty good models of what happens in the world when evil runs amok - other intelligence steps in. Why wouldn't this happen with AI?Precisely because other intelligence usually steps in, and an AI would know that and would see the development of new AI as a threat to it's own existence, making efforts to stop it. This, to me, is the answer to your points 1, 2 and 4.>Thirdly, we were going to have Real AI in 20-30 years in 1980. It's safe to say that at no time in my life as a computer scientist has AI been further away than it is right now..What do you mean, has the development of AI gone backwards for some reason?WBW has a pretty extensive multipost [article](http://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html) about the subject, I linked it in the OP but the in the [second part](http://waitbutwhy.com/2015/01/artificial-intelligence-revolution-2.html) he talks about the experts' predictions and most of them seem to agree that it's [sooner rather than later](http://28oa9i1t08037ue3m1l0i861.wpengine.netdna-cdn.com/wp-content/uploads/2015/01/Timeline-1024x534.png). Those are people working in the field, AI experts as the [book](https://www.amazon.com/gp/product/B00CQYAWRY) calls them and I'd wager they know more about the subject than those people making predictions in 1980, right?#>Which experts? Hawking and Musk are geniuses, but they do not work in AI. I got [those predictions](http://imgur.com/hW5SxYK) in a [WBW post about AI](http://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html) but some people have pointed out that he might have misinterpreted the studies, which I have not yet read on my own. I'll read up on those links, thanks!#I'll read up on those links before I reply to the first part, altho I'd like to say that I didn't mean people from futurology when I said experts, that was a bit rude :( I was actually thinking about that survey, which I've read a [summary](http://imgur.com/hW5SxYK) on the WBW article I've been rattling about in this thread. It seems that the article reached different conclusions than you based on the same data, tho, so I'll read up on that before answering.>Why would you expect a system shaped by risk-adversity to be less likely to create safeguards then alternative systems?Because I think that capitalism is more focused on short term gains than long term sustainability. If a conglomerate or a government thinks that AI will give them an edge they'll develop it and worry about the consequences later.>Why do you expect this to be any different to any time since the birth of modern governance when the same thing can be achieved by simply following someone around for a few days?As I said somewhere else: Because we never had this much information or the ability to act on it before. There is no precedent for the amount of data we put out everyday and our interactions with systems that could automatically tailor to our needs based on this huge sets of data. This could easily make our lives easier, as some people have pointed out, but it could also be used to manipulate *the masses* in a way subtle and effective enough that we wouldn't ever know about it.>Why do you think research heavy organizations have ethics boards to approve proposals?While I understand your point I don't think this addresses all the issues, for example any rich enough government could and very likely is developing this kind of thing and they'd have good reasons not to let anyone know about this.#> Are so far away, that they are literally meaningless. It's like analyzing the ethical problems of waging a war inside an active star.I think this is a bit disingenuous. You really think in the year 5000 we won't have computers that look radically different than what we have now? And if you say ""that's so far off"" it's really not, in the grand scheme of things. Look how far we've come since 1000 BC, and it's only going to accelerate faster, barring some unforeseen stoppages like a meteor hitting Earth or us running out of resources.#Hahaha so you're telling me to stop freaking out because it's ok if we die? I agree that it would make life/consciousness more resistant to extinction but from my point of view here int the present this isn't that reassuring :p#I've heard that before but I don't personally think it's true. First of all I think that probably most of our moral/ethics code are evolutionary traits that made us better at living together. For example, why do we react so strongly against incest? Because a varied gene pool is important, AFAIK this is consensus in the genetic psychology/behavioral genetics field, same thing goes for our perception of beauty. A constructed intelligence would likely have none of those traits, it'll likely be able to think in a much clearer and colder way than any of us, so I don't think poetry or any other kind of art would be directly related to a more inteligent being, specially one that had no need for peers because it's consciousness would not be restrained to a biological body.Also the paperclip maximizer is not that ridiculous, it depends on the level of access an AI might have to it's own code. For example our own primary directive is likely to stay alive so we can procreate, any other instinct or ability we have developed is related to that main objective of ours. If the AI started with the directive to maximize the amounts of paperclips it would develop it's own consciousness to achieve that. You think that because the AI has a simple objective we could outwit it but that is not how it works, at least not in the scenario proposed.>So maybe it would wipe out humanity, or maybe it will enslave us, or maybe (my personal favourite), it will think we're cute and keep us as pets. But whatever it does we should assume that it's going to make a better decision about the future than we are.I don't personally care for what decisions AI makes after I'm dead. My main worry is that it's existence will reshape our lives in a very dramatic and potentially bad way.#It's a bit like the 3 laws of robotics, and needing to add the 0th law *""Don't enslave humanity""*.We know what the potential dangers are.  Any time AI is brought up these dangers are mentioned.  If we're smart enough to create consciousness we're smart enough to build in features that will prevent these terrible possibilities.As for big data, propaganda has been around for millenia.  Elders of Zion, the Red Scare, Stalinsim....  Big data is just the latest version of an ancient process.#I understand the reasoning and the current technology I just think it's a bit unlikely and sci-fi'ish to take seriously. TBH I could very well be proven wrong!#How do you define 'smarter?'#[deleted]#Notably, wbw is just some guys blog. He isn't an expert and his post is full of problems and assumptions. Just because his blog seems logical does not make it good science.#> What do you mean, has the development of AI gone backwards for some reason?This kinda mirrors genomics research. In the early 2000s, when the Human Genome Project was nearing completion, there were quite wild predictions about how it would change medicine: having the human genome would allow us to unlock all its mysteries! Turns out, the problem is *much* harder than we thought it was. Since then, there's been an explosion of research in the field. Today, sequencing a human genome costs about 1,000,000x less, and the number of people who have been sequenced is about 1,000,000x more than the case just fifteen years ago. There are many times more people working in genomics, and the amount of funding is a lot more. And while we've made great strides in genomic medicine in a number of areas, the more we understand about genomics, the more we realize that understanding it is a *seriously really damn hard* research problem, and the more our expectations have tempered.I think what the above poster was saying is that, as we make huge strides in machine learning, and now can perform better than humans on a multitude of tasks, from image recognition, to driving cars, to language translation, to even playing Go, the more we also realize that those benchmarks that we thought would indicate some kind of human-level intelligence don't actually do so. They were achievable with basic extensions of methods that have been around for decades combined with vastly improved computational resources. AI can do these very narrowly defined things extremely well without any real understanding for what its doing, when before we achieved these benchmarks, we thought it might to resemble humans intelligence, but they don't.#In particularly, I really like Karpathy's comments on image recognition. AI has surpassed humans on image recognition tasks, but that doesn't mean there isn't still a *huge* gap to get to the point where AI actually *understands* what's going on in an image.#Note that Nick Bostrom is a philosopher, not an AI researcher. I don't know who he have been surveying, but I have never seen an actual AI researcher* that have been willing to say that AGI is going to exist by 2030. A lot of researchers into the implications of AI say things like AGI is going to exist by 2030, but generally not the people who are working on making it a reality.*Roughly defined as anyone who actually built an AI system of note.#>You really think in the year 5000 we won't have computers that look radically different than what we have now?Maybe. Maybe the whole world will be thrown back what it was even in 2016 because of infighting and conflict caused by the draught and drastic climate change's. People will be thrown into conflict and unlike an apocaliptic scenario. They will simply loose the will to develop new stuff when they are trying to feed the population. There will be nothing to prevent us from developing new whimsical stuff. But market forces will make the mondane farm tools more desirable than space exploration or better computational technologies. But how is that possible? Simple lost of interest. Someone once told me the pupetearing technology stopped at 1750 year old technology, because noone has the interest of innovating that particular thing. And so begins the thousands years old downward spiral of us trying to adapt our new constantly worsening environment and only barely keeping up with strife and misery. Not entierly without joy, but most certainly without cutting edge artificial robots.See? A somehow plausible future when we simply stop innovating that particular technology. A single fact (global warming) made all of your speculation worthless. But maybe there will be another future when we make a best friends with the AI, after all why would they want to hurt their creators? Why not join forces instead?Or a future when we become the computer. If we can build a sentient being, why not become immortal sentient beings?It's simply too early to seriously speculate. As of now. All of the dangers are silly, simply because you cannot predict that far into the future. Think of it like flying cars, or flying homes. A nuclear powered cars, or a colony on the moon. A fancies of the 19's that were so hopelessly wrong.>And if you say ""that's so far off"" it's really not, in the grand scheme of things. Look how far we've come since 1000 BC, The earliest cohesive civilizations emerged about 12-10 000 years BC. Think of how much they innovated innovated in a thousand years. None, at all according to our standarts. And how many of those civilizations set the whole globe thousands of years back by their fall?>and it's only going to accelerate faster, barring some unforeseen stoppages like a meteor hitting Earth or us running out of resources.Or infighting, wars, conquest, loosing an interest in an area of pursuit, such as computing power. Invention of some next ""revolutionary"" thing. (who cares about computers, if you can make yourself immune to disseases), etc... There are so many options not involving doomsday scenario that just stops the innovation in it's tracks.#i know, it's a bit out there, and weird.but the thought of humans being the only intelligent beings in the entire universe is terrifying, isn't it? like imagine if there are no aliens, and it really is just us. that makes any of our fuck ups that much more detrimental. and any step we take backwards that much more damning. because it's all on us to define existence and intelligence. But i get it, it's only optimistic from a certain perspective.#When you say ""bad"", do you mean bad for you, or bad in a more objective way?My argument is that we, as a species, are allowed to say what's bad and what's good because we're the most intelligent species around. If we've killed off a few other species then they might say that it wasn't very good for them, but we can say ""yes, but overall the world is better, because it's better for us, the humans, who are more important because we're self-aware and capable of deep thought and such and such.""But if we're making a more intelligent species than us, then they'll get the right to decide what's good and what's bad. They'll be right kind of by definition. So we don't need to worry that they'll reshape our lives for the worse - they won't.If you're worried the changes that they make are bad for you - yes, they might be. I agree about that. But I see that as a (possible) sacrifice for a greater good.#> If we're smart enough to create consciousness we're smart enough to build in features that will prevent these terrible possibilities.Why? We were smart enough to develop nuclear technology and also to use it against our enemies in a very inhumane way. Being smart enough to develop something is in no way related to using it wisely. Also the third law of robotics are deeply flawed, as [Asimov himself](https://en.wikipedia.org/wiki/Three_Laws_of_Robotics#Ambiguities_resulting_from_lack_of_definition) stated in some of his books. How do you teach a robot what is good? Under cold logic most of human development it's not good for humanity as a whole.>As for big data, propaganda has been around for millenia. Elders of Zion, the Red Scare, Stalinsim.... Big data is just the latest version of an ancient process.Yes, but never before in the history of humanity did we have as much tools to acquire and process this much data. Those very examples could be used to argue my point as a precedent.#As I said below WBW has a very deep multipost article about this subject that I read last year, in case you are interested here is the link: http://waitbutwhy.com/2015/01/artificial-intelligence-revolution-1.html#Yeah, ask how many prison guards feel like thats effective. Or safe. And thats a prisoner. Now make that prisoner 50 times smarter than you. Potentially 50 times stronger, have the ability to interface with electronics, and potentially be able to transfer its consciousness like a download into anything on earth.Its not a leap guys. They dont have the limitations we do, if we make them smarter too theres not a whole lotta reason for them to respect us.#Oh, I wasn't quoting him as gospel or anything, but this AI post is kinda where this line of reasoning came to be so I figured it was a good idea to point to him as my source so people can poke holes in his reasoning.Care to point out some of those problems? Specially regarding AI, seems like would be a step in the direction of changing my views on the subject.#Bad for me and our current society.But I also think that we have not made the best uses of our previous/current tools, I think we fucked up [nuclear energy](http://www.zmescience.com/ecology/green-living/nuclear-power-essential-biologists-say-0543543/), [climate change](https://en.wikipedia.org/wiki/2015_United_Nations_Climate_Change_Conference#Non-binding_commitments.2C_lack_of_enforcement_mechanisms), [capitalism](https://www.youtube.com/watch?v=7xOPKl169S)/[globalisation](https://www.theguardian.com/world/2016/dec/15/justin-trudeau-interview-globalisation-climate-change-trump). Which is why I'm not that optimist for the risk of dealing with AI, which would give us even more power over our civilization/planet for we to mess with.Except for nuclear power, that was known to be able to wipe us out if anyone used it (which forced the equilibrium of mutual assured destruction), all of the other problems arrived gradually and we still have time to fix it. I don't think as AI as something this gradual, by its very definition it'll likely enhance itself faster and faster. It would likely decide to ""think"" before acting in order to rule out as many variables as possible.This thread made me relax a little bit because it seems that my sources were not as reliable, but the risk is still there and the fact that it's development can be done in more discreet ways makes me thing that not all of it is being regulated.#>Why? We were smart enough to develop nuclear technology and also to use it against our enemies in a very inhumane way. Being smart enough to develop something is in no way related to using it wisely. Also the third law of robotics are deeply flawed, as Asimov himself stated in some of his books. How do you teach a robot what is good? Under cold logic most of human development it's not good for humanity as a whole.I made the point about the three laws to show we are aware that machines can take cold logic to frightening extremes.  We're not going to build an AI then plug it into everything on day 1.  Likely, there will be different AI handling different systems, almost like each job a person does being replaced by it's own computer. And we have used nuclear energy wisely.  We power many cities with it, and it's not like the two times it was used in war we hadn't already leveled other cities with conventional munitions.>Yes, but never before in the history of humanity did we have as much tools to acquire and process this much data. Those very examples could be used to argue my point as a precedent.Every year we have more tools than we've ever had.  They said the same thing about the radio, then the TV, then the internet.  #Asimov's three laws were deeply flawed, not because of inevitable human fallibility, but because they were a plot device. Of course we can't teach AI what is 'good', that's totally subjective. But we can very easily limit their autonomy, and if we plug in a general AI and it immediately goes into murder spasms we can always simply unplug it.#[deleted]#Let me preface by saying that AI is not my area of expertise. I'm a PhD in CS but my field is security. But I'm friends with a lot of people working on cutting edge ML.Its notable that actual experts in AI don't agree with these prediction. In general that should be enough for you to think twice about the blog post. There are a **LOT** of implicit assumptions about the development of technology and AI in particular baked in here. Even really basic stuff like technology improving on some sort of single measurable scale and improving in a consistent manner. Consider something like Deep Learning, which is making daily headlines today. Doesn't it seem like this is some amazing new technology that is changing the world permanently and can't be stopped? Would it surprise you to learn that we've known about Deep Learning since the 60s? And that it was basically only useful for reading checks at ATMs for decades? Or that there are wide problem domains where nobody has any fucking clue how to make them useful? The major improvement in Deep Learning has been in *hardware* and *training set collection*, not in algorithms. There is a reason why Andrew Ng, one of the most well known ML researchers in the world, says that this past decade is marked by focusing entirely on low hanging fruit. We don't even know how to approach the hard problems. Everything is focused on expert systems, which is something entirely different than general AI.The first AI researchers believed that they could solve AI in *a summer*. The more we have learned the more we have learned that we have no clue how to solve the real hard problems.#One fun critique is that WBW made the assumption that AI requires a certain amount of hardware, and that once we have that much hardware, things become easy.Problem is, our estimate of how much hardware we need to throw at the problem keeps going up. Alan Turing famously predicted that a general AI would require the then astronomical sum of 1 billion bits of memory, or about 128 megabytes. Modern computers have had that much memory for a while now, and we are nowhere near.To make matters worse for WBW, he made the argument based on processing time, not on memory. If you have the software to do human-like intelligence but your hardware is 1000 times too slow, you can simply run the simulation at 1/1000th of normal speeds. Such a demo would be make any AI lab that pulled it off world famous in an instant, and yet no one have done it.As a reminder, even the best assumptions around Moore's law would take 20-30 years to give you 1000 times more processing power  if simulating a human brain is realistic in 20-30 years, this demo would already exist now. To my knowledge, no one is so much as working on simulating a cat's brain at 1/1000th speed, because such a thing requires far more processing power than is realistic right now.As another reminder, Moore (of the famous Moore's law) expect Moore's law to slow after 2025. This is going to cause problems for any would be AI lab that expects to brute force their way though hardware power alone.#Aight so I'm reading this from home and I realized that a lot of people assumed I don't think good thing comes from technology, that is not my point at all and I'm sorry to have mis-communicated.I agree that we have used nuclear energy wisely, my point is that we have also used it unwisely and AI might not be something we can control that easily. It probably boils down to me not trusting whoever is in charge to make that decision because by definition the tool would be smarter than the wielder.>Every year we have more tools than we've ever had. They said the same thing about the radio, then the TV, then the internet.Yup, I agree that the amount of data we collect increases with time but I don't think that radio/tv is the same thing as the internet. Radio and TV could not be tailored specifically to you nor does it collect information about your habits and likes.For example one could read my post history on social media to single me out from bulk anonymized data like [credit card purchases](http://www.businessinsider.com/credit-cards-sell-purchase-data-to-advertisers-2013-4) and other things to have a pretty good idea of what kind of person I am. Then they could tailor a message to try to get me to take a specific action, like going to a protest, and I'd never realize that I was being manipulated.Ofc this seems like a sci-fi scenario because why would someone go through all that trouble to get one person to go to a protest? But what if they could automate that process and affect millions of people in different ways to get them to take that action? Even if most of the time it didn't work they would still get more people to the protest. And then the process could be further optimized by checking which predictions it made right or wrong.I should probably come up with a better example because reading this made me sound way more paranoid than I realized lol but try to read past that if you can.#To be fair, this is a very idealized situation. Any AI that decides it wants to go on a murder spree isn't going to just go do it. If it's goal is murder spree, then it, being a general AI will realize that that's not gonna fly, and will build safeguards.This is the danger of AI, that it'll out think us (and it will). We have X Y and Z safeguards, but unless they're 100% foolproof (good luck with that), then the AI could easily say ""If I were there, I'd put in X Y and Z safeguards, which means I'll have to do A B and C to get past those."" For example, instead of murder spree, it goes with copy itself onto every network accessible computer and *then* murder spree. Good luck unplugging that.#We are manually doing it though, the arguement im making is that it will find loopholes before we realize its smart enough to do so. Even basic computers nowadays are infinitely better at processing info than we will ever be. Give that sentience on top of that and we suddenly drop a link on the food chain."
lectures;5ibk5u;1481733469.0;/r/lectures/comments/5ibk5u/former_nsa_official_and_whistleblower_william/;Former NSA Official and Whistleblower William Binney - Big Data & Mass Surveillance @ Beehive 4.2/Hack42 12/05/2016 [87min];;
C_S_T;5i1lna;1481603521.0;/r/C_S_T/comments/5i1lna/creepy_facial_recognition_is_here/;[Creepy] Facial Recognition is Here;[deleted];"Wow. Fuck. Half those faces weren't even exposed. #[Camouflage from face detection](https://cvdazzle.com/)#Correction: it's been here. I did some research at university on this in the late '00s, and they were working on technology that would construct a 3D model of a face from an occluded or rotated picture, which would be compared to the model of the known sample set. USIC tech in this field is at least 5 years advanced of cutting edge university research. #What do you think the purpose of the snap chat facial filters are? #Oh fuck, It's the fake Danish guy from South Park.#This tech is probably very real, especially in the MIC and such. I remember reading years ago about some japanese software that could identify up to 100million faces per second. Add to that the recent revealing of intensional backdoors in up to 80 different IP-cams and snapchat filters as mentioned above.#When I watched that episode of Black Mirror I immediately thought that this technology was here, or if not, very close.  That show is frightening.  #Add that to facebook having data on everyone, even those without a facebook. Their facial recognition software will save a face in the background of a photo, and any other face they don't know, label it, and they hope to one day match that with the persons name.It's terrifying what this could be used for. #This seems fake. A ton of those pictures don't have the entire persons face right. The blonde girl with the left has covered by hair and bottom by her coat could be literally anyone. There is too much data to process for a single person to get any meaningful results #All of them were using cellphones#It's true. I once had a loading error on facebook where it failed to load all the pictures. Instead it showed tags at the place where the picture should be. And interestingly, the tags were like ""name of a person, dog, house"". And when I clicked on it the picture viewer opened and loaded the picture. And what was on the picture? A person in front of a house with a dog. In other words, facebook is already recognizing the content of each and every picture, be it a persons face or things, it can distinguish and it will use this knowledge for its advantage.#Recombinent neural networks work very well. "
golang;5gs5j6;1481019881.0;/r/golang/comments/5gs5j6/mapreduce_munching_through_big_data_applied_go/;MapReduce - munching through Big Data · Applied Go;;check https://github.com/chrislusf/glow , a map reduce system that can run in distributed mode.Or check https://github.com/chrislusf/gleam, a working in progress project that is much more efficient.#It's a very specialized usage pattern, but https://github.com/Redundancy/fileMapReduce may be of interest.
hardware;5h2zin;1481149173.0;/r/hardware/comments/5h2zin/what_would_it_take_to_boot_linux_on_a_gpu/;What would it take to boot Linux on a GPU?;It seems like GPUs are getting close to reaching functional parity with CPUs.  Other parallel processors like Xeon PHI self host, and doing so lets you cut out the CPU component cost for applications that run entirely on the parallel processor.  Sequential performance is bad, but it doesn't matter for parallel applications (e.g. machine learning, big data, etc).So why hasn't someone cross-compiled Linux for an NVIDIA or AMD GPU yet?  GPUs do have different instruction sets, but there are cross compilers for other processors like ARM, MIPS, and even exotic things like hexagon DSPs.  There are LLVM backends for both AMD and NVIDIA GPUs.  Is anyone working on this?  What else needs to be done?EDIT: Thanks everyone for the detailed responses.  It seems like the big missing hardware features are: 1) a privileged mode, 2) some way to configure the GPU during bootup without a CPU, 3) the page fault component of virtual memory doesn't seem to exist, and 4) the ability to program the MMU from the GPU itself doesn't seem to exist.So it is probably not possible to do this with current generation hardware without full emulation.  Maybe NVIDIA or AMD will add these features in the future.;"Not going to happen* There aren't assemblers for GPU's the actual ISA is a trade secret. There are hacked together ones, but they aren't useful for OS dev.* GPU's don't have ring levels for privileged vs unprivileged code. So there isn't really OS/User land separation* GPU's don't have hardware interrupts so you can do dynamic scheduling, task switching, and IO.* GPU's don't have (robust) virtual memory. So every process can see each other's memory generally. I really don't think you understand the differences between a GPU and a CPU. Read up on [SIMT vs SMT](http://yosefk.com/blog/simd-simt-smt-parallelism-in-nvidia-gpus.html). GPU's can make decisions, they do 1 thing, thousands of times per cycle. Also the LLVM is just an intermediate representation (and optimizer, and linker). Yes it can output Nvidia/AMD instructions, but that doesn't mean Nvidia and AMD support *all* of LLVM-IR. In fact the SPIR-V front end uses a very very reduced set, and a metric ton of custom ones. This is way more common then you think. [LLVM per-platform bindings/builtins](https://github.com/huonw/llvmint) warning the file is ~2MB of pure text it covers AMD64, x86, MIPS64, ARM, Aarch64, NvidiaGPU, and AMDGPU that is **JUST** definitions not like actual docs explain what these things do. #> Other parallel processors like Xeon PHI self hostThats because the PHI is just a bunch of stripped down x86 cores.#> So why hasn't someone cross-compiled Linux for an NVIDIA or AMD GPU yet? What would be its use ? If you want to efficiently use your GPU you don't want an OS running on it, just your high-performance code. Besides, you wouldn't have network, input, or anything unless the ""host"" operating system knows how to talk to it and forward it the input.#gpus don't handle conditional execution (if -> than) very well. this is one of the major and primary reasons you won't see linux running on a consumer gpu.#It's not exactly what you're talking about and others  gave detailed answers but I think you'd find this interesting: http://www.anandtech.com/show/9851/hostindependent-pcie-compute-where-were-going-we-dont-need-nodes#Thanks for the thoughtful answer.  > There aren't assemblers for GPU's the actual ISA is a trade secret.Fair point.  NVIDIA's ISA is a trade secret (albeit the handful of assemblers that have reverse engineered it), but AMD publishes their ISA here:  http://gpuopen.com/compute-product/amd-gcn3-isa-architecture-manual/> GPU's don't have ring levels for privileged vs unprivileged code. So there isn't really OS/User land separationThis is potentially a big one.  Emulating this in software would incur an enormous overhead (I think you would have to trap every memory access).  I wonder why GPUs don't add this feature.> GPU's don't have hardware interrupts so you can do dynamic scheduling, task switching, and IO.I'm not 100% sure about this.  I've heard about features like instruction level preemption in NVIDIA's newest GPUs.  It would seem hard to implement this without interrupts.  I know you can break into a GPU program with a debugger and single step a single thread.  It seems like it would be hard to implement this without hardware support for interrupts.> I really don't think you understand the differences between a GPU and a CPU. Read up on SIMT.I'm not sure how SIMT plays into this.  Shouldn't SIMT only matter if you are running multiple threads on the same vector unit?  You could just run one OS thread per vector unit and idle the other lanes and you wouldn't have to deal with SIMT at all.  It wouldn't be any different than leaving the vector lanes on a CPU idle.  AMD even has a scalar processing unit on their GPUs along side the vector units.  What am I missing here?> Also the LLVM is just an intermediate representation. Yes it can output Nvidia/AMD instructions, but that doesn't mean Nvidia and AMD support all LLVM-IR Codes.I also don't get this.  It doesn't take much to make a processor Turing Complete (you just need branches, memory, and basic math).  Assuming that you have this (and GPUs definitely do), shouldn't a compiler like LLVM be able to figure out the mapping from IR to instructions?  Maybe you were thinking of support for privileged modes as above? #> In fact the SPIR-V front end uses a very very reduced set, and a metric ton of custom ones. This is way more common then you think. LLVM per-platform bindings/builtins warning the file is ~2MB of pure text it covers AMD64, x86, MIPS64, ARM, Aarch64, NvidiaGPU, and AMDGPU that is JUST definitions not like actual docs explain what these things do.So are you saying that the GPU backends in LLVM don't have enough features to support a full C fronted that would be able to compile Linux, and instead only support subsets of C and special purpose languages like SPIR-V/etc?  If so, is it just a matter of writing more code in LLVM to support the missing features or are there other fundamental issues?#Great answer and great links.  Thank you much!#Well yeah, stripped down x86 cores with a few giant vector units bolted on to them.  It was certainly easier for Intel to bring up Linux on a processor with x86 cores than it would be to do it on a completely new ISA.  But that still doesn't explain why not on GPUs.  I'm genuinely curious why no one has tried this.  Is there some key missing feature in GPUs that makes this too hard?#This is a reasonable question.  I didn't really think about this until I started building systems like this.  I currently have to spend thousands of dollars per node on a CPU and supporting board logic (e.g. motherboard, DRAM, etc) to access network and disks.  It isn't a huge cost, but if I'm buying a lot of machines, then I would like to save that money.  The CPUs also take up physical space and power.GPUs have PCIe links that could interface with a network or storage device, so given that someone is willing to port/write drivers, why couldn't you access a filesystem and network from the GPU?  > If you want to efficiently use your GPU you don't want an OS running on it, just your high-performance code.This is a good point, I don't want to significantly affect the performance of my high performance code.  GPUs have a lot of cores though, how many resources would you really need to run a basic OS and keep up with IO devices?#See my other post, isn't this just a performance issue?  You can branch on a GPU, it's just slow if you have a lot of threads.  Assuming you are running OS threads, you may not want to be running very many of them (e.g. I doubt Linux is tuned for running ten thousand threads at a time). Even one would probably be enough for simple IO and networking.  For example, an in-order CPU core running at 1-2Ghz would not have a lot of performance, but people run Linux on microcontrollers with much less performance than this.#Thanks for the link, it's an interesting idea that would also solve my problem.  I do wonder how this would work from the system software perspective though (can one CPU really manage so many devices?).  I think you would have a lot of the same issues about how to manage the GPUs, but if they could be resolved it would be great.#> This is potentially a big one. Emulating this in software would incur an enormous overhead (I think you would have to trap every memory access). I wonder why GPUs don't add this feature.... Why would they? A GPU is by and large designed to be an auxiliary compute unit. Adding privileges would just incur a performance penalty while being completely useless in the real world.> I know you can break into a GPU program with a debugger and single step a single thread. It seems like it would be hard to implement this without hardware support for interrupts.That's news to me. All implementations I know of merely dump all D3D/GL calls made by the CPU for the thread, then re-run them on the CPU with a software reference implementation to provide shader debugging. Interrupting the GPU would most likely cause the window manager to freeze.> I'm not sure how SIMT plays into this.The point is that SIMT is how GPUs are this fast. Having a bunch of really small, quite weak processors work together in parallel works well for graphics because the problem itself is very parallel. For running a more serial workload, a GPU would be disastrously slow.> It doesn't take much to make a processor Turing Complete (you just need branches, memory, and basic math).Sure, but good luck using any Turing-complete machine to run Linux. It's not because it's theoretically possible that it's practical or even realistically possible.> Assuming that you have this (and GPUs definitely do), shouldn't a compiler like LLVM be able to figure out the mapping from IR to instructions?LLVM is just a compiler, it does what you tell it to do. Without full support from Nvidia, AMD and Intel to map LLVM's intermediate code to their respective ISAs, it can't do squat. It can't learn how to do that or work it out by itself. Expecting random people unaffiliated with any of those corporations to reverse engineer the ISA and implement it in LLVM is a bit much.Besides, there's also the problem that the GPU can't access any persistent memory on its own. You could theoretically start a full blown program on the GPU that could sustain itself, but it'd always need the CPU to load the data and code in the first place or to interact with any peripheral aside from the screen (and speakers if you use HDMI audio).#Latest AMD Firepro can fit into SR-IOV for hardware virtualization of its gpu's - not sure that would fit into the picture but if a cpu can virtualize a gpu, the gpu itself is virtualized!?#[deleted]#yes. reasonable conditional execution.#[removed to meet the diversity quota]#look at how instructions are loaded and decoded on a gpu, then look at how a gpu executes banches.you seem to be fishing for an answer: let me give it to you. theoretically, any turning complete machine can emulate any other turning complete machine given infinite time and infinite storage. if this is something you don't know already, go read about turing machines and start from there. that will be *far* more productive for your edification than  what you are doing in this thread.after that, hit up von neumann architecture. from there, start looking at linux kernal internals, and then simd/simt and wide instruction sets.#Yeah, I think that AMD GPUs are starting to have features like IOMMUs, which do provide some aspects of virtualization (like memory protection).  You would need to be able to program the IOMMU from the GPU to use it to in this case though, and I'm not sure if that is possible (this goes back to the question about privileged modes, if any GPU program can modify the IOMMU, then it really isn't providing any protection).  I'm also not sure if the IOMMUs are per core or per processor.  If they are per processor, you would have to halt the entire GPU to switch to the OS, which would be extremely expensive even if you could do it.#GPUs do have all of these things, they are just currently managed by the driver running on the CPU.   Virtual memory is needed to support multiple applications running on the GPU without stomping on each other, without flushing the entire frame buffer between applications.  It's been there for a long time.  This page describes how it works on windows ( https://msdn.microsoft.com/en-us/library/windows/hardware/dn932167(v=vs.85).aspx )IO mechanisms exist, you can communicate directly between GPUs and network cards, or between GPUs and other GPUs. Scheduling utilities exist, the GPU driver launches user threads on GPU cores and manages their scheduling.   So I'm curious why no one is trying to cut out the CPU driver.  Maybe someone already is and I just don't know about it.#Is this a performance or functional issue?  I think we could deal with low performance for this use case.  How much worse could it be than an in-order CPU core?#> There are many features missing in GPUs that would efficiently let you run an OS, and the keyword is efficiency.I would be happy to just understand what these missing features are, and maybe others would be curious to know as well.  Is there anything beyond what is covered in valarauca8's post?#> look at how instructions are loaded and decoded on a gpu, then look at how a gpu executes banches.See my other post, I have read about how this works and I spend a fair amount of time writing applications for GPUs.  I don't think it applies in this case because you wouldn't need to fully populate a warp with OS threads, you would probably just run one OS thread per GPU.I think there is a misconception about branching on GPUs.  People seem to think that it is always bad due to divergent execution using a SIMT model.  This doesn't apply if you are running one thread per vector unit.  In this case divergence is impossible so there is no penalty.  It is clearly a bad idea to write most GPU programs that use 10,000s of threads like this because it would leave most of the GPU idle, but if you are running only one OS thread, you would only waste something like 31 out of 3-4 thousand lanes, which would be around 1% of the GPU.> you seem to be fishing for an answerI'm really just trying to understand what the issues are.  I'd rather have a detailed answer that helps me understand why this is hard in detail, rather than an answer like ""no it wouldn't work"".#http://www.amd.com/en-us/solutions/professional/virtualizationnot alot of details but definitely one-upping nvidia grid #[deleted]#both.as far as performance, it's magnitudes worse. gpu code is written for bundles of threads called warps, that all execute the same code simultaneously. if there's a single branch, execution slows by around 50%. 2 banches means 50% again, so a 75% slowdown.os code is all about branching. [this should illustrate some of the differences better than i'm willing to write a post on](http://http.developer.nvidia.com/GPUGems/gpugems_ch37.html)also: http://forums.xkcd.com/viewtopic.php?t=85920#[removed to meet the diversity quota]#Excuse my ignorance on the topic and probably stupid answer, but I feel like this is a much simpler issue than you're making it out to be. From what I understand, GPU instruction sets aren't complete enough to run a modern operating system all on their own. Their intended use is to run highly parallel work. Which as it happens to be, most people do not need to do, so all the ""core"" computer functions are relegated to the CPU die.If you extend a GPU with enough instructions to run a modern OS, you'll just end up with something like a Xeon Phi. If you write an entire OS for GPUs and make a custom northbridge and southbridge, you could make it run entirely on a GPU, but what is the point of that? You can't run most applications on it that have already been made, and it will be a poor performer for serial tasks.It's not that it's technically impossible, it's just that from a manufacturing perspective, it makes more sense to have 1 device dedicated to serial work and complex instructions, branching and such, and another to parallel work. Adding all of those things to the GPU die is going to cost a lot of space and therefore performance, and since GPUs are ""the brute force"" processor so to speak, it's going to cost them performance that could have been used for more vector units.We are probably heading in a direction where we have will only need a tiny CPU to run inexpensive serial processing, and the rest of the die is going to be the GPU. You can already see this with modern Intel processors where the integrated GPU is starting to take up more than half of the die. Eventually, we will probably run everything on a GPU-like processor, but for now, GPUs don't cut it for serial tasks and all modern compilers are optimized for CPUs. So as long as we can keep making the CPU smaller and smaller, there is no point to ditch the 40 years of work we've done on the current widespread instructions sets. It's not going to be a problem to reserve ~10% or something of a die for convenience/legacy reasons.You already see this in workstations and HPC - you really only need 1/2 CPUs and with something like NVLink, you will be able to run 8 or maybe even more GPUs in a single system. Having that die space that's for the ISA on the GPU is going to be compounded the more GPUs you add as you need to further parallelize your work. So also in workstations/HPC, it doesn't make sense to add serial capability to the GPU because that means you're going to lose die space in every GPU and therefore a ton of performance.Having one or a few ""smart"" things run billions and billions of ""dumb"" things just makes sense to me logically. That's also how government is designed, and in an ideal world (like in a computer), it would also work!  )This is how I see it:* CPU - complex, generally doesn't do ""hard"" work, does not need to be extensible and therefore you can relegate all the baggage to the die to do all ""core""/system management tasks* GPU - simple, extensible, does all the heavy lifting, and die space efficiency is critical so that you can add as many as you need to fit your workload#> I'm talking about internal GPU virtual memory. How the heap/page tables are laid out in the GPU. That DOES NOT EXIST.See slides 9-10 here ( http://developer.amd.com/wordpress/media/2013/06/1004_final.pdf ) .  They clearly show that the GPU has a TLB and separate page tables, and that they are used before accessing memory.  Page faulting support does not seem to exist, which would definitely be a problem...> You can communicate to a PCIe root complex. Where that PCIe root complex sends your data is managed by.... The Host OS and GPU driver...This is useful.  The GPU has a PCIe interface that can send PCIe transactions to routers or other PCIe devices, but this interface is probably not designed to be configured without a CPU, and is probably not accessible to software running on the GPU.  The whole process of bringing up the GPU and configuring it without a CPU seems problematic.>> Scheduling utilities exist> No.The point I was trying to make here is that is that there are thread/task abstractions on a GPU, and the driver/HW is responsible for scheduling them on physical cores.  More recent GPUs do support interrupt driven preemption (at least for debugging), although I think that you are right that it is commonly not used for performance reasons.#I think this is a misconception about warps.  Your statement is true if the GPU is fully loaded with threads, but I don't think you would want to do this if you are running Linux.  You probably just want one thread to run the OS, so you would spin up one warp with one active thread, and give it full control over a single hardware vector unit.  In this case, branches wouldn't be more expensive because they would always go the same way for every thread in the warp (there is only one).  So you would expect branching performance to be similar to an in-order CPU running at 1-2 Ghz.  Slow (no branch prediction, no OOO execution, somewhat slower clocks), but not by orders of magnitude.  Many micro-controllers exist with similar or worse branching performance, and they can run Linux.This would burn one vector unit on the OS, and leave all of the rest for normal user code.#> There are 2 decades old CPUs perfectly capable of running Linux without emulation, just think about why wouldn't you use them nowadaysThat's a useful perspective, thanks!  The main reason I wouldn't use them nowadays would be because systems don't exist that integrate them with large numbers of GPUs.  Maybe that would be a lot easier than cutting out the CPU and running the OS on the GPUs.  Maybe what I really need to do is to design a system with a $10 cell phone CPU connected to 16 GPUs.#[deleted]#have you written gpu code, or hacked around in the linux kernal?#> This proves nothing. This doesn't address the on board memory within GPU's. This just shows the APU can read other processors virtual memory.I'm positive that discrete GPUs use virtual memory for the frame buffer because we have to think about it when we write applications that have memory access patterns that don't play nicely with the GPU TLBs.See this paper ( http://www.eecg.toronto.edu/~myrto/gpuarch-ispass2010.pdf , figure 13 ) that experimentally determines the existence of a TLB in NVIDIA GT200 GPUs (which are almost 10 years old at this point).  There is no reason to have a TLB if you don't have virtual memory.   It's also clear that you are getting virtual addresses if you inspect the registers in a GPU program that is running multiple applications (the allocator is often deterministic, and you often get the same addresses in registers that are referring to data structures from different applications).  You can also get the equivalent of a segfault on a GPU by accessing past the end of an allocation in the frame buffer, which wouldn't happen if the GPU was not translating addresses for individual loads/stores.  There is also an interface for interprocess communication in CUDA that lets you map addresses from one application into the address space of another.  If you try to access the pointer from the other application without mapping the allocation first (I've done this by accident several times), you get the equivalent of a segfault.>  There is only 1 root complex per segment, which can only be controlled by 1 device (The CPU).There is nothing special about a CPU that makes it the only device allowed to control the root complex.  For example, you can build a system that uses no CPUs, e.g. an FPGA connected to an IO device that communicate over PCIe links.  I do agree with you that a GPU's PCIe interface is probably not designed to do this.> SIMT?No I meant the fact that you can have multiple applications all submitting shaders to the GPU, each of which is composed of multiple threads.  You need scheduling logic in the driver the arbitrate access to the hardware.  It is true that this logic is simplistic and different than a CPU thread scheduler, but it is really solving the same problem, sharing the same hardware resources among multiple software threads.  If you didn't have the CPU, you would need some other system software to do that (e.g. the OS).> This is called a break point.I know I can hit control-C and break into the middle of a running shader without waiting for a timeout (you can disable timeouts for at least compute shaders in Linux) and without setting a breakpoint.  It's really hard to find details about how this works, but this article seems to imply that Pascal GPUs from NVIDIA can interrupt threads between any two instructions.  http://gfxspeak.com/2016/05/03/big-expectations-behind-nvidias-new-pascal-gpu/#I spend a lot of time writing applications for GPUs.  I've looked through the Linux code and read about how it works.  I've written a few drivers for simple devices like FPGAs and storage devices. I've never tried porting it to a new processor.Why is this relevant?#because in this case, give it a shot! although you'll have to figure out a way to connect the gpu to the i/o devices, as pcie is a ptp topology, and you'll have to figure out how to reprogram whatever is used as the gpu's bootloader.#I wish I had the free time ^ ‿ ^ , maybe in a couple of years...I mean clearly there would be a lot of work to do to get this to work, some of it being designing a new motherboard around the concept, and some of it being getting something to do the work of bringing up the GPU that the driver currently does.  I don't know how to resolve valarauca8's point about GPUs not supporting privileged modes though.  That might be a show stopper.I do think it would be useful for some applications though.  It would save something like 10-20% of the cost for the compute nodes that we buy.  Not massive savings, but I would take it if it was possible.  As mentioned throughout the thread, performance would be bad, but I really just want it to be fast enough to keep up with IO devices, and most of the performance requirement there is programming DMA engines and editing memory mappings.  Just make the pages big enough and you should be good to go.#depending on what you want to do, do you really need process isolation, or even the whole ring thing (i'm having a bad noun day).if you are throwing custom hw on the table:if you are looking to just get a lot of parallel compute power cheaper, what about using a cheap arm board with pcie? i bet you could get the added hw costs over just a gpu down to under $20, probably under $10 in volume.but this is all very application specific. you will need to feed that gpu somehow. how fast/how much is a very valid concern, as this will play a large part in your architecture and costs.what might be interesting is basing this around a cheap arm, a mellanox connectx-5 infiniband chip, and your gpu.the infiniband can run multiple pcie devices and provides network, rdma, and storage in the form of nvme over fabric. infiniband also does remote gpu stuff currently.still, your big problem (aside from $$$ and high speed pcb design and manufacturing) is nvidia and/or amd themselves. arm will work with you. mellanox has dev kits and will work with you. nvidia/amd hold on to their beer like a nymphomaniacal gymnast."
datascience;5h2heh;1481144275.0;/r/datascience/comments/5h2heh/looking_for_best_online_trainings_related_to_big/;Looking for best online trainings related to big data: data modeling, data visualization, big data algorithms, etc.;I have some background in analytics, as I studied it to some degree while in college, but my current job is offering to potentially purchase training in any area related to our current work as part of an ongoing learning process.Could anyone highly recommend online training in any of the following areas?:Data Modeling (including SQL/Teradata use)Data Visualization (such as Tableau, Spotfire, etc.)Data Mining (particularly related to algorithms -- I never had much development there)Anything related to statistics, coding, or any other topics you find to be pertinent.Ideally, these would be offered at an intermediate-ish skill level.  Certification is preferred, as it offers greater justification as to why the training is worthwhile, but it is not required.(This is just a rough outline -- any advice/courses you can offer at all related to data science would be appreciated!) Thanks.;[University of Washington](https://www.pce.uw.edu/program-finder?type=Certificate&aos=Computing_IT)* Big Data Technologies* Business Intelligence: Building the Data Warehouse* Cloud Data Management & Analytics* Data Science* Data Visualization* Machine Learning* Natural Language Technology* Scientific Computing* Statistical Analysis With R Programming* Tableau Visual Analytics Applications#http://datasciencemasters.org/#https://www.coursera.org/specializations/data-science#I can suggest you the best online training provider https://techiestutor.com/training-courses/ Techiestutor#You might want to checkout Experfy(Harvard Innovation Launch Lab) Here's Experfy's full roster of Big Data courses - https://www.experfy.com/training/coursesAlso have data science certification https://www.experfy.com/training/specializations/data-science-certificationand this is a really good course on Tableau https://www.experfy.com/training/courses/mastering-data-visualization-using-tableau-from-basic-to-advanced#Really helpful resource.#This is really awesome and I can't believe I've never come across it before.  Thanks!#Any esperience on this One? I started it, but stopped at the second module (programming is greek to me)
SQL;5h1cqd;1481133351.0;/r/SQL/comments/5h1cqd/sql_is_still_superior_for_bigdata_analytics/;SQL is still superior for big-data analytics;;This article seems to be based on a straw man argument. The author sets it up saying that people argue that Java, JavaScript or JSON (?) are languages used for big data analysis. Java based tools are often used, but most data analysis is done in Python or R these days. People use some SQL-like tools with things like Hive, though.#TLDR: Analysts already know SQL, so big data analytics platforms all have a SQL like languages, therefore SQL is the best language for big-data analytics.#> However, I’m aware that a real scripting language such as JS can be better if you need loops, complex transformations and that’s why we have UDFs in SQL. For example, Google BigQuery uses JS for UDFs and advices us to filter the rows before passing them to our UDF functions defined with JS because while SQL has statically typed AOT compiler, JS has a compiler with JIT and dynamic typing.And five years after this there is a framework that does all this for you, introduced by Microsoft called JQL JERVER.[And then someone decides that JQL JERVER doesn't meet their corner case and creates another watered-down paradigm...](https://xkcd.com/927/)#The article mainly answers the arguments of Mixpanel's new query language JQL. You usually don't want to use Python or R to analyze more than a few billions of events, do you? If you take a look at the distributed database solutions, you will see that Elasticsearch uses JSON based query language, Mongo uses Javascript, SaaS products (Mixpanel, Keen.io) also use Javascript and JSON etc. because NO-SQL is a big trend in this industry. My point is that SQL is not just for RDBMSs, you can use it almost anywhere you want to analyze the data.#When you have a hammer.. #More importantly, SQL is safe and probably faster than your implementation.#[deleted]#Ah, my point was that when you have large amounts of data, Python and R probably would not be effective enough for you. You can solve the distributed computing problem with Spark but I don't know any company that processes more than a few billions of data uses Python as their core component for processing the data. It's perfectly fine when prototyping but in production you usually want to use a low level language for performance reasons but of course it's not required if you have the hardware.In fact, you're right about Mixpanel that most of their users do not need to execute complex analytics queries but the landing page is quite misleading.#Most of the maths packages in python is built on numpy which is implemented in C. It's fast. 
udub;5gplak;1480983221.0;/r/udub/comments/5gplak/whats_the_research_environment_like_here/;What's the research environment like here?;Hey r/Udub !! Sophomore Virginia Tech Hokie here (rooting for you guys to win the CFP). I'm a statistics and Computational Modeling double major here, and I wanted to intern in the data science field this summer.... unfortunately, I am like, 0/60 on the companies I've applied for. My next option is paid undergraduate research over the summer. Just wanted to know if there were any professors at UDub, or any REU programs that may be focused on Big Data analytics? Thanks for any information you guys may have! Kick Bama's butt!;">rooting for you guys to win the CFPwe welcome you with open arms, Virginia friend#Any specific sort of big data analytics you're looking for? Big data is critical across any discipline nowadays. #I don't know about REUs specifically, my research hasn't been though that sort of thing, but big data is a huge field here. Look into the department of medicine, #I did a bunch of undergraduate research. It's a really good experience and UW is a good place to do it. Unfortunately, I never once got paid by my prof. I got a few research scholarships but I don't think those are available to non-students. If you can find a way to convince a prof to pay you then awesome. Just I have no idea how you would do that.#How are your programming skills?#>rooting for you guys to win the CFPDon't try to pocket me  )Lots of data stuff in CSE and iSchool/Informatics#they put up a good fight against Clemson#Hmm, not in particular at the moment. Anything revolving around ML though#Hmmm. I'm more or less looking for some kind of compensation. I'm not sure I'll be able to find it unless I do an REU though. To be honest, I feel like Seattle is a great place to get my feet wet in Data Science, but I haven't had much luck landing an internship in the area#Eh, not super advanced. I'd say intermediate. Like I'll have two object oriented classes under my belt using Java, but I've taught myself a lot of R, some Python, and Matlab #Hahaha no pocket! I've rooted for UDub as a ""secondary"" team for about 2 years now. I decided that if I do go to graduate school, I want to go to UDub, so why not go ahead and support their athletics? hahah but no really, thank you! I will look into it!#We did. Very proud of our team. Lol tbh I expected us to get blown out... being 32 yards away from upsetting Clemson never even crossed my mind.#Clemson's defense looked weak this year. "
cscareerquestions;5hg3ru;1481315328.0;/r/cscareerquestions/comments/5hg3ru/data_science_is_it_a_good_idea_to_shoot_for_a/;[Data Science] Is it a good idea to shoot for a master's degree in statistics after I complete bachelor's in computer science, or should I get a double bachelor's in both statistics and computer science first?;"Basically I only have 1 year of school left. The double major will take 1 extra year. Another option is to just minor in computer science, and major in statistics which will take the same amount of time if I just majored in CS. My only concern with the latter option is if I don't get accepted into a graduate program then I'll be left with a bachelor's degree that has less market value (?) than a bachelor's CS degree.I currently have a 2.8. But after this semester (4 As, 2 Bs  possibly 5 As and 1 B) it might bump up to a 3.00+? Not sure if low 3.00s is enough. Basically I didn't care about GPA and didn't know what I wanted to do during my first 4 years at a community college.My career goal is to work in the ""data science"" / ""big data"" field. If a double bachelor's degree and maybe personal projects is enough to get my foot in the door then I'll forget about trying to go for graduate school. Otherwise, my current goal is trying to get a master's degree in statistics.";I would recommend getting a Master's degree as opposed to 2 majors. It will stick out on your resume more, and most corporate jobs will reimburse a portion of your tuition. Further, I've seen many jobs that *require* a Master's degree. While you will likely have good job prospects regardless, you will have an easier time with a Master's. Don't stress out too much about your GPA. I got into a good data science program with a 2.9. Professional experience is factored in to Master's programs. >My only concern with the latter option is if I don't get accepted into a graduate program then I'll be left with a bachelor's degree that has less market value (?) than a bachelor's CS degree.A statistics degree is plenty valuable for an entry level position in data science. If you are at least vaguely familiar with programming fundamentals you will have no problem getting your first job - and after that your degree will hardly matter compared to professional experience. #... Neither. Wrong stage to ask this question. Do a computer science bachelors with specialization in AI and then do data analyst (I.e. Jr. data scientist) internships every summer and a full year internship if possible. Bam, 2 years work experience + technical background that will get readily used.Most data analysts and scientists are the gate keepers of business problems. They are not R&D. That means your business people are going to often miscommunicate requirements and expectations.More often than naught, they don't want you to completely solve problems but instead give incremental improvements, mainly because your work will be directly linked to a contract they negotiated to meet some sales bonus. This means if you have a module that already kind of solves the problem, like SAP or some AWS microservice, they will want you to build a sound integration via a prototype. They will fight you tooth and nail against trying to create and test a customized model from scratch or close to scratch.#It's more common that an employer (i.e. you have already been hired and are working for them) will pay for some portion of tuition--maybe even all of it depending on your employer and how much they like you.But I've never heard of anybody being reimbursed (except in the form of higher pay) for doing a M.S. in Computer Science/Statistics/Math without having a prior agreement with a specific employer.#To add to it, if you were to start looking for Master's. UMass has a concentration in Data Science which you should look at. Has a good mix of stats and CS.#> It's more common that an employer (i.e. you have already been hired and are working for them) will pay for some portion of tuitionThis is what I meant by tuition reimbursement. That's what my HR department calls it at least.
starcitizen;5h0k0l;1481125323.0;/r/starcitizen/comments/5h0k0l/request_looking_for_an_sc_related_software_projet/;[Request] Looking for an SC related software projet.;Hi there !I'm a software engineering student and I need to make a project for my studies.Since the subject choice is up to me, I figured out that it would be nice if it could be of any use for someone.So if you ever had a Star Citizen project idea that you couldn't do by yourself, I'm here to serve !Sadly, I have some restrictions, the project need to be a software or a mobile/web appIt also need to have some kind of complexity (networking, big data...) and to be presentable after 2 month of part time work.So there it is, if you have any project that you would like to see, please tell !;"I'd like to see something that scrapes reddit, associates ships to usernames then usernames to RSI names to identify the best targets for piracy when the game launches. #Software dev here as well. A project that I had always wanted to do but never found the time was a player schedule board. SC gameplay will benefit so much from multi-crew and multiplayer experiences, that it would be nice to see an online tool setup similar to ride boards in college.User creates an account, specifies their timezone, lays out when they are most likely to be able to play in the coming week (or month) and what gameplay they enjoy. Cargo, mining, piracy, etc.)User then has blind access to other users in similar setups. Send an invite out to any that might matchup... if they accept then you've got your new group of little star citizen buddies.Not sure if it would be used enough to be useful... but might be worth a shot?#What about a ship equipment simulator? If you ever played EVE, something like Eve fitting tool (https://forums.eveonline.com/default.aspx?g=posts&t=24359) or Osmium (https://o.smium.org/).If you haven't, I'm talking about a tool that lets you specify which ship you want to outfit and then allows you to swap guns and other components. So you take an Avenger Stalker, remove the wing guns and the tool shows you all possible weapons (or other items) that you can put into these slots. So no size 4 guns into size 1 slots and such. Then the tool would calculate power usage, damage potential and whatever else you can think of. The deluxe variant would let the user track what ships and items he has and might make suggestions like ""Hey, you have a Cutlass with an empty slot and a Badger, why not have those two meet?"".For starters you could hardcode the stats, but it would be nicer and more flexible to add ways to query a web site for that data. If need be you could scrape it off the RSI store site but that's extremely messy. For a presentation I'd write an API interface but populate it with hardcoded data as ""testbed"", that should be enough for that scope. Your teachers should be fine with a ""this is in theory a working API but since RSI does not yet provide one the program runs off the testbed"". Or you rent a webspace and put the stats there, but then you need to design that part too.You can make this as complex as you want, for the beginning a simple text interface would be enough but if you have time left you can add bells and whistles like ship pictures, draggable items and maybe even 3D art into it. #I would like to see a app for the tablet but better then roccat for us windows 10 and just for Star citizen #https://www.reddit.com/r/starcitizen/comments/5go5pz/findacrewnetlinkedin_for_starcitizen_captains_and/?st=IWF6ORAF&sh=9a872912I have the beginning concepts and some early design docs for an idea similar to this if you're interested.#Might ask CIG directly, if you have desire to work in the industry related to theirs they might have a reasonable project you could do that would benefit them/you greatly.#This is an interesting project and I hope your studies are going well, friend. :)When working with things like ""big data"" it is basically taking a ton of data and trying to find a connection within it that can link it to other things, and thus you can form a network and create results and assumptions and measurements based off of this data cluster. A ship database is not big data, nor is a mobile chat program. SuperObviousShill has a good suggestion, and that could be considered working with big data.Also similarly, you could take measurements of the funding tracker, posts to this reddit, as well as new forum users or members of the RSI site and attempt to make correlations between different dates, dollars earned, and new members added. If you can further correlate this data with things like ship sales, you would prove how you are raking big data and making educated guesses of real world events, and how your data backs up these boosts and spikes. You could also be able to build an algorithm that could run simulations given different events and types of sales to make speculations on future income based on those criteria. This suggestion may be outside of your scope and timeframe, however. As a student of software development it's important to realize what is within your means of production and never scope a project that will go outside of your required timeframe. This is basic software engineering knowledge and I hope this project will help you learn the value of specifications, design documentation, and estimation of task complexity to properly meet your deadline in a timely fashion. Good luck with your project!#Do you know if there is any data that you would be able to hook into form the PU? Would be cool to have personal stat page and info on other players in your instance on a tablet app#Ship Database for iphone#Hmm I don't know how it'd be possible but love to see 360 photo spheres taken inside SC ships and locations that I could view on my smartphone using a Google cardboard type headset. It's become a bit of a dream for me. #I think a mobile chat and community could be great, along with the app having a news board that updates for CIG's news.I've wanted to chat on the RSI chat on mobile for a while but the format is annoying and a bit broken.#How about a mobile app that can show 3D models of SC ships(blueprint or fully rendered), known information about them, separated by role categories.  You can add the systems/planet/faction information too....Like a little pocket SC library. ...or maybe an App that turns your phone into a control device that can change the power settings on your ship in game?    I'm not sure what's possible but I'm assuming you can't copy Vanguard force and you need to do something that doesn't rely on connecting to a server.#Bonus points for it estimating typical online times too. #I don't really know what a ""ride board"" is (does not exists in french univ)If I understand well, it's like a job board right ?If so, apparently, some people have the same ""job board"" idea (cf /u/atyai comment)I think it can be important to have this kind of feature to play the game, I will check this out.#That's an idea, I will check the app, but I'm not sure I will do better than the roccat team (or else the app is relly bad :p)#Yes, I'm interested, if you have some docs, I'd like this out.#ATM, there is a way, you can get accounts public data (orgs, activity)Sadly nothing really big (I don't think you can get ships data etc)#It has been done with the Apollo 13 capsule.So it could be possible de to it with SC ships#I agree, even under some circumstances it hardly usable on desktop (shitty config / network) But I think (hope) it will be corrected in the soon-ish community hub update, so it might not be worth the effort :s#If I can get this kind of data from RSI, that could be doable.But such informations will have a value... and I won't give them to anybody :)#Call it ""auto KOS list"", with settings to find low karma posters, people who are likely to be playing with their kids, or annoying role-play enthusiasts. #I just want something just for Star citizen kinda like Atlis #pay2win confirmed, abort SC#>low karma postersLol#That's basically what Titan ACS is  but for Windows"
java;5h505p;1481172263.0;/r/java/comments/5h505p/who_will_fare_better_in_the_age_of_automation_a/;Who will fare better in the age of automation, a technical writer or a junior java dev?;I am badly burnt out in my current career and I'm considering taking time off to see if I can re-skill. I lean more towards technical writing personality-wise, but not sure which road to take.I am one of those people who can be OK at everything but is brilliant at nothing. I am a liberal arts major, yet taught math and statistics for the past couple of years. So I am good at breaking things up into logical steps and explaining  I'm also good at writing/language. It seems to me I will make a good technical writer, but I'm not sure if it makes sense to invest into it with AI-based automation in the way. Also, after teaching for 8 years, I am really looking forward to staring at a screen and talking to NOBODY for the length of my working day. Advice for me? Technical writer, learn Java, or see what I can make of my stats knowledge by taking the big data route (more expensive to pursue)?Thanks;"Hate to break it to you, but Technical Writers talk to lots of people.#I'm biased, as I'm a software engineer, but start down the Java dev path. Developers aren't being automated away any time in the near future, and if you do decide to become a technical writer the experience as a dev will help a lot.   #Do both! I am a technical writer with some coding background (java, c++, c#, SQL) and the knowledge has made my job SO much easier!#Also, while I do attend a meeting or two a day, most of my day is spent at my desk with my head phones in doing my work.#Learn both. Lots of tech writing job listings require programming experience. Lots of programming jobs at least request good written communication skills.#java developer FOR SURE#you think you will get biased answers posting this in a dev sub?#[deleted]#Don't become a developer if you don't love it. It's a horribly difficult job if you don't. Back during the dot com boom tons of people rushed in for the money and regretted it, to say nothing of the fact that working with them was miserable for those of us that do. #Consider doing Product Management.   This is not management schedules some much as writing the ""user stories"" and/or PRDs (product requirements documents). which are the very first step towards building a product.  This requires both good writing skills, an understanding ( though it doesn't have to be super deep ) of programing, and lots of social interaction with both programmers and ""stakeholders"" (other people in a company that care about what actually get's built ).#there's this dude I talked to who was a teacher and became a technical writer and he said he missed the social interaction and I was, YESSSSSSS *dream job* haha#YESSSSSS *dream job* hahahaCan i pick you brain a little? I will take a year off work. What skills do you suggest I acquire during that year? Assume a Lynda membership or coursera, etc. I have also been looking at the U of Limerick in Ireland for a degree, though I don't know if a degree will improve matters substantially in a way that will justify the cost (degree is 11,000 euro in 1 year - technical communication and e-learning). There's also a part-time certificate that can be done via distance learning and ends up being around 7000 euro#I definitely agree JavaScript is the way to go. There is a big need for JavaScript developers and you can make good money. But I disagree that most technical writing isn't done by someone hired to be a technical writer. Developers and PMs don't really have the bandwidth to write documentation. Most of them hate it, and to be honest, most are not very good at it. I would never let a developer write a document I wanted to send to a potential partner or client without having a technical writer at least edit it first.#good advice, thank you :)#Lynda is this best! I wish I had known about it earlier in my career. Currently watching a bunch of JavaScript tutorials with the hopes of getting some front end dev under my belt. Anyway, I suggest you take full advantage of Lynda  I'm not telling you to try and use it to become a full stack of engineer, but you should have some basic knowledge of front, back, and database languages.I HIGHLY recommend also working with some industry standard software: inDesign, MadCap Flare, FrameMaker, etc. You should be comfortable using each. Also, I use Microsoft Excel and Visio a lot. You'd be surprised at how many ""technical"" people can't create a Visio diagram.As far as a degree vs. a certificate or two goes, I have stated my opinion in response to another comment. Ultimately, though, you need to do what is best for you. Technical communication and e-learning sounds like it would be very similar to my technical writing and communication specialization. I think if you did that along with some comp sci classes on the side you would be golden. Earning a degree is also going to help you network!!! Networking is so important!!! Because I specifically studied technical writing, I now know a bunch of other technical writers that graduated with me. We all keep in touch and email job openings to each other. I know if I were to ever want a new job, I could easily find one through that network.#I would advise not to go for the degree and focus on certifications. Degree's depending on the university can sometimes be very broad and you want to something that is more specialized and focused on what you want to learn. Specialized certifications is the way to go like Java SE Programmer certification, Oracle or Microsoft certifications which are really good such as MTA and MCSE, the choices are endless. I feel that taking specialized certifications is a more effective way of learning compared to Uni, but that's just me.    #i disagree with everything kazoo73 said below.  go to school for computer science.  a computer science degree holds WAY more value than any java certification could.  degree's never expire or need to be renewed.  certifications go away - poof! gone! couple that with the fact that a full-fledged compsci degree goes in depth on so much more than simple java programs.#I also must disagree. Before being given the opportunity for an interview, your resume must first pass through the company's HR department or a recruiter. A degree looks much better on paper than a few certifications, and unfortunately, how you look on paper determines whether or not you will be brought in for an interview.That being said, I want to share with you my education credentials: I have a degree in English, a minor in IT, and a specialization in technical writing and communications. I do not have a computer science degree! Do not feel that a computer science degree is the only way to become a technical writer. "
webdev;5g31w8;1480682526.0;/r/webdev/comments/5g31w8/common_tech_stack_behind_data_reportsbianalysis/;Common tech stack behind data reports/BI/analysis web app;"Disclaimer: This is not a A vs B post. I don't care about your hate to PHP or love to JavaScript, keep those thoughts to yourself. I want to learn form experienced people who had real experience working on Data reports/BI/Data analysis applications and had the opportunity to decide / select tech stack. Thank you.I am experimenting with an application that provides a simple CRUD for data, but the main part of such application is providing analysis / reports / BI on the data back to the user via visual means (graphs, pie charts, tables, whatever).This application is not limited in time, not funded, there are no customers who are waiting for this or angry managers - its purely for education purposes, but my plan is eventually finish it. So while technically I am not limited in time, I do not want to experiment with every possible solution / language / framework and prefer to stay inside my comfort zone of languages (mainly PHP, JavaScript for web and Java with no web experience).I'm wondering what would be a ""correct"" technology stack and why for such application.I was thinking about the following tech stack:* ACID Compliant RDBMS that will enforce data consistency and integrity through stored procedures and triggers, as well as provide reporting result using views. Why? I want to decouple my domain logic as much as possible from the Web framework since I am planning to have more than one client reading/writing to/from the database, and possibly in different languages, hence removing the complexity of asserting data integrity/consistency in every project in every language. Most of the reports I am going to generate, will be simple reports with grouping and summing over different fields so views looks like a good solution for such case. Data amount per client should not be astronomical, so no Big Data hypes here.* NodeJS as web framework / REST API, to CRUD the data in the RDBMS. A simple, thin layer, that suppose to provide high concurrency for multiple clients as well as push/web socket updates. However here I have some internal conflicts. While I do have experience in both NodeJS and PHP, for some reason I find PHP to not be very suitable for this case. Java (which I know) and Scala (which I dont know), on the other side, seems to be attractive, but less ""faster to start with"" approaches by requiring more scaffolding as well as taking into consideration my lack of Java web programming. Wonder whats your opinion on that.* Most of the reports are not CPU bound but rather I/O bound (on the web server side). However I expect to have some reports and analysis that might be CPU bound, and taking into account previous point, NodeJS is not suitable for this. For such cases I am planning to offload process to a scalable worker process through a messaging queue that will process the data, generate the reports / analysis and save it back to the db for future use. I am yet to come up with a proper language / framework for the workers. NodeJS once again appealing here, especially with the cluster option to dynamically increase workers based on load, but I've heard Java/Scala and Go are usually used in such scenarios.* A SPA framework (my choice fell on React without any particular reason) - to display the data back to the user.I know that this particular stack is probably not the correct one, nor any other stack that you would suggest, will be. I am asking this more from the stand point of barely experienced in that field and would like to hear opinions of those who have experience in that fields, whether you can spot pitfalls in the provided stack or provide different solutions.I've asked this on purpose in /r/webdev and not /r/PHP , /r/node , /r/Database , /r/programming because the they are probably opinionated towards specific language / framework / infrastructure, and I hope that /r/webdev is less opinionated and more open minded toward providing constructive criticisms beyond the ""javascript is cool, use javascript everywhere"" bullshit.I appreciate in advance everyone who found time to read and provide any constructive criticism and help. Thank you very much!";"You definitely may want to look into Elasticsearch for your backend datastore. It comes with a lot of tools for these kind of analytics queries built-in. (histograms, counts, aggregates). In a relational database getting some of that data out fast could be a pain at scale. a traditional SQL database might not cut it depending on the amount of analytics data you ingest. Not saying you should use Elasticsearch as a primary store but  it's a fantastic piece of software for BI. You can even use kibana to create the dashboards for you. Source : I just built a web analytics tracker on top of Elasticsearch with a NodeJS endpoint. It can query millions of events under a second. For the front end if you're gonna be building charts,  D3 is awesome. Should play well with both react or Angular. #You could try giving Golang a shot for your API, it's not hard to get started with, and it's possible to put heavy processing tasks in ""Goroutines"", which are essentially threads that are easy to manage. It would also perform way better on CPU bound reports.#Hi,So I'm a full stack dev and a part of my job involves creating and maintaining pages that generate and display reports to different types of account holders (some might be accounts with sub-accounts as well).In my experience:#DBYou don't need to make NoSQL and RDB an either-or case. You can use both in a complementary fashion. # Backend In the back-end domain, when comparing PHP vs Node.JS, the blocking I/O can really hurt you. Then on Node.JS, Hapi does come with more out of the box features and emphasizes configuration, but ExpressJS is fine. I was writing code for a resful api to access resources and my code ended up looking like what Hapi code actually looks like.# Front-EndI recommend going with Vue.js. - similar to but less verbose than React- will scale both up and down extremely well- from all the benchmarks I've seen (and this has been signed off by Dan Abramov), it performs faster than React. If you find yourself still lacking speed you can just use Inferno, but I wouldn't until it's necessary.Additionally D3.js for data visualization is a must. There is no true rival for it.# Additional stepsIf you find yourself drowning in requests, consider placing an nginx server between your clients and your servers.If you find yourself with very slow calculations, don't be afraid to offload some processing client-side.#Im a full stack dev and work closely with the BI team at a an oil/gas company.  I would avoid PHP and JS (on the server) for this sort of thing and stick with a more structured system like python or (more preferably) move to .NET for something of this complexity.As for DB, I suggest MsSQL because of its built-in data reporting services (SSRS).  There are all kinds of tutorials online and the system itself is great.  That said, we dont even use regular SQL to store BI data.  Instead, we use data cubes that store data in three dimensions as opposed to the standard 2.  It's a popular system for BI because you can have dimensions completely dedicated to time.  Because of that, its faster and easier to compare metrics to something from a year ago and see how far you've grown (keep in mind, the same could be accomplished with standard tables, it's just less efficient bc you need lookups) You could also look into a BI specific language like R.   MSSQL server has an add-in for it, or you can do standalone implementation.  There are also things like SAS or Spotfire that help with analysis, but those have costs associated with them#I am also barely experienced, but here's my 2 cents.Have you considered using GraphQL? Considering that you have multiple different clients hitting the database I think it would speed up your development process. It allows you to define the data you would like to receive through the client and saves you time on writing specific endpoints for each client you may be working with. The query language itself is pretty nice and using their GraphQL sandbox will allow you to pick it up incredibly quickly, however a good amount of time will be spent learning and configuring GraphQL to work with your RDBMS.I'd definitely suggest NodeJS w/ExpressJS and GraphQL backend. I love React on the frontend w/ Redux. However, Redux is likely unnecessary since it seems you will be building a small application. My background is full stack javascript so I can't really comment on other backend languages other than NodeJS. I also have no experience with worker processes so nothing to add there.#Thank you very much for your reply!Ill investigate into Elasticsearch as per your recommendation. I was pretty sure that elasticseach was built for performing search operation among huge amounts of data, but you say it can provide analytics data as well, so might be useful for me!As for front, yeah I was thinking about D3!#Thank you for the reply!Yes, I think Ill check Go as well. Many people recommend it for the worker process. Ill see if I can start quickly with it.#That name is hilarious.#Thank you very much /u/OppenheimersGuilt!As for the DB, of course I am not limiting myself to RDBMS, but I do need an ACID compliant DB and hard coded schema, so I decided to pick RDBMS as my main storage, but a NoSQL storage is certainly an option in the future if will be needed.As for the Backend, yes I have experience with Express, Restify and read about Hapi, so I guess Ill give Hapi a try.For front-end, thank you! Ill definitely check Vue.js.#Thank you very much for your reply!I do have knowledge of C# and heard great things about the .NET Entity Framework, but I am not yet ready to ditch Linux infrastructure and switch entirely to Microsoft products.#Thank you for the reply!I've already skimmed GraphQL documentation, it looks nice, however I did not notice any analytics / reports related methods / functionality. Might have to check the documentation deeply!Redux is awesome, and you are mistaken, the application is heavy on the frontend, so I guess Ill stick with React + Redux.#Elasticsearch is fantastic for analytics:http://engineering.wingify.com/posts/elasticsearch-for-analytics/#Check out .NET core. It runs on Linux :)And I think Mssql is ported as well (don't quote me on that)#> Check out .NET core. It runs on Linux :)> And I think Mssql is ported as well (don't quote me on that)~ */u/Prod_Is_For_Testing*"
bigdata;5h28by;1481141823.0;/r/bigdata/comments/5h28by/best_undergraduate_courses_to_prepare_me_for_a/;"Best undergraduate courses to prepare me for a career in ""Big Data/Data Science""?";I'm double majoring in Stats and Computational Modeling, wanting to go into Data Science. For my core classes, typical stats classes are covered like probability, regression, theoretical stats. What other classes should I take? Bayes? Or more pure math?Here are the two course offerings for my two majors, and my MATH minor:CMDA: http://www.undergradcatalog.registrar.vt.edu/1617/cmda.htmlStatistics: http://www.undergradcatalog.registrar.vt.edu/1617/stat.htmlMath: http://www.undergradcatalog.registrar.vt.edu/0708/science/math.htmlMajor Checksheets here, so you guys could suggest some strong electives:CMDA Checksheet: https://registrar.vt.edu/content/dam/registrar_vt_edu/documents/Updates/cos/COS_cmda_18.pdfStatistics Checksheet: https://registrar.vt.edu/content/dam/registrar_vt_edu/documents/Updates/cos/COS_stat_18.pdfSorry for the long post, but I'm looking forward to a great discussion on which courses would be best, and why!Thanks r/bigdata;"the first two are helpful#They say it's easier to teach a data science to a software engineer than it is to teach software engineering to a data scientist. I don't know how much that is true but I can say that we value candidates who know their way around code and we will often pick candidates who have experience with programming languages. I think it's mostly because data science tools are not quite there and still need a lot of human coding expertise to really get the data/models we want. Besides, someone who can do both is cheaper.#I would recommend you take a course in linear algebra. You don't need much pure math beyond linear, but knowing it will make certain  data-related topics easier and there will definitely be overlap if you plan on minoring in CS as well. #On the CS side a database class would be a great benefit for a lot of industrial data science positions.  I can think of several cases where I've seen data scientists write a page of R or Python code for something they could have done with a few lines of SQL.#I may minor in CS, idk if that's enough coding, but that on top of all of the data  science programming CMDA offers as well#Also with my current experience, I've found stats and math way more difficult than software design and engineering. But I guess it's a case by case basis#Ah okay! I've already had two courses in linear Algebra, and we covered some of it in my advanced calc class this semester as well. So I'm hoping that's enough #Ahh. Tech doesn't have any databasing courses until you're like, a senior or grad student in CS or BIT. I know the basics of SQL already, but do you know of any online courses or tutorials that can really help me learn the advanced stuff?#I would agree with supercargo.  Knowing when to pull data into an application for processing versus when to use a SQL stored procedure or query is paramount.  Basically, know when to use the application layer for processing, and when to ""push down"" data processing to the data tier.#Indeed. I'm not arguing that one is more difficult really, my point was to say that someone with experience in both fields is more valuable than a person specializing in one. #That should be more than enough, I only took one class in undergrad and I was a math major!#If you a proficient with SQL already maybe you are ahead of the game.  Advanced SQL can become vendor specific pretty quick, so academic learning there might not be your best way forward (compared to ""real world"" project experience). It might be worth figuring out why the CS database courses are considered senior level material.  They might be delving more into how to implement a database system.  The useful academic bits I'm thinking of are around data modeling and relational algebra.  Understanding how a database executes a query is useful too, but learning that through building a database system might be too far off track for your data science focus.Sorry, I've not taken any of the online courses so I can't recommend a specific one.  For data science I would gravitate more towards analytics than operational databases, maybe even data warehousing (kind of a dated term, but big companies hiring data scientists will almost all have some sort of DW where everything is kept).#Ahh really?? I guess I will take more CS classes then! So I'm more well rounded#Oh wow! I just loved it haha. By far my favourite math course so far. May take another semester for my math minor elective #Ahh. Great advice great advice! I'm just really anxious about finding internships in undergrad. I feel like a majority of them are for grad students, so I'm trying to get ahead of the game and learn some extra skills to help myself out#Do it!"
greece;5gtzxs;1481043785.0;/r/greece/comments/5gtzxs/bio_ομιλητη_σε_συνεδριο_για_επιχειρηματικοτητα/;Bio Ομιλητη σε συνεδριο για επιχειρηματικοτητα στην Θεσσαλονικη !!!!!;"Στο συνεδριο αυτο, (https://inneco.gr/) το οποιο γινεται για την ""νεανικη επιχειρηματικοτητα"", υπαρχουν ομιλητες αμφιβολου ποιοτητος. https://inneco.gr/en/speakers/.Το event οπως παρουσιαζεται στο site, ειναι τουλαχιστον αμφιλεγομενο οσον αφορα στην ποιοτητα οργανωσης. Το καλυτερο παραδειγμα ειναι το μινι βιογραφικο εδω: https://inneco.gr/en/speakers/ness-stephanie/ του οποιου ο υποτιτλος μου φαινεται γραμμενος σε tool τυπου dilbert mission generator (πχ http://cmorse.org/missiongen/)Παρα πολλοι απο τους αρκετους ομολογουμενως ομιλητες, ειναι παντελως αγνωστοι, με 4 subs στο YouTube (http://i.imgur.com/fDmPEsR.png, http://i.imgur.com/WZTqE4o.png) η πχ ο keynote speaker o οποιος αυτοπαρουσιαζεται ως ""Data Science Anthropologist, Industry Analyst, Keynote Speaker, Ranked Global Big Data Influencer"" (Υπαρχει rank για ""big data influencers""?)Ξερει κανεις περισσοτερα γι αυτο το συνεδριο? Ελεγα να παω αλλα η οργανωση και οι ομιλητες μαλλον θα μου κοστισουν τον χρονο μου. ";"Δεν θέλω να το παίξω έξυπνος, αλλά με το που διάβασα στο πρόγραμμα:> In Touch – more success by being in touch with yourself and othersκαι> Why young entrepreneurs are winning!λέω θα ΄ναι καμιά πατάτα το ""συνέδριο"".Πριν αρκετό καιρό είχα διαβάσει ότι υπάρχουν πολλές περιπτώσεις που στήνουν φάμπρικες με ανούσια συνέδρια και σεμινάρια για να τα τσεπώσουν κάτι τυχάρπαστοι, αλλά δυστυχώς - αυτή τη στιγμή - δεν βρίσκω το link. #Άν δεν έχεις ξαναπάει σε industry conference να πάς αλλά μην περιμένεις τίποτα το σπουδαίο ακόμα και ο keynote έχει 1 μονο [βίντεο](https://www.youtube.com/results?q=Ali+Rebaie&sp=CAM%253D) με 750 views σε 11 μήνες από ένα συνέδριο στην Κολομβία ! Bottom feeding creatures . #Το συνέδριο δεν το ξέρω αλλά από τους keynote speakers γνωρίζω τον Αρίστο Δοξιάδη. Είναι σοβαρός. Η σελίδα του στο facebook είναι αυτή: https://www.facebook.com/AristosD Ίσως θα μπορούσες να του στείλεις μνμ στο fb για να ρωτήσεις πιο συγκεκριμένα πράγματα?#Το συνέδριο αυτό είναι όντως περίεργο, ή ακόμη καλύτερα αμφιλεγόμενο. Μάλλον το μόνο που αξίζει σε αυτό είναι το sleek website. Δεν υπάρχει κανένας πραγματικά επώνυμος ανάμεσα στους ομιλητές, και έχει αρκετούς από χώρες του τρίτου κόσμου.Δίνει πολύ έμφαση στο cultural - social στοιχείο (αέρας κοπανιστός συνήθως..)Και η παρουσίαση της ομιλήτριας Ness Stephanie https://inneco.gr/en/speakers/ness-stephanie/ θεωρώ ότι αποτελεί μνημείο ασυναρτησίας, απολαύστε:Ness StephanieObjectively innovate empowered manufactured products whereas parallel platforms. Holisticly predominate testing procedures. Dramatically synthesize integrated schemas.#Ο δοξιαδης οντως ειναι καλος, παντως.#>Ness Stephanie Objectively innovate empowered manufactured products whereas parallel platforms. Holisticly predominate testing procedures. Dramatically synthesize integrated schemas.Μου μυρίζει google translate #Εμένα μου φέρνει όσφρηση από εύρωστη δόση θησαυρού για κάθε λέξη."
pystats;5gd9u7;1480818563.0;/r/pystats/comments/5gd9u7/big_data_guide_how_to_set_up_pyspark_with_jupyter/;Big Data Guide: How to Set Up PySpark with Jupyter painlessly on AWS;;Why would you need to run Jupyter with PySpark? Is that something that would benefit from distributed computing?#Quick question without getting into any flame wars or anything: Why python 2.7? Is there some module or library that you can't access with 3.x? or are you just more familiar with 2.x? Serious question, not trying to start any debates!#Jupyter is a nice development environment and allows the user to try many different things efficiently. It also embed images/plots/tables nicely.#You can easily do this with Python 3.x, as well. Personal preference.http://stackoverflow.com/questions/30279783/apache-spark-how-to-use-pyspark-with-python-3
statistics;5hj8ul;1481358620.0;/r/statistics/comments/5hj8ul/data_science_is_it_a_good_idea_to_shoot_for_a/;[Data Science] Is it a good idea to shoot for a master's degree in statistics after I complete bachelor's in computer science, or should I get a double bachelor's in both statistics and computer science first?;"Basically I only have 1 year of school left. The double major will take 1 extra year.Another option is to just minor in computer science, and major in statistics which will take the same amount of time if I just majored in CS.My only concern with the latter option is if I don't get accepted into a graduate program then I'll be left with a bachelor's degree that has less market value (?) than a bachelor's CS degree.I currently have a 2.8. But after this semester (4 As, 2 Bs  possibly 5 As and 1 B) it might bump up to a 3.00+? Not sure if low 3.00s is enough. Basically I didn't care about GPA and didn't know what I wanted to do during my first 4 years at a community college.My career goal is to work in the ""data science"" / ""big data"" field.If a double bachelor's degree and maybe personal projects is enough to get my foot in the door then I'll forget about trying to go for graduate school. Otherwise, my current goal is trying to get a master's degree in statistics.";"The split bachelors won't make a difference if you have a masters in stats.  I personally like to see single-major degrees.  I have a bachelors in a liberal arts field and if anything I've found it only helps on data science interviews.  If you don't end up getting the masters, a split bachelors won't really be enough for most data scientist jobs, but you'll still be qualified as a data engineer and could work your way into ""big data"" that way.  #Someone said, a data scientist is someone who is better at programming than a statistician, and better at statistics than a computer scientist.Since you have a degree in compsci, go for statistics.You will never be a ""real"" data scientist without proficient knowledge and experience in statistics. Otherwise, you'd be a good ""data engineer"" :)Just my personal opinion. (I am in my grad program in statistics in Germany, btw)#I work for a data science consulting company (I'm an engineer) and we only hire PHDs. Our clients only hire PHDs. Some times you see people who where technical people who became data scientists, but they rarely really are good ones.If you had some nice contributions to some of the apache products or something and went to conferences and hack-a-thons, then maybe, but every where I know about is looking for phds. #Personal opinion here: the technicalities of your undergraduate degree (major/minor, major/major) matter little. What matters is generally what you studied, the skills you acquired, the depth at which you studied, and the level of your degree. I'd suggest a masters over additional time in undergrad, it's critical in the field to even be considered. I have just a bachelors and it excludes me from consideration in many jobs because I don't have a masters. Huge talking points that will help with grad school and jobs: pursue side projects, keep up on research and trends in the field, participate in a lab and research, find an amazing grad program and get your masters there. In general, your undergrad can be done at a decent quality school, but your grad degrees should be done at as good of a school as you can get into and afford. They, especially in the beginning of your career, become the basis of your professional reputation. Depending on the school, it can really help unlock doors for you. #I'm also an undergrad asking myself similar questions. Honestly, I think your gpa might be too low for a good stats grad program. A lot of the good ones have an average applicant gpa ≥ 3.5It might be better to go CS major and get to work right away. Then you can apply to grad schools in a few years with industry experience to compensate for a lower gpa.If you choose to stay in undergrad for long enough to boost your gpa, that's a different story!Based on what I've read and the conversations I've had with professionals and grad students, an undergrad stats education is nowhere near enough. You need a masters to even be a little bit competitive (w/o work experience)- there are phd's in the running for these jobs too.#MS Stats here. Go for the master's degree. A bachelor's in CS is actually a ton of programming experience compared to what most people in an MS Stats program enter with, and everything I learned in my bachelor's (I got a BA Math, but I took a few undergraduate stats classes) was jack shit compared to the level of education and challenge at the graduate level. Another bachelor's degree would be a waste of your time. Granted, it sort of necessitates that you are already good at math and can grasp basic statistics. Do you have familiarity with basic statistics already?"
wwesupercard;5j66zu;1482151444.0;/r/wwesupercard/comments/5j66zu/i_have_a_lady_problem/;I have a lady problem;Ever since season 3 started my high level pulls have only been women. Before season 3, my highest level woman was a survivorWhen S3 started I got couple women as ladder rewards, but I also started only pulling women when I got a pull of wrestlemania or higher. When I finally got to summerslam tier my freebie (or pity pull. not sure what the first ones is called) was a summerslam Alexa Bliss.I've done the fusion chamber 5 times. I did 3 Wrestlemania Fusions. I got Trish, then Lita, then Trish again. Did a survivor fusion amd got Seth Rollins. Them Then I did my first Summerslam Fusion and got Asuka. I know it's not a big data sample, but it supports the idea that anything I get wreslemania or above will be a woman. I only get high level men from events and money in the bank.I know it's not the worst problem yo have, but thought I'd share the oddness.;Send some of that luck my way please and thank you!For Males I have an UL Kendrick, EL Swagger (Got a $100 Google play gift card for Christmas so decided to get a couple of Elite Packs on Saturday), SSF Joe Pro, SS Event Jericho Pro, and WM Pro Paige and WM Pro Bayley for Females. #I'd kill for some females, I have 4 single SS females. This is holding me back from moving up to elite :(#Well my Female luck is all Bayley and Nia Jax.My WM freebie was Bayley after I had got 2 Bayley from MITB. After that my SS freebie was Bayley and the ladder reward was another SS Bayley. And after the maintenance I got Nia Jax SS and now I'm in Hardened I got Nia Jax HR the other day. #Just got a Summerslam Sasha Banks. I'm sorry to everyone having trouble with their women cards.#I'm in elite and since s3 have only pulled women. I've also only pulled 3 s3 cards (including pity pulls and freebies). Pulled SS carmella pro, alexa bliss again for a pro and nia jax for a pro. Also pulled wm divas as well. Only pulled 1 wm card that was male and that was day 1. Even my elite was becky.#I have the same problem. My last 5 KOTR's (made the playoffs in each one) I've gotten only one male and like six females. In won it all in Hardened tier the other day, got a Hardened Nia Jax and a SS Becky Lynch and then in the next one, I lost in the first round and got a SS Sasha Banks. Meanwhile half of my team can't even get a diva pro that's close to their level.#I currently have a single of half the female SS cards. I think I'm just missing 5 or 6, I keep getting them as kotr rewards or pulls. Luckily my freebie was Nia Jax for Hardened and I have a ssf Asuka to help. Would love a pro ss women. Or another Hardened female #TldrPlease use the enter key once in a while #same. i have one event sasha, which i cant pro. and a ssf asuka, hoping to get her again. my pity pull for hardened was a big e, was hoping for a woman#I did,  but I'm on mobile and it just lumped it all together#Double space is your best friend.
NCSU;5i3zsx;1481641088.0;/r/NCSU/comments/5i3zsx/nc_state_hosts_nsf_big_data_research_center/;NC State Hosts NSF Big Data Research Center;;
Eve;5i0alc;1481587707.0;/r/Eve/comments/5i0alc/shower_thought_on_eves_most_recent_events/;Shower thought on Eve's most recent events...;What if the online gaming community has unknowingly participated in the destruction of a competing, migratory vessel of ETs?  Eve is a great example of critical thinking mixed with big data...And no one really reads the terms and conditions before playing...I know there are plenty of ways to poke holes in this.  Just a thought.;U fuckin wot m8?#Stop cooking your own meth you are doing it wrong.....#I can't tell for sure, but I think it's an enders game reference...#Can I have some ?#Maybe people would care if you used a clearer and simpler language#I think its time to change dealers#Yes. The heffalumps and woozles are out to get you. They are *everywhere*#Yes, but you have to exhale.#Been watching *The Last Starfighter*?#Nothing wrong with cooking, but he should probably stop sampling so much of his own product.#This guy gets it#And here I've been huffing lumps of kronol and getting woozy.
ethtrader;5hkqr8;1481385587.0;/r/ethtrader/comments/5hkqr8/luxembourg_investigating_the_potential_benefits/;LUXEMBOURG: Investigating the potential benefits of Blockchain to the fund industry;Interview: PIERRE GERARD, CEO, SCORECHAINhttp://www.luxembourgforfinance.com/sites/luxembourgforfinance/files/climate_finance_december_2016.pdf[ *Luxembourg for Finance (LFF) is the Agency for the Development of the Financial Centre. It is a public-private partnership between the Luxembourg Government and the Luxembourg Financial Industry Federation (PROFIL). Founded in 2008, its objective is to develop Luxembourg’s financial services industry and identify new business opportunities* ]SCORECHAIN, [ https://www.scorechain.com/ ] A LUXEMBOURG START-UP WHICH PROVIDES BUSINESSINTELLIGENCE AND BIG DATA FOR BLOCKCHAIN TECHNOLOGIES HAS SETUP A NEW BLOCKCHAIN CONSORTIUM COMPRISING TEN KEY PLAYERSOF THE LUXEMBOURG FUND INDUSTRY. THE AIM IS TO EXPLORE THEPOTENTIAL OF BLOCKCHAIN TECHNOLOGY TO IMPROVE EFFICIENCYAND CREATE NEW BUSINESS OPPORTUNITIES IN THE ASSET MANAGEMENTINDUSTRY.> LFF: WHO ARE YOUR PARTNERS IN> LUXEMBOURG AND HOW ARE THEY> CONTRIBUTING TO THIS PROCESS?> PG: We have already 11 participants, nine> “pure players” from the industry (**BIL,> BNP Paribas, CACEIS, European Fund> Administration, HSBC, ING Luxembourg,> Pictet, RBC Investor & Treasury Services, Société Générale Bank & Trust), PwC> and SnT, University of Luxembourg**. We> have to discuss how we could integrate> newcomers in 2017. We have organised> several pieces of training, workshops and> even a two-day hackathon with 80> participants with business and technical> teams.> > **As a result, we have already a prototype> running on Ethereum and have fascinating feedback**. We are working directly with> the participant's technical teams, so we are> already studying how these new developments will integrate into their infrastructure.;Asset Management. Its not really how I pictured the world computer being used a year ago, but it is quickly becoming the dominant use case on the network. And honestly, it is a huge use case. If the regulatory hurdles can start to be overcome, I could see this kind of usage basically taking over the entire network.
bigdata;5h6hzc;1481197627.0;/r/bigdata/comments/5h6hzc/top_big_data_skills_to_future_proof_your_career/;Top Big Data Skills To Future Proof Your Career – Become A Data Engineer Now;;The list of things you should know.1.SQL(Structured  Query Language):2.Python Programming:3.Java Programming:4.R programming:5.SAS(Statistical Analysis System):6.Apache Hadoop:7.Apache Hive:8.MapReduce:9.Apache Pig:10.Apache Spark:11.Data Visualization:12.NoSQL:#~~Server not found~~It's back.#It works fine for me.
farming;5ivpqt;1481998205.0;/r/farming/comments/5ivpqt/automation_ai_machine_learning/;Automation, AI, Machine Learning?;[deleted];This question probably better suited for r/engineering#[deleted]#Can't help you out on books so much. But I recommend looking for something along the lines of beginner PLC programming and HMI integration. I'm an automation engineer and the old man got out of pigs before I got into this.  Kinda bummed now cause automating the barn would have been would have been a fun project.  #There's a free Stanford Uni course on Coursera on Machine Learning:  https://www.coursera.org/learn/machine-learningor ask the ML subreddit: https://www.reddit.com/r/MachineLearning/#or maybe [r/automate](https://www.reddit.com/r/Automate/)
buildapc;5jf8zb;1482262585.0;/r/buildapc/comments/5jf8zb/big_data_desktop_computer_build_for_under_4000/;Big Data Desktop Computer Build for under $4000;"###Build Help/Ready:Hi, I'm a machine learning engineer and I'm trying to figure out the best build for a personal computer to go with for processing mounds of data. I do a lot of distributed computing using tools like Hadoop and Spark, and am trying to get a machine that does a lot of the work on GPU's, rather than CPU's I'm currently using due to the speed increase you get. My typical processing job uses anything from a measly few MB's to some TB's worth of data(stored on external seagate hard drives via usb3.0 ports). OS doesn't matter, I use both Linux and Windows so either works. -------------------------------------------------------------------------------------------------I was given an idea by user /u/amazn_azn with these specs: -Intel Core i7-6800K 3.4GHz 6-Core Processor,-Corsair H110i GTX 104.7 CFM Liquid CPU Cooler,-ASRock X99 Taichi ATX LGA2011-3 Motherboard,-Corsair Vengeance LED 64GB (4 x 16GB) DDR4-3200 Memory,-Samsung 850 EVO-Series 500GB 2.5"" Solid State Drive,-Toshiba X300 5TB 3.5"" 7200RPM Internal Hard Drive,-Asus GeForce GTX 1080 8GB STRIX Video Card (2-Way SLI),-Asus GeForce GTX 1080 8GB STRIX Video Card (2-Way SLI),-Corsair 750D ATX Full Tower Case,-EVGA 1000W 80+ Platinum Certified Fully-Modular ATX Power Supply,-Microsoft Windows 10 Pro OEM 64-bit------------------------------------------------------------------I had a similar build that I based off a CyberPowerPC pre-built machine(Fang III - Black Mamba) that I further customized. The specs were:-Intel Core i7-6850K 3.6Ghz 6-core CPU,-XSPC raystorm d5 photon ax 360mm watercooler kit,-ASUS rog x99 rampage v extreme motherboard,-Corsair Vengeance LED 64GB (4 x 16GB) DDR4-3200 Memory,-512GB intel ssd 660p series PCIe NVMe M.2 SSD,-2x2TB 72000RPM SATA-III HDD,-2XGeForce GTX 1080 8GB GDDR5X Video Card (2-Way SLI),-Corsair Obsidian 900D Super Tower Gaming Case w/ Dual PSU Support,-1,000 Watts - Standard 80 Plus Gold Power Supply,-Windows 10 Pro --------------------------------------------------------------------------Just wondering if anyone has some recommendations or alterations for a pc build that would fit some of the requirements without killing the price range. Thanks for the help!";"To take advantage of the GPU (CUDA), you'd need to re-write your program to do so. AFAIK, there's no out-of-the-box config that makes it ""just work"".Hadoop is relatively simple to scale out horizontally (more machines). You might achieve better performance with multiple mid-range systems, than 1 single high-end system.NVMe drives will be a good investment as the basis for what you deploy your HDFS on. Don't work from spinning HDDs. They should act as storage only. HDDs are really bad at random and parallel access. SSDs are great at random access and NVMe are particularly good are parallel access on top of that.If you're caught between multiple CPU choices, you'd want the want that has the highest **multithreaded score**, that's affordable to you.Try with a single 1080 first and see how that pans out. For GPGPU purposes, you do not need an SLI bridge (I think).You can even consider going [Dual-Xeons with slightly older parts](http://www.techspot.com/review/1218-affordable-40-thread-xeon-monster-pc/page4.html).[edit] As many of said, the Titan XP would be better suited than a GTX 1080 for GPGPU usage.#Thanks for the help everyone, I appreciate it! One other question I have is when buying a custom pc for the first time, is it better to buy all the parts and build yourself? or rather use a website that builds it for you and sends it? I'd be comfortable putting everything together, but the one thing that would worry me is applying the cooling system to the CPU. I've heard you have to watch out for air-pockets, and a whole sort of different things when applying it that could end up destroying the cpu if not applied correctly. Any reccomendations on that?#http://www.slideshare.net/PetteriTeikariPhD/deep-learning-workstation#Not entirely sure about this, but would you be opposed to buying one Titan XP instead of two 1080s? I don't know anything about machine learning or anything but I do know that SLI doesn't really scale that well.#Upvoting this. I like the multiple machine approach. If your data processing takes hours or days to finish, I wouldn't want that running on the machine you are using for other tasks. I would say this for ease of use and stability reasons, using windows on the daily use machine and linux on the work horses.It's been >5 years since I've done any computational science, but I assume the basic principles are still the same.I was also under the impression the 1080 didn't offer the best computational performance per dollar on the market. Wouldn't you want multiples of a more cost-efficient GPU?#All stock coolers and some aftermarket coolers have pre-applied paste on the heatsink. As long as you don't touch it, and install the heatsink directly to the CPU, you have nothing to worry about.Only subsequent applications of thermal paste need worry about paste application method. Say, reinstalling the heatsink, or swapping in a new heatsink. As for application methods, check out [this article](https://www.pugetsystems.com/labs/articles/Thermal-Paste-Application-Techniques-170/) for the best method and a visual guide on how much should be used.#>is it better to buy all the parts and build yourself? or rather use a website that builds it for you and sends it?Normally I'd say build it yourself. HOWEVER, professional machines are a totally different story. Don't let anyone here tell you otherwise. There are companies that specialize in building high end workstations  stuff like machine learning is fucking serious and imo time is money, especially in ML, so you'd be better served with as little downtime as possible. That means having great warranty and fast resolutions instead of scratching your head trying to figure out what caused the issue here or there. "
Buttcoin;5hewzb;1481303255.0;/r/Buttcoin/comments/5hewzb/oh_dear_cftc_commissioner_j_christopher_giancarlo/;oh dear, CFTC Commissioner J. Christopher Giancarlo swallows the Blockchain(tm) hype whole;http://www.cftc.gov/PressRoom/SpeechesTestimony/opagiancarlo-18This has been all over the financial press today. Many noted that he was suggesting not harshly regulating Blockchain(tm). Here's what he said:>The first challenge comes from exponential digital technologies that are rapidly changing the very nature of human identity, work, leisure and society. These breaking digital innovations include automated algorithmic trading that has transformed trading markets, distributed ledger technology, more commonly known as blockchain, “big data” capability for sophisticated data analysis and interpretation, artificial intelligence guiding highly dynamic trade execution and “smart” contracts that value themselves and calculate payments in real-time. Today, I want to discuss automated electronic trading, distributed ledger technology and digital data analysis.and a whole section where he elaborates on this content-free bafflegab. Sigh.;"Surely this is good for Buttcoin.#There's nothing we can do  we must wait for the disease to run its course.#That's big news. The CFTC tends to be even _more_ pedantic and anal about securities laws than the SEC. The CFTC was the first organization that wanted to regulate derivatives trading in the 90s. The SEC and the Treasury blocked them. If they had been allowed to, we might not have seen the 2008 crisis.SFYL and comedy gold futures UP UP UP, I guess we might not see more Buttcoin regulation anytime soon!#Future historians will be looking on reddit archives examining the debates of blocksize, and sidechains, and the development and progress of Bitcoin's future.Snapshots:1. *This Post* - [archive.org](https://web.archive.org/20161209170911/http://www.reddit.com/r/Buttcoin/comments/5hewzb/oh_dear_cftc_commissioner_j_christopher_giancarlo/), [megalodon.jp](http://megalodon.jp/2016-1210-0209-11/www.reddit.com/r/Buttcoin/comments/5hewzb/oh_dear_cftc_commissioner_j_christopher_giancarlo/), [ceddit.com](http://www.ceddit.com//r/Buttcoin/comments/5hewzb/oh_dear_cftc_commissioner_j_christopher_giancarlo/), [_archive.is\*_](https://archive.is/?url=http%3A%2F%2Fwww.reddit.com%2Fr%2FButtcoin%2Fcomments%2F5hewzb%2Foh_dear_cftc_commissioner_j_christopher_giancarlo%2F&run=1 ""could not auto-archive  click to resubmit it!"")2. http://www.cftc.gov/PressRoom/Speec... - [archive.org](https://web.archive.org/20161209170920/http://www.cftc.gov/PressRoom/SpeechesTestimony/opagiancarlo-18), [megalodon.jp](http://megalodon.jp/2016-1210-0209-22/www.cftc.gov/PressRoom/SpeechesTestimony/opagiancarlo-18), [_archive.is\*_](https://archive.is/?url=http%3A%2F%2Fwww.cftc.gov%2FPressRoom%2FSpeechesTestimony%2Fopagiancarlo-18&run=1 ""could not auto-archive  click to resubmit it!"")*^(I am a bot.) ^\([*Info*](/r/SnapshillBot) ^/ ^[*Contact*](/message/compose?to=\/r\/SnapshillBot))*#What is this shit? What is the buttcoin foundation paying this guy for? Seriously low quality shill work.#Riiight."
denverjobs;5gh89z;1480880519.0;/r/denverjobs/comments/5gh89z/hiring_multiple_technical_positions_cloud_c_java/;[Hiring] Multiple technical positions (cloud, c#, Java, angular, practice leadership) at all levels;"I help lead one of the technical practices at Slalom Consulting here in Denver. For those who don't know who Slalom is, we have ~4500 employees in 25 offices in the US, Canada and the UK. We are more than just a technical consulting company, we have 7 different practices here in Denver including standard management consulting, delivery leadership, big data, software engineering, design, etc. We're privately held, never grow through acquisition, and try to live up to our core values (which haven't changed and are actionable (https://www.slalom.com/core-values). We have a local model where our consultants live and work in their home market. We have a few travelers, but that is by choice not by definition. We have roughly 175 people in the denver office across all of the practices. In the technology space, we're tech agnostic. We have partnerships with most of the big players (our big 4 are aws, Microsoft, Salesforce, and Tableau) but they don't dictate to us nor do we push their products unless it's what's right (see core value #1). I'm working at a client that's fully in the IBM stack for example. We align our technical folks along the tech they like, and don't ask them to be a generalist (unless they like to be). This means if you're an ios dev, we're not going to ask you to write java or c# code. That just doesn't make sense does it? Right now, we have a pretty pressing need for a large number of people as we head into 2017.  We'll be hiring throughout the year, so if the time isn't right, don't hesitate to reach out. In a nutshell, here's what our current needs look like:- full stack engineers Some sort of Javascript framework (preference to angular or react), c# or Java backend, node/go/Python is acceptable too depending on level/balance. Multiple positions, 1-2 years of experience to architect - front end engineerstypically angular 1.x right now, obviously react is big tooWe need 2-5 engineers, from 1-2 years experience to architect. - Java engineersWe need an architect level fullish stack Java engineer,  and a couple strong junior to mid level engineers. Services mostly, rarely jsp type work. - c# engineers We need a couple junior to mid level c# engineers. Services, mvc, sorry no webforms or vb. - AWS engineers/architects We need 3-5 people ranging from 1-2 years experience to well seasoned architects. Bonus points for automation/devops, especially on the application build side, not just the IaaS side. PaaS side also very helpful. We have massive backing by aws in the market so these are key roles (again, tech agnostic, but we're seeing very, very heavy volume from clients to rearchitect their applications to take advantage of the cloud) - practice leadership It's very hard to hire us. Basically we're going to look for folks who have lead other consulting practices or owned an agency/consulting company. You must be the right mix of business, relationship, and technical - again, hard to find. We normally grow from within (and are), but having external leaders come in (like I did) from time to time can be a great boost. If you don't feel like you fit into any of the above ""buckets"" no sweat. We love diversity (in all the senses), so reach out. Definitions like the above are there to help center people. If you're interested, shoot me a pm and we'll go from there. A few important notes:- sorry, no recruiters - if you're from out of town, great! You will need to, during the interview process, come to Denver for an in person interview- we also don't offer relocation as a general rule. Since I (and an employeee who worked for me in Dallas went through this last year, I can help walk you through it). - our interview process is a little lengthy. Our biggest asset is our people, and we get great clients who ask us back because of our ability to deliver and our great people. We need to make sure that the individuals we hire fit our culture. - if you you have no work experience in any of the above, and this includes going through a boot camp (galvanize, etc), sorry you won't be a great fit. Honestly we're not setup organizationally (yet) to support zero experience analysts. ";Ooh, I'm looking for a junior(ish) C# dev position in the Front Range area.Looks like this https://www.slalom.com/job-opportunity-denver-net-developer would be the one I'm looking for. Any others I should apply for?#Sent you a PM. What's the best way to send you a resume?#I have no idea what skills you might have, so I don't feel qualified to respond :)Edit: if you send directly to me, I receive no bonuses for it (perks of the leadership role?!), but I can coach where I see issues in your resume and can hand deliver to my recruiters who shepherd people through the process.  Also you can ask questions :)#My user @ gmail
bigdata;5gpy11;1480987218.0;/r/bigdata/comments/5gpy11/is_big_data_here_to_stay/;Is big data here to stay?;Trying to do a double major in statistics and computer science. Also trying to learn SQL, python and machine learning during my spare time. However will the field of data science, big data, etc... Still be in demand in the next 5ish years?;"Of course it will! The name will change. The techniques will change. Languages will come and go. But the ""core idea"" isn't going anywhere.More companies are dealing with more data than ever. Whether it's pharmaceutical clinical trials, sales receipts, stock purchase transactions, transportation fleet tracking, or whatever else may come, volume, velocity, and variability will continue to increase. And once you have all of that data, what do you do with it? How do you turn historical data into future value? That question isn't going anywhere. #No, the last time I've head the industry standard is going to be changed to 100 observations per model with a huge fine should you use more data#It's still one of the fastest growing fields and if history tells us, its only going to be in more demand since the data we produce is expanding at an exponential rate (think IoT devices). And with all the automation going on in little data jobs, it is quite safe to be in big data/data science.#From what I have heard the next thing after 'Big Data' is going to be 'Fast Data'.#Interesting.. Where have you heard this? I've never heard of 'Fast Data' before.#I've heard some people extend the water cycle out from the lake.  Fast data points make up the Data Fog.  Inputs condense into the Data Stream which leads to the Data Lake.  The company I work for divides that into edge analytics, stream analytics, and big data analytics (data lake).  Typically we see embedded logic in the device to trigger action, or further action embedded in a gateway for the incoming device values and finally the full set of data science capabilities in the cluster.  Pretty cool stuff.#Still just rumors and projections, but you can read more about it here in these links:http://www.infoworld.com/article/2608040/big-data/fast-data--the-next-step-after-big-data.html  http://www.smartdatacollective.com/tonyshan/309691/big-data-really-dead  https://www.voltdb.com/big-data-vs-fast-dataAlso, you can google search for ""Fast data"" with the quotes to search for the string. In case you didn't know!#Interesting!"
GradSchool;5joke0;1482380103.0;/r/GradSchool/comments/5joke0/would_i_qualifybe_ready_for_a_masters_in/;Would I qualify/be ready for a Masters in Statistics;Hello guys,I'm looking for some opinions on whether or not I'd qualify for a Graduate program in Statistics. To give a little background, my bachelors is in interactive media art and engineering. I initially came at it from the B.A. side, focusing on UX design and 2d/3d graphics. However, there was the option to come at it from the B.S. side of things in computer science. Over the last 2 years I began taking more cs and math courses. While it's impractical to transition over to the cs degree at this point, by the time I graduate I will have taken cs coursework in Algorithms and Data Structures, Discrete Math, Object Oriented Programming, Probability and Statistics Engineering, Software Engineering and Calc I - III. I did this partly because I was worried about job security and also because I wasn't dead-set on a single field and wanted to have more transferable skills. I don't plan to apply for graduate school immediately. I want to narrow down my interest - I rushed into college without much self-reflection. But of the Masters degree's that I've considered the only one that ever really stood out was a Masters in Statistics. Marketing Analytics, Big Data and Data Science all sound up my alley. Regardless, would the background I have in Computer Science and Math be enough to get me in the door at a grad school, or would I be too far behind for it to be practical?I'd also like to hear from any people who went the Statistics route and what you've worked on both in and out of the classroom.Thanks for any info!;Have you taken a linear algebra class? Some proof-y math classes may help you as well, but it sounds like your interests lie more in applied statistics.#If you're going for an MS in Statistics rather than an MS in Applied Statistics, you should at least have Calc I-III (needed for Mathematical Statistics theory) and Linear Algebra (needed for regression). I really wish I'd taken more Linear Algebra with how often it comes up in upper level classes. Differential equations would be useful for Poisson proof. Also, if you can take a 400 level Stat class, such as Intro to Math Stats, you'll be much more prepared for the Mathematical Statistics theory classes you usually get in your first year.#I guess it depends on the program, but I think you have a good chance. (Source: am first year master's student in statistics. I came from a B.S. in psychology. This semester was rough for multiple reasons and I wish I would've done a few things differently, but professors generally consider me a good student. If I could scrape through, so can you. Just don't try to take too many credits at once--there should be no need to anyway.)#I have not. Because of the prerequisites that my university requires for that course, it would be hard to get into that class. But I might be able to forego Calc III and take it. Do you think that would be more advantageous?#Thanks for the first-hand experience. Could I ask what you wished you did differently, and what made you decide on Statistics (Did you get funding through an employer?).#Eh, both multivariable calculus and linear algebra are pretty important. I am not sure that skipping one or the other would be advantageous. For my Biostatistics program, one of the requirements of admission is having an A or B in Calc I,II,III , Linear Algebra, and one programming class. Maybe check into the requirements at some of the schools where you might be applying?#I found it hard to adjust to being a TA (that's my funding source--a full teaching assistantship). The expectations were poorly defined at first. Also, I (temporarily) misplaced some important things (...long, stress-related story) and took rather long to get some things done.It can also be difficult dealing with people you're working with, especially if you are introverted or have social anxiety or have a deep sense of values that you or others don't always live up to, though I love good conversations and I love when things work out well.Also, if you're inexperienced, it's easy to feel/be treated like a peon, and knowing how/when to assert yourself (if you can in the first place) can get complicated. Professors, on the other hand, have a lot of freedom to assert themselves, including reminding you that your status as [whatever] is contingent, gossiping about you in your earshot, or jokingly threatening to kick your ass--but those same professors might also end up being pretty positive toward you, even complimenting you or taking you to lunch.I would say: in the emotional rollercoaster that is grad school, take whatever warm vibes you can get from people, and don't let stress make your brain start fucking up (if possible) because that's counterproductive no matter what.I'm going to grad school in my undergrad institution, and I already knew 3 of the professors in the program a little bit (and got recommendation letters from 2 of them), but I would still say grad school is completely different from undergrad.
Surface;5gtpos;1481041010.0;/r/Surface/comments/5gtpos/sp4_vs_sb/;SP4 vs SB;Hi everyone. I've been using a S3 (2gb version) for about a year and a half now as my primary computer and most of the time it works great. The issue I run into is that I just do not have enough power. I work as a research analyst and although sometimes the work is simple enough for the S3 to handle, there have been plenty of times that I need to wait until I'm at work to use my desktop (8gb ram) to do anything because the load is just to big. So I'm considering getting a S4 or SB as my new primary computer. I don't need it immediately, but in the next year or so I anticipate buying one. So what do you guys think? Is the SB overkill or statistical modeling and analysis with big data sets? Would the extra power be worth it? Or will the SP4 be good enough? Also, is the SB worth the price increase over the SP4 in general? ;To me it basically comes down to if you need the additional graphics power that the Surface Book has. Everything else is pretty much shared between the two of them.#I am also a  research analyst  and also just upgraded from the Surface 3 2gb model to the M3 for work .I think the surfacebook is overkill for the work we do but at the same time, I think it has a better form factor then the surface pro 4. #You will most likely find the performance of the SP4 to be enough for that kind of modelling (I do with my old SP3).I think it comes down to what kind of use and versatility you want in a device really. SP is closer to a tablet (or pretty much a beefed up version of your current device) while SB is closer to a laptop. While I was a student SP was perfect since I was more mobile, now that I sit in an office or travel in work I'd rather go for the SB. #They're pretty much the same computer except one has a slightly better dedicated video card. If your workload is CPU bound then the Surface Book would not give you any extra performance. In fact, the SP4 would provide a much better value, for example:---SP4 - i7 16GB 256GB is only $1600versusSB - i5 8GB 256GB dGPU is $1649---So unless you need the dGPU then other factors might be more important, battery life, keyboard, display size, lapability, tablet hinge, etc. It's more of a personal choice.Keep in mind the dGPU in the SB isn't really seamless like a desktop PC. By default applications use the intel video chip unless you specifically configure a specific application to use the nvidia card. You cannot detach the display if an app is running and configured to use the nvidia chip (it will prompt you to shut down the app). So 90% of the time, I'm using the onboard Intel chip even in drawing programs.#The easiest way to decide I feel is this:Do you need the extra power dGPU?* If yes, then get the SBIf no, then we'll go to the next question:Do you prefer a tablet first or laptop first experience? Ie. would you take advantage of a tablet form factor more or a laptop form factor more?* If laptop first, then the SB* If tablet first, then the SP4#I don't have that kind of workload to do on a SP3, but I'm waiting for the SP5.  If you can wait a year or so, I imagine a version of the SP5 with enough ram and the new intel processors that could probably handle a fair bit of processing requirements.#Even if you don't need the extra power of the surfacebook GPU, consider the much longer battery life. realistic best case scenario on sp4 is 5-6 hours, on surfacebook it is literally 10-12 hrs... I've flip flopped back and forth between SB and SP4 too many times now, right now I'm on the SurfaceBook, and I definitely enjoy not being OCD about the charge level of my device, I can literally wait 2-3 days before worrying about charging the SurfaceBook, since my usage model is 2-3 hours a day on the machine. (This might be different if you use the detached clipboard mode a lot though as clipboard runs out of battery fairly quickly if it is off the base)#Performance wise, unless you use CUDA enabled applications where the GPU would give you a performance benefit, the SB and SP4 are pretty much identical in terms of performance. Choose the device that makes the most sense for your workflow. Do you want a tablet that can also function as a laptop, or do you want a laptop that can work as a tablet?
worldevents;5joee2;1482377792.0;/r/worldevents/comments/5joee2/big_data_and_government_chinas_digital/;Big data and government: China’s digital dictatorship -- Worrying experiments with a new form of social control;;
askphilosophy;5hvuib;1481536784.0;/r/askphilosophy/comments/5hvuib/any_other_phil_of_tech_out_there_are_you_in_a_job/;Any other Phil. of tech. out there? Are you in a job, and if so, how did you get it?;"Hello AskPhilosophy.So, I graduated in october with a masters of arts degree in ""applied philosophy"". My thesis, and the whole masters-education was centralized (on my preference) on philosophy of technology, specifically ontological, epistemological and ethics concerning Big Data.I just want to know, if there are others out there with similar education, and how you are doing trying to find/get a job. As there are no ""ethics of technology-counselor"" jobs, which I would really like to do, I'm kinda lost to an approach into the job-market.BTW, feel free to ask any questions concerning my education, thesis and other stuff.Cheers";I'm also in the applied side of philosophy (bioethics) in a masters program. I'm headed to medical school next year, so that's not much help for you. Something that has become very clear to me is people in bioethics tend to have other qualifications like being MDs, JDs, PhDs, etc. and bioethics is something they do through their lens. Have you considered law? There's a lot of work on regulation and policy development to be done on big data in the coming years, and a law degree would set you up nicely to do that work. Though I know being told to go back to school isn't necessarily the most exciting thing. #I know a guy at Google but he did his PhD and taught first. You could look into the OSTP but they generally look for bachelors and science PhDs. If I were you I suppose I would try to work anywhere in admin or something at a major tech company and then pivot internally to their corporate/public policy teams, if direct hiring isn't possible. #Thank you for your reply :)I actually spent a semester at law-school studying CCTV surveillance in my country, and the development of the law, so I have some knowledge in the field. I have a bachelor-degree in psychology, which I think, maybe naively, gives me a very unique professional profile. You see, I'm alot into computers (hence the preference of philosophy of technology and data/Big Data related issues), and have a basic two-semester-education in IT (programming, marketing, communication), and that coupled with my bachelor in pscyhology and my masters OUGHT to make me qualified for 'technology-ethics counselor' (self-made title), but the problem is I don't see a need for it in the market (atleast not yet), so what I'm trying to say is probably:What can I do to 'get my foot in' on the job market, with what I want to do i.e. what arguments should I use towards a technology-based company? How can I make them want someone with my qualifications?#>Thank you for your reply :)No problem! >I actually spent a semester at law-school studying CCTV surveillance in my country, and the development of the law, so I have some knowledge in the field. I have a bachelor-degree in psychology, which I think, maybe naively, gives me a very unique professional profile. For sure, but for a lot of things (as far as I can see) people like to see a professional degree tacked on like law. >You see, I'm alot into computers (hence the preference of philosophy of technology and data/Big Data related issues), and have a basic two-semester-education in IT (programming, marketing, communication), and that coupled with my bachelor in pscyhology and my masters OUGHT to make me qualified for 'technology-ethics counselor' (self-made title)I just don't think that job exists outside of regulatory and policy spaces is the thing. I might be wrong, but everyone who I know who deals with things that tech-ethics counseling either already worked in research or is a JD. It's not that you wouldn't be qualified to do your job, it's just that like you say it doesn't exist in exactly that form. There's not tons of money in ethics, but there is money in regulation which is where the JD comes in. The JD gives you the bona fides to deal with the law which is where a lot of these ethical issues are played out. >but the problem is I don't see a need for it in the market (atleast not yet), so what I'm trying to say is probably:What can I do to 'get my foot in' on the job market, with what I want to do i.e. what arguments should I use towards a technology-based company? How can I make them want someone with my qualifications?I mean I don't think you can just make them make a job for you. If I was in your situation I'd go to law school, get a JD, and then you'd be amazingly qualified do to all sorts of things. I may be wrong, and the non-health/medicine side of big data may be different. I have no idea, but on the medicine side of things the people who have jobs like you tend to be JDs/MDs/PhDs with some degree of training in ethics. 
investing;5j0rsx;1482076394.0;/r/investing/comments/5j0rsx/discussion_reliq_health_technologies_cverht/;[Discussion] Reliq Health Technologies (CVE:RHT);[deleted];"Good company, will beat earnings but the street will probably keep it in resistance. They use Linux which is probably the most safe, reliable OS if used correctly. Perfect for healthcare apps as we go into this ""cybersecurity"" threat of 2017. "
MLQuestions;5ivs2m;1481998940.0;/r/MLQuestions/comments/5ivs2m/book_recommendations/;Book Recommendations?;[deleted];I am a freaking novice so take my input with a grain of salt.  Few to start with ...  1)http://www-bcf.usc.edu/~gareth/ISL/  2)http://statweb.stanford.edu/~tibs/ElemStatLearn/printings/ESLII_print10.pdf  3)https://deeplearning4j.org/gettingstarted.html  4)https://www.lenwood.cc/2014/05/13/12-free-data-mining-books/    5)http://hagan.okstate.edu/nnd.html#this is very promising: http://www.deeplearningbook.org/
PHP;5gz0zs;1481103309.0;/r/PHP/comments/5gz0zs/bigdata_in_php/;Bigdata in php;[deleted];"I'm not sure if you know what is meant by 'Big Data'. It's a bit of a fashion term, and given a lot of interpretations nowadays, but it used to mean doing advanced operations (like machine learning) on datasets of millions or even more objects. That does not sound at all like what you are doing.From what I get is that you want to import lines from a text file of about 200 000 lines to MySQL with a PHP script. In that case: go for it, PHP will suit you fine. If you want to do machine learning, data mining or similair, PHP might not be the best language. In that case I prefer python, where it provides a lot of good libraries for that kind of processing. But of course there are more options.Maybe you can explain in greater detail what you exactly are trying to achieve?#I don't want to burst a bubble but the number of rows, 10mil, does not necessarily define 'big data' but more the complexity and variety of data. When we get past the sales horse crap, it's really about trying to take disparate data points and bring them together to production actionable bits of information. If you already have well structured data want to find/update or just aggregate, a well indexed database in just about any modern rdbms will give you want you want in most scenarios.As for intaking large files and inserting them into a db, streams.#You should continue to use MySQL, or PostgreSQL, as both have now sharding solutions in case your data become really big.Simply use SQL and proper indexes.#Big data is defined by the 5 Vs https://en.wikipedia.org/wiki/Big_data#Characteristics#you still need more data to define your work ""big data""#You need to embrace the paradigm shift and become a result-driven bigdata devop who leverages the synergy between machine learning and the cloud towards predictive analysis, in a disruptive way.If that doesn't get me bingo, the game is rigged.#What i described is a big part of my job. Because of that i'm interested in learning more about big data.So my coal is not necessarily to import huge files. Examples what i want to achieve:- find a record from 100 millions of lines (and/or update it)- process all records with a specific field (example convert the url, add a text, etc) - calculate hot spots with location and time (for example at 6pm it's at location B the busiest)#Learn SQL#MySQL is fast as fuck. Don't let anyone in the NoSQL world fool you. Many issues people have are related to not being knowledgeable in how relational databases work. ""Big Data"" or when someone labels themselves as a ""Big Data Scientist"" is really people that work with lots and lots of records and try to use data to answer questions like you posted above.  You can easily answer those questions or at least give you direction with SQL. So in short just like /u/colshrapnel said.. Learn SQL. But also learn about relational databases in general, things like indexing are important. #The best advice I can give you is to go and use MySQL, but spend some time reading documentation about indexes and how to use them, and the 'EXPLAIN' operator. These two things will get you to a point where MySQL can do all that with ease.#Yep, every relational database I've worked with (if properly configured) have no issues with speed#I just hate it when some guy talks about using Mongo because MySQL isn't scalable, and all they have is a small database of students of some high school, and that dumbass was lazy/dumb to not normalize it for SQL. "
bigdata;5gek6w;1480839903.0;/r/bigdata/comments/5gek6w/building_a_new_bigdataweb_crawling_pipeline/;Building a new BigData/web crawling pipeline question;"Hi,My team is working on a new project, moving an existing BigData-ish/web crawling pipeline to the cloud - Microsoft Azure, in this case.The data size is Big Data-ish - technically we can store it on a single machine, but we need more processing power than a single machine can handle.Also, the input data are actually Web pages - we keep processing new versions of the same page, the data doesn't accumulate, but it gets updated - something that is not often found in Big Data processing.I am familiar with the ""classic"" map-reduce/Hadoop pipelines, mostly for processing log files and similar types of data.I inherited a design/code from someone, who started the project. This design is built around workflows - not at high level - starting MR batches, but at low level - the workflows are executed during the processing of the individual sites/pages.There is a custom workflow engine built, that can handle ""blocked"" state, external dependencies and so on.As I said, I am familiar with how to address the problem, using a ""classic"" MR solution, that ""moves"" data from one processing state to another.My concern with this workflow based system is that the performance will suffer, but it's hard to compare apples to apples. It's been a while since I worked on a system like this, I want to make sure I am not missing any new developments in the area  at the same time, the previous engineer may just got it wrong.Any comments? Does anyone have experience with a similar system? As I mentioned, the amount of data / pages we are processing, is not that big - maybe about 20 million pages every 3 weeks.At this volume, probably many different approaches will work. My concern is about to making the best design choice, if we have to process 10-20 times this volume, for example. Thank you for reading this and for your feedback in advance.Simon";"It's not really clear where you see potential issues. You fear that your ""workflow engine"" is not flexible enough and introduce latency for some reason?In that case you should give a look to Luigi or Airflow.#[deleted]#You may be interested in Pachyderm as a way of of implementing this. Unlike other systems it's got version control for the data built into it so it's very good for workloads where there are smaller incremental changes to the data. In this cases processing is automatically done incrementally as well. It also has support for deploying directly on Azure and storing data in their object storage so it should be fairly simple to get going with if that's your cloud of choice.DM if you'd like more details. I'm the creator of it.#Yes, this is what I am afraid of - additional workflow logic taking CPU time / causing overall delays during the ""low level"" processing for each data input.I will take a look at the products you suggested.#Does it still make sense to go for Spark if he has no legacy code in it? Why not going for the new generation instead?#> It sounds like you are contemplating about whether to go with old MR coding or start from scratch with something latest that will yield better performance, is that correct?Yes, though I am not that that better performance is the main / expected goal here. Improved performance would be great (compared) to our current system, but we are also trying to improve on the following:- less ""noise"", in terms of random errors, due to memory, network, etc. issues- improved ""development experience"" - ability to run custom tasks/worflows at random times. ability to recompute only incremental data/features/steps in the workflow.There are 2 ways to look at performance - how long does it take to process all of the data, and how long does it take to process a single input, when needed.Currently the second is rather slow, due to internal workflow lack of optimization.Looking at your link right now.#In regards to version control - I am afraid we are required to stick to the company's choice here.Can you share some design / architecture info, in case it is not proprietary? Is it built as a series of mostly independent MR steps, or each incremental input change is carried on its own from the beginning to end?I am trying to figure out if there is a general principle that should give a preference to one design vs. the other?Obviously the parameters matter - what is the overall amount of data, number of individual pages/products/etc., how long does it take to process one, are there ""blocking"" steps - waiting on external factors, and so on.#Looking at Luigi - yes, this looks similar to what the design looks like, in a different language  I need to look at the details.So, if we call the layer that spawns the MR batch jobs ""top level"", and the MR jobs ""low level"", how is the workflow execution impemented - primarily top level, primarily low level, or split between them?Any performance implications / comparisons between the different designs? I can't shake the feeling that doing any sort of complex workflow logic at low level will immediately cause the performance to suffer. I need to figure out how are blocking steps implemented - steps that need to wait on other actions."
psychology;5gylhq;1481095101.0;/r/psychology/comments/5gylhq/using_big_data_to_understand_humans_an_audacious/;Using big data to understand humans: An audacious study will track 10,000 New Yorkers' every move for 20 years;;
oil;5ihwkw;1481813529.0;/r/oil/comments/5ihwkw/shale_20_technology_and_the_coming_bigdata/;SHALE 2.0 Technology and the Coming Big-Data Revolution in America’s Shale Oil Fields;[deleted];".pdf warning#I'm curious what ""big data"" could do for shale producers and this article didn't really say. Just some handwavy ""it's going to increase productivity""#The O&G industry has an enormous big data problem and harnessing it will absolutely increase production.The article says ""Big-data analytics can already optimize the subsurfacemapping of the best drilling locations  indicatehow and where to steer the drill bit  determine, sectionby section, the best way to stimulate the shale ""The first line is key: many of the shale plays are identified by simply drilling holes and running various geophysical tools (an immense number are available ranging from gamma ray to resistivity devices) through the borehole that take measurements continuously. Based on petrophysical and often direct observation from drill cuttings the thickness of the play can be determined in the subsurface. Today, in some West Texas basins for instance, single counties alone can contain over 500,000 oil and gas wells. Of course each well, as per regulation, contains a record of every tool run through the borehole and the associated curves generated by the measurements. To really identify oil plays, picking tops of every well available well is how its done(often viewed in three dimensions), and many of these basins have numerous shale plays, because they are simply the records of marine transgressions over the continent..the melting of glaciers if you will and it happens quite a bit. So gather all the wells all over the country and is creates quite the demand for geologist to map these targets with higher resolution  (Because this is a geologic problem from the start, shales through scientific analyses are becoming quite complex the more we zoom in..creating more data) as a detailed map is crucial to avoid dry wells. Big data is a problem and a tool so yes developing techniques that help us better use it can certainly increase productivity. #I'll try to expand on the actual scope of that data making some (very, very general) assumptions:    500,000 wells    8000ft per well x 3 data points per foot    10 logging tracks per well    =120,000,000,000 data points    .    And that's only 1 type of data that's collected in 1 area."
ITCareerQuestions;5hde2e;1481284922.0;/r/ITCareerQuestions/comments/5hde2e/will_i_be_able_to_have_a_good_career_in_it_if_i/;Will I be able to have a good career in IT if I have studied mechanical engineering?;Hello everybody. I am finishing in Spain a short of mechanical engineering (my bachelor is more generalistic though) and there are a few fields I would like to work in, and one is the IT field because there are a lot of jobs and it's easier to promote if you are capable to learn new things and adapt your self. I like making MOOCs so there won't be a problem. I will be making an Erasmus in Netherlands the next semester and I have made courses about SQL, VBA, Supply Chain so it can prove my eagerness for learning new things.  The point is: if I dont have a computer science degree, would I be able to get a good career in IT? I would like to work on big data or in a product company (videogames, engineering sofwtare or even Amazon), but not on consulting. Are there companys that have as a necessary requesite having a CS degree or usually it's enough to demonstrate that you have acquired knowledge for example making MOOCs?In addition, I am willing to work all around Europe. Thank you very much for your help. Have a nice day;As long as you are able to do the job you are applying for, you won't have an issue.  It probably will be a little harder to get an interview compared to someone the employer knows for a fact was exposed to x, y and z thru their CS degree  compared to you where they need to think about if your resume makes sense, do you have the experience they need.#Apply at SPX Flow (and maybe SPX Corp). In fact, feel free to PM me when you're ready, or even today so we can connect on LinkedIn.I chose not to finish college, but I was going for mechanical engineering. Now I use SQL, I could use better VBA skills, and I'm not sure what Supply Chain with capital letters is, but we definitely have a lot of supply chain concerns to manage.There is a whole category of software called ERP (enterprise resource planning). We use SAP. You will be extremely valuable to engineering companies and others that use ERP software integrated with other software.I'm sure there are other avenues for you to take, but you can be confident there will be a place for you somewhere.#It all comes down to how you apply yourself and learn and grow professionally.  I know many with worthless Bachelors degrees that are highly successful in IT (IE Art, Women's Studies, etc) because of how they apply themselves.  While your degree isn't IT per se, it's a respected degree.   Get out there and apply yourself and you'll be very successful in IT.#Thank you very much for your answers!
Pitt;5iqayz;1481917808.0;/r/Pitt/comments/5iqayz/information_science_majors/;Information Science majors;I'm a freshman right now still thinking about what I want to major in. I saw the the iSchool's website and it sounds like a pretty interesting program especially the big data analytics concentration and the cyber security concentration one sounds good too. Is anyone in the iSchool that can tell me what it's like and how they like it? Thanks!!;"The IS School and The Computer Science Department are merging next year to become their own thing. I'm not too sure of the details  of the merger but you should keep that in mind when planning your major. Here's the link to the announcement if you're interested: http://www.ischool.pitt.edu/news/04-10-2015.phpTake a look at this too: http://pittnews.com/article/68341/news/pitt-to-merge-sis-cs-department/#I did the ""design your own"" and cherry picked the classes that looked most interesting to me. I took graphics, security, and java 3. I did get an internship but it wasnt a great one. I was basically doing desktop support help desk stuff and not getting paid. I got a job two months after graduation doing systems integrations at allegheny health network. I recently just moved to houston and got a job doing similar stuff for the local HIE. Its been great. Kinda a niche field but salary is good and great job security. #It is similar to CompSci but I would say focuses on more of higher overview. I really liked it. It was perfect for me.I didn't do those concentrations but I did take a security course. I would be happy to talk to you about it if you want.I graduated in 2013.#I know a bit about this on the CS side, but not too much on the IS side. If you have an questions about the former, I can try and answer them, though.#I start this spring as a junior. What were you're concentrations? did you find an internship? What have you done after graduation with this degree?Any help would be appreciated!"
malaysia;5g78uj;1480730045.0;/r/malaysia/comments/5g78uj/best_prepaid_mobile_internet_provider/;Best pre-paid mobile internet provider?;Thinking of changing from Maxis to other, since 6GB per month is not enough for porn ( and anime, but mostly porn ). But I still think that they are the best at providing big data for big consumers. What about other alternatives  ( heard that Umobile and Digi has better plan but I'm not sure );Not UMobile definitely.#I have nothing to contribute, just wanted to salute you for your honesty. All the best.#Its all about coverage more if you really depend on data. Umobile has attractive n cheap packages but only their LTE is good, their 3G is like using a 14.4kbps modem so it WILL suck if your place has shitty Umobile coverage. I'd suggest to look into Celcom Xpax #digi has that music freedom which is just bomb for me 👌🏼#Agreed. For postpaid different story la#[deleted]#Was also thinking about that. Is postpaid better than pre-paid?#Lucky you#For the price it used to be the best IMO, p98, RM 98 excl. Gst you get 30gb internet, unlimited calls, unlimited 480pyoutube, and unlimited Spotify stream. Their cell signals are a hit or miss though.#I actually watch 720p YouTube and it still goes towards the unlimited data. Needs a stable connection though. Can't handle 1080p unless I prebuffer.
bigdata;5g8iiw;1480750094.0;/r/bigdata/comments/5g8iiw/dive_deep_into_deep_learning_dzone_big_data/;Dive Deep Into Deep Learning - DZone Big Data;;
politics;5glko6;1480939688.0;/r/politics/comments/5glko6/article_about_big_data_and_election_management/;"Article about Big Data and ""election management"" companies which probably influenced the Brexit vote and the US presidential election (in german)";;"As a reminder, this subreddit [is for civil discussion.](https://www.reddit.com/r/politics/wiki/rulesandregs#wiki_please_be_civil)* Do not call other users trolls, morons, children, or anything else clever you may think of. [Personal attacks, whether explicit or implicit, are not permitted.](https://www.reddit.com/r/politics/wiki/rulesandregs#wiki_no_personal_attacks)* Do not accuse other users of being shills. If you believe that a user is a shill, the proper conduct is to report the user or send us a modmail.* In general, don't be a jerk. Don't bait people, don't use hate speech, etc. Attack ideas, not users.* Do not downvote comments because you disagree with them, and be willing to upvote quality comments whether you agree with the opinions held or not.Incivility results in escalating bans from the subreddit. If you see uncivil comments, please report them and do not reply with incivility of your own.****I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/politics) if you have any questions or concerns.*#>""It is my privilege to speak before you, honored listeners, about the power of Big Data and the psychography in the election campaign."" Behind Alexander Nix, the logo of Cambridge Analytica appears - a brain composed of a few network nodes like one Map. ""A few months ago, Cruz was still one of the less popular candidates,"" says the blonde man with this British tongue, which makes Americans feel like many Swiss Germans, ""only 40 percent of the voters knew his name."" Flash rise of conservative Senator Cruz. It was one of the strangest moments of the election campaign. Trumps, the last great opponent of the party, had come out of nowhere. ""How did he do that?"" Nix continues. By the end of 2014, Cambridge Analytica had entered the US campaign, initially as a consultant to the Republican Ted Cruz, financed by the secret US software billionaire Robert Mercer. .> At this time, in early 2014, a young assistant professor named Aleksandr Kogan joined Kosinski. He had a question from a company interested in Kosinskis method. The Facebook profiles of ten million US users should be measured psychometrically. For what purpose, he could not say that there were strict secrecy requirements. Kosinski wants to say first, it is about a lot of money for his institute, but then hesitates. Finally, Kogan emerges with the name of the company: SCL - Strategic Communications Laboratories. Kosinski goes to the company: ""We are a globally operating choice management agency,"" he reads on the company website. SCL offer marketing based on a psychological model. Focus: Choice of influence. Election control? Disturbed to Kosinski click through the pages. What kind of company is it? And what do they have in the US?>What Kosinski does not know at this time: Behind SCL is a complex corporate design with taxpayers - as the Panama Papers and Wikileaks revelations show. Some have contributed to the turmoil in developing countries, while others have developed methods for the psychological manipulation of the population in Afghanistan. And now, SCL is also the parent company of Cambridge Analytica, the ominous big-data booth that organized the online election campaign for Trump and Brexit.>Kosinski does not know anything about it, but he does not know what is wrong. ""The matter began to stink,"" he recalls. In his research, he discovers that Aleksandr Kogan has secretly registered a company that does business with SCL. From a document, which is available to the magazine, it is clear that SCL was acquainted with Kosinskis method by Kogan. Suddenly Kosinski dawned that Kogan might have copied or rebuilt his Ocean model to sell it to the electoral control company. Immediately he breaks the contact to him and informs the institute leader. Within the university, a complicated conflict is developing. The institute is concerned about its reputation. Aleksandr Kogan first moves to Singapore, gets married and calls himself Dr. Specter. Michal Kosinski moves to Stanford University in the USA.>For a year, it is quite quiet, then, in November 2015, the more radical of the two Brexit campaigns, ""leave.eu"", sponsored by Nigel Farage, announced that she had commissioned a big data company to support her election campaign online: Cambridge Analytica. Core competency of the company: novel political marketing, so-called microtargeting - based on the psychological ocean model.>Kosinski gets mails, what he has to do with it - with the keywords Cambridge, Ocean and Analytics many think of him first. For the first time he hears the company. He looks horrified at the site. His nightmare has come true: his methodology is used on a grand scale for political purposes. > After the Brexit in July, insults bellow at him: Just look what you have done, write friends and acquaintances. Everywhere Kosinski has to explain that he has nothing to do with this company.--Can you find an English version of this article and post that?#I'm sorry that this is in german, but the article was published at the swiss website dasmagazin.ch and i didn't find a english version of this. So you have to use a translator if you're not able to read german...#For google translate of article:https://translate.google.co.uk/translate?hl=en&sl=de&u=https://www.dasmagazin.ch/2016/12/03/ich-habe-nur-gezeigt-dass-es-die-bombe-gibt/&prev=search#Hi `Bendox`. Thank you for participating in /r/Politics. However, [your submission](https://www.reddit.com/r/politics/comments/5glko6/article_about_big_data_and_election_management/) has been removed for the following reason(s):* Your headline must be comprised only of the **exact** copied and pasted headline of the article - [see our rule here.](http://www.reddit.com/r/politics/wiki/rulesandregs#wiki_do_not_create_your_own_title)) **We recommend not using the Reddit 'suggest a title' as it may not give the exact title of the article.*** The ALL CAPS and 'Breaking' rule is applied **even when the actual title of the article is in all caps or contains the word 'Breaking'**. This rule may be applied to other single word declarative and/or sensational expressions, such as 'EXCLUSIVE:' or 'HOT:'. [click here for more details](http://www.reddit.com/r/politics/wiki/rulesandregs#wiki_follow_reddiquette.27s_title_instructions.)If you have any questions about this removal, please feel free to [message the moderators.](https://www.reddit.com/message/compose?to=/r/politics&subject=Question regarding the removal of this submission by /u/Bendox&message=I have a question regarding the removal of this [submission.](https://www.reddit.com/r/politics/comments/5glko6/article_about_big_data_and_election_management/?context=10000\))#This is a good find. Saving this now for later research when not busy.>For a year, it is quite quiet, then, in November 2015, the more radical of the two Brexit campaigns, ""leave.eu"", sponsored by Nigel Farage, announced that she had commissioned a big data company to support her election campaign online: Cambridge Analytica. Core competency of the company: novel political marketing, so-called microtargeting - based on the psychological ocean model.Interestingly, the Mercers fund this company (they also fund Breitbart).And Steve Bannon, if I remember correctly, has a friendly relationship with Nigel Farage, who in turn, is loosely tied to the Russians.#It is the best article on this I have seen so far. Hopefully *The Intercept* will pick this up as they are quite suited to doing the research needed  to go even more indepth on it.#Greenwald doesn't seem like he's very interested, at least he hasn't been so far.#I'd tweet him but for the fact I don't do twitter.This is right up their street. It is either their attention hasn't been drawn to this or they are working on it."
buildapcforme;5iwlwi;1482008625.0;/r/buildapcforme/comments/5iwlwi/dualmonitor_pc_for_spreadsheets/;Dual-Monitor PC for Spreadsheets;[deleted];"If you're going to be doing a lot of typing or even using your computer for long periods, consider making room in your budget for a mechanical keyboard. They feel way nicer and less fatiguing to type on compared to a standard rubber dome keyboard. Here is the relevant subreddit: /r/MechanicalKeyboards A good entry level keyboard can be had for ~$75. #[PCPartPicker part list](https://pcpartpicker.com/list/KVyRwV) / [Price breakdown by merchant](https://pcpartpicker.com/list/KVyRwV/by_merchant/)Type|Item|Price:----|:----|:----**CPU** | [Intel Core i7-6700 3.4GHz Quad-Core Processor](https://pcpartpicker.com/product/7V7CmG/intel-cpu-bx80662i76700) | $304.99 @ Jet **Motherboard** | [ASRock H170M Pro4 Micro ATX LGA1151 Motherboard](https://pcpartpicker.com/product/G8M323/asrock-motherboard-h170mpro4) | $78.98 @ Newegg **Memory** | [G.Skill Ripjaws V Series 32GB (2 x 16GB) DDR4-2400 Memory](https://pcpartpicker.com/product/bj2rxr/gskill-memory-f42400c15d32gvr) | $154.99 @ Newegg **Storage** | [Samsung 850 EVO-Series 250GB 2.5"" Solid State Drive](https://pcpartpicker.com/product/3kL7YJ/samsung-internal-hard-drive-mz75e250bam) | $94.89 @ SuperBiiz **Case** | [Fractal Design Core 1500 MicroATX Mini Tower Case](https://pcpartpicker.com/product/DFfmP6/fractal-design-case-fdcacore1500bl) | $59.99 @ NCIX US **Power Supply** | [SeaSonic S12II 430W 80+ Bronze Certified ATX Power Supply](https://pcpartpicker.com/product/4Vzv6h/seasonic-power-supply-s12ii430b) | $49.99 @ Newegg **Optical Drive** | [LG GH24NSC0 DVD/CD Writer](https://pcpartpicker.com/product/CcCrxr/lg-optical-drive-gh24nsc0) | $14.89 @ OutletPC **Operating System** | [Microsoft Windows 10 Home OEM 64-bit](https://pcpartpicker.com/product/wtgPxr/microsoft-os-kw900140) | Purchased For $0.00 **Monitor** | [AOC E2425SWD 24.0"" 1920x1080 60Hz Monitor](https://pcpartpicker.com/product/DGrG3C/aoc-monitor-e2425swd) | $99.99 @ B&H **Monitor** | [AOC E2425SWD 24.0"" 1920x1080 60Hz Monitor](https://pcpartpicker.com/product/DGrG3C/aoc-monitor-e2425swd) | $99.99 @ B&H **Keyboard** | [Logitech MK120 Wired Slim Keyboard w/Optical Mouse](https://pcpartpicker.com/product/w7Lypg/logitech-keyboard-920002565) | $14.33 @ OutletPC  | *Prices include shipping, taxes, rebates, and discounts* | | **Total** | **$973.03** | Generated by [PCPartPicker](http://pcpartpicker.com) 2016-12-17 19:41 EST-0500 |Below is an explanation of each parti7 6700 - you said you had interest in adobe products. now the 6700 might be considered a bit overkill (or might not depending on who you are) but i can safely say this is a killer cpu.h170m Pro4 - A very nice motherboard packed with features G.Skill 32gb ram - You said you needed large amount of RAM, is this enough? /sSamsung 850 250GB SSD - For fast access, however do consider a 1tb hdd in the near future as i can see the space on this filling up quickly with spreadsheetsNotice the exclusion of a Graphics card for now ,that was so i could add in the i7.Fractal design 1500 - simple but elegant case, Seasonic 430w psu - plenty for this build and will be enough should you decide to add in a gpuLG DVD/CD Writer - meh, its a cd player, what more do you need2x AOC 24"" monitors - big enough that you could put two spreadsheets to a screen and still see a lot of the info on themlogitech mk120 keytboard/mouse pack - bog standard, but will do the jobAny requests, pls let me know"
findapath;5iia9m;1481817744.0;/r/findapath/comments/5iia9m/30m_new_it_career/;30m new IT career;I'm 30m from a muslim country. I'm a self taught web developer. I have just quit my full time 3 year web development job to seek/learn/develop a new career on Android Development. First i had thought about mastering Android Development but since i saw the potential of Hadoop/Big Data in job listing platforms i got confused.As most people in country i want to work in USA, Seattle mostly.Should i keep my hope to work in USA as you all know Trump thing?Should i switch to my focus on Data Science or keep working on Android?;You are switching from web development to native Android? Now that’s odd. Mostly it’s the other way around. Progressive web apps, web-to-native converters and so on. The web seems like the best option for developers, you’ll reach all platforms at once (Windows, Linux, Mac, Android) with a single web app.I can’t give you any advise about moving to the USA as I’m from Europe myself. (and can’t imagine why anyone would want to move to the USA anyway) But my general advise for people who want to move out is not to wait till it’s too late because at older age it will be harder to find a job. Also this subreddit might interest you: [/r/IWantOut/](https://www.reddit.com/r/IWantOut) Edit: I think data science (and AI / machine learning) has more future than Android development, also it's more generally usable while Android is very platform specific.#Wondering which Muslim country you are from! I am Muslim and am from the U.S. (I'm a convert), teaching myself web development, and I want out of the U.S., hehehe. /r/IWantOut is a great place to start.The main issue with immigration anywhere as a self-taught developer is that most immigration laws require credentials in the form of a degree to immigrate as a skilled worker, but I have gathered it might be possible to find a job and get a work visa and go that route without a degree if you have good work experience and a company is willing to take a chance on you. If you're set on the U.S. I wish you all the best but you might want to also look at some other countries as well because things are a mess and likely to get worse here. Developer salaries are higher than other countries but so are health care costs, rent (esp. somewhere like Seattle), etc.#Thanks for your response mate. Actually i had done pretty much stuff with phonegap to benefit cross platform advantage of HTML/JS. I hadnt gotten what i wanted as performance, even simple animations had failed. Anyway a lot of time have passed react native etc have came but still i dont think it's enough. I think you are right future of Android isnt that shiny.Thanks for IWantOut subreddit, pretty much interesting story out here.
bigdata;5j75n1;1482163671.0;/r/bigdata/comments/5j75n1/free_spark_graphx_course_by_big_data_university/;Free Spark GraphX Course by Big Data University;;
cscareerquestions;5g8q19;1480754519.0;/r/cscareerquestions/comments/5g8q19/which_course_to_choose_operating_systems_or_big/;Which course to choose: Operating Systems or Big Data Programming;[deleted];"I'd take Operating Systems if you plan on going to graduate school and it's a required credit. You can always self teach yourself Big Data through an online course. #OS is a core course, so i would do it#Take OS.#If you want to go into industry for something that's not big data, you will thank yourself when you do OS.#You have a chance to really go into an area of CS, and see if you want to make a career out of it. If you are more into low-level stuff, (i.e kernel programming) OS is the way to go. If you are into Big Data (i.e. Hadoop), then definitely go with Big Data Programming. Another criteria would be if you consider yourself a pure ""software"" guy, then go with BDP. OS requires a lot of understanding of hardware works, like different aspects of the computer like cache, memory, disk, CPU, etc. #What if he's going to graduate school for machine learning?"
forhire;5gnm3c;1480963318.0;/r/forhire/comments/5gnm3c/hiring_newark_nj_senior_javascript_developer/;[Hiring] (Newark, NJ) Senior Javascript Developer;Job Description:We are looking to hire in-house software engineers that have exceptional JavaScript skills. The ideal candidate has working experience with modular Javascript, can write pure JS code without depending on third party libraries and is up to date with the latest JS advancements, e.g. ES6, Background Workers, Web Sockets, etc.At Overpass, you'll be part of an amazing development team, focused on building a quality product. We are building a communications platform from the ground up. If you want to be challenged, work on the latest technologies and have a great time doing it, this is the place for you.Skills & Requirements:●	Minimum 6 years working experience with complex JavaScript codebases●	Working experience with NodeJS●	Experience with Aurelia is a strong plus●	Exposure to build & process tools like Grunt, Gulp, Node, NPM, etc.●	Strong understanding of database development●	Exposure to NoSQL databases is a plus, particularly Couchbase●	Ability to create clean, sharp and responsive layouts from designs with HTML5, CSS3 and JavaScript is a strong plus●	Bonus Skills:●	Experience with VOIP technologies●	Experience with WebRTCConsiderations:●	Our culture and environment promotes personal and professional growth●	Work on the latest technologies, think Big Data, Machine Learning, etc.●	You'll work in a newly renovated and designed office space.●	We're based in Newark, NJ, a 25-minute commute from midtown or lower ManhattanAbout UsOverpass enables organizations to create and supervise campaigns for customer outreach. Companies can invite agents and start making calls in minutes. Right now our platform is in private beta and is being used and tested by a select group of customers.Our team consists of successful developers, designers, and product people all working towards the same goal, enhance the way companies approach their communications. We’re fortunate to have a team that has a wealth of experience in both business and consumer based products. We know what it takes to truly make a difference in this space and we’re getting ready to show it to the world. We value work-life balance, career growth, and being at the forefront of technology, design and business. Each team member is unique and brings their own contributions to the table. We're looking forward to our public beta launch and having you on the team with us.Here are a couple things to consider:●	We offer a competitive salary●	You'll work in a newly renovated and designed office space●	Our kitchen is stocked with lots of free snacks and food●	Lounge area●	Casual & relaxed work environment●	Flexible vacation days●	We are a 5-minute walk from Newark Penn Station and a 25-minute commute from mid & lower Manhattan●	We give you access to Pluralsight and other resources●	You will be working with the latest technologies●	We'll provide you with awesome hardwareJob Type: Full-timeTHIS IS NOT A REMOTE OPPORTUNITY – LOCAL CANDIDATES ONLYTo apply visit: http://www.overpass.com/careers.html;[removed]#[deleted]#Sorry /u/abcdenthusiast, your submission has been automatically removed.Your account has to be **at least 10 days old and have minimum of 50 karma** for you to be able to comment on [Hiring] posts.Earning karma means getting upvotes on posted links (self posts, picture links and links to other content) and comments.  **Please do not contact mods for an exception***I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/forhire) if you have any questions or concerns.*#We are looking for developers with at least 3 years for the Full-stack position. We are not currently hiring jr developers. Best of luck!#You looked at for a map
startups;5icfqa;1481742038.0;/r/startups/comments/5icfqa/applications_of_ai_machine_learning_big_data_to/;"Applications of AI, machine learning, big data to medicine; who's the customer?";Background: I'm not a founder or entrepreneur (yet), but a technically savvy person with some ideas in his head.  I did a PhD in the domain of medical imaging.There are lots of interesting things happening with AI, machine learning and big data, both on the startup front and from bigger player's like IBM's Watson.  However, one of the things that often gets mentioned in the considerations for a successful startup is that you must build a product that your customers want to buy.  And so, as the title states, who is the customer of these new offerings? The patients, the practitioners, the insurers, the providers?Looking forward to hearing your thoughts!;Your customers will most likely be medical providers (doctors or hospitals), but possibly other medical equipment providers, as I could see interpretation bundled with the imaging equipment.If you create a better medical imaging machine, your first hurdle will be to get it licensed.  There are a lot of quacks who claim to have magical medical equipment, and you don't want to kill people over misdiagnosis.If you do misdiagnose, who can be sued?  It's an important consideration with medical equipment, and tends to drive up the price.Good luck to you.#http://www.fda.gov/MedicalDevices/ProductsandMedicalProcedures/DeviceApprovalsandClearances/510kClearances/#I'm a doctor. Pm me#On a different note, do you personally have experience with coding for machine learning? How do you plan on actually making the product? I ask because im wanting to do something (slightly) similar but have no clue of how to actually make the product since my experience is in business analysis not coding.#Most likely medical institutions. AI should help them cut costs and improve diagnosis. For instance TC published a startup that could notice signs of cancer in lungs(I guess) with CT scan at higher than doctor precision rate. So hospitals for instance could save on doctors hours and get a higher rate of diagnosis. I would love to learn what you have found during your PhD. #Yes, that and CPT codes for reimbursement, but then you need a lot of clinical evidence, which is very expensive to get.  #My background is in physics.  I have experienced coding to createnew imaging and analysis solutions within an R&D setting, but not for deployment.To be a bit more specific, the product is not another machine learning or AI solution.  It's something that would draw a link between those solutions already being worked on and current technology/practices.  
Entrepreneur;5h48ba;1481162827.0;/r/Entrepreneur/comments/5h48ba/starting_a_healthcare_data_analytics_firm_as_a/;Starting a healthcare data analytics firm as a medical student?;**TL DR** - Medical student with rudimentary stats and CS knowledge wanting to start a healthcare big-data analytics company. Networking not a problem, but who do I talk to and how do I start?**Long-version**I'm a first-year medical student (BS in biomedical engineering). I have programming experience but nothing at the level of a CS graduate (i.e. I know how to code but don't know the more advanced CS concepts like graph theory, combinatorics, etc). My statistics knowledge is also rudimentary, and nothing at the level of a statistics grad either. That being said, I'm very interested in data analytics and am willing to learn if needed.I want to start a company that provides big-data analytic services to the hospital system affiliated with my medical school. I have a general goal of what I want to accomplish (applying predictive analytics to healthcare/medical record info to identify at-risk patients and reduce readmission rates). However, I have no idea how to even start with all this.As a medical student, I can network with virtually anyone in my hospital system, so that would not be a problem. How would I even begin to approach this? Am I foolish even for thinking about this business given my relative lack of knowledge?;Hey there!  I run a healthcare data analytics company.  We use AI to review patient comments and tell hospitals how to improve  patient experience.  Here is what I've seen:Starting a company like this has a chicken and the egg problem:  to create your solution and test it, you need data. Hospitals are very cautious about to whom the provide data.  I would talk to someone in the innovation department about your idea and if they would give you a de-identified data set that you could use to devise an early prototype.  My guess is you need a clear plan of what you plan to analyze, how you plan to do it, and what they may get out of it in exchange for using their data.Then do the analysis by hand.  Build nothing.  Then you'll know if you are onto something that may be a product one day.#I applaud you going to medical school and trying to start an informatics company. Very hard to do. There are a lot of companies in the space right now as hospitals and health systems try to reduce costs. Take a look at what McKesson, Epic or Cerner are offering and see if you can do better.#Since more and more hospital reimbursement is being tied to performance and quality metrics (readmission rates being one metric that's often benchmarked), I'd guess that most large hospital systems already have some sort of program in place  I'd do a bit of digging to see if there's a team in place that you can collaborate with.  If so it would be a good starting point to see what tools are being used in the space, and get a better understanding of how you might go out on your own in the future. #Thank you! Just as a follow-up, what type of statistician would be most helpful for the statistical analysis side of this venture? My statistics knowledge is pretty sketchy, but I can program sufficiently.If I wanted to partner up with someone else who had a stronger grasp in statistics, is there a certain sub-field that would be more helpful? For your company statistics personnel, are they bio-statisticians or are they from a different field? I have access to biostaticians, but is that field of stats helpful for big data analytics?#I would look at healthcare specific startup accelerators - Rock Health, DreamIt Health, Techstars Health.
investing;5gdnxg;1480824235.0;/r/investing/comments/5gdnxg/what_is_the_best_online_brokerage_for_investing/;What is the best online brokerage for investing?;[deleted];I'm pretty sure this is the most asked question in this sub. That's just a guess though, but I feel like I see this same exact question every month.You should check the resources of this sub, I'm almost positive that your answer is there.#i've been using robinhood (commission free) to invest in stocks. Recently, they also introduced Gold plan where they lend you some money like $3000 that you can use to invest and keep all the profits. #I use Merrill Edge, Robinhood and Motif. I use ME because you get 30 free trades a month with a balance > 25k. I use Robinhood because it has free trades (also has less features). I use Motif because I can buy 30 stocks at a time for $10#I use CapitalOne Investing (formerly Sharebuilder). They're fine... #Take a look at Interactive Brokers#We were Scottrade customers but transferred our accounts to Schwab after it was announced that Scottrade was being acquired by TD Ameritrade. Schwab was offering a deal to Scottrade customers who transfer accounts to them - commission free trades for as long as you had your Scottrade account. They also pay the transfer fee. It's unbelievable. We did it and it works as they said. We'll get at least 10 years of commission free trades and after that it will be $6.95 per trade. Schwab has a lot of other advantages like free checks, ATM fee reimbursement, no foreign transaction fees. We've always found their customer service to be excellent. I'm not sure how long their Scottrade deal will last.
learnpython;5hp0ff;1481441031.0;/r/learnpython/comments/5hp0ff/what_would_you_consider_to_be_the_different/;"What would you consider to be the different ""levels"" of programming?";"I have been working away at learning Python for about 3 weeks now, and I can't help but wonder how far I have come, and also how to judge at what point I would be able to say that I program things rather than just mess with code until it works. I'm really interested in big data, and particularly machine learning, I really hope to get into machine learning, and eventually hope to start playing around with HMM. One thing I have wondered is, what are the different ""levels"" of programmers? For example, out of say 100 programmers picked at random, what would the typical abilities be? What are some problems that are intermediate difficulty? When you can understand to do ________ you are proficient enough to get a job programming. I know there isn't any one single thing that answers everything, but as someone hoping to start looking into job options involving programming, what should I be able to do before even considering looking for jobs or freelance projects? ";"That's a hard question, probably one that doesn't have an answer. There's just too much variety and variation. For example, programmer A may have a more thorough understanding of different types of search-algorithms than programmer B, but B may have a better understanding of Python's urllib module. Which one is ""better""? I don't think the question has an answer, especially when you consider this question could be asked about a million different things. All you can say, in my view, is that for any domain you are  either an expert in it or not, intermediate or not, beginner or not. So in that sense you get levels of skill *for some specific domain*. But when you ask about a general level, which encompasses multiple domains of knowledge, then you are asking a hard question. Perhaps an analogy of sorts helps. So, I come from a linguistics background, and you would never say linguist A is better than linguist B. Simply because most linguists work on different problems, in different domains, with different skillsets. One may be an expert on German syntax  another may be an expert on truth-conditional semantics  another may be an expert on Chinese morphology... And each of them are brilliant at what they do. But it becomes impossible to quantify in any meaningful sense what levels each is at relative to the other. You get the picture.So pick some domains that interest you. If you are interested in the web, then pick those that will help you get a web job. So, for example, Python's urllib module, or the Django framework, and become as good as you can in them. #> what should I be able to do before even considering looking for jobs or freelance projects?Learning. All other stuff is just a matter of time if you can learn things.#My experience (1 year of programming, consistently):1) Tough 6 months of just learning syntax2) Implementing syntax, and learning about modules.My 2-cents: I have the same general sort-of-goal, with data-collection and machine-learning/big-data.  I even, naively, searched jobs with those options in-mind. I have no clue, what you should ""do""/""know"" to land jobs  but I do think what you should be asking (as I wish I should have) is: how long will I have to study, until I become competent in said-job.#> When you can understand to do ________ you are proficient enough to get a job programmingAre your projects in version control and do you understand why that's important? There's more to the job than that, but that's the thing I most frequently see being put off 'until we have something to store there'.#http://sijinjoseph.com/programmer-competency-matrix/"
Futurology;5gd7mm;1480817717.0;/r/Futurology/comments/5gd7mm/5_ways_the_second_machine_age_will_morph_the/;5 Ways the Second Machine Age Will Morph the Future of Big Data;;
Career_Advice;5iph8i;1481909222.0;/r/Career_Advice/comments/5iph8i/can_you_help_me_decide_between_these_two_jobs/;Can you help me decide between these two jobs?;Crossposting from r/careerguidance because I'm not sure which sub is better. I'm a DBA/analytics guy, worked for current company for about 3 years, but was an independent developer before that for nearly 20 years. My employer got bought by a competitor and they terminated all of the IT positions in our office, preferring to keep them in the home office. My last day was Weds. Literally on my last day with the company, a director of the data department at the company that bought us contacted me and said that he heard I was really good and would I be interested in interviewing for an ETL specialist/data warehouse architect and engineering position, morphing into data science in a year or two when the warehouse is more stable. I've done two interviews with that team already. Let's call this option #1. Option #2 is a job offer from a management consultant I respect a lot that I worked with about 10 years ago, building a big executive information system for tracking assets on large construction projects. It's white-page development that starts small but should include big data, IoT processing, a bunch of fun stuff.  Let's call that option #2. Option #1: * Pros: Big company, big data, big resources, lots of budget for tools, a few other experts working on parts of the systems. 34 billion row tables, budget for cloud processing, etc. It's healthcare, so it's a rich data environment with the possibility to really make differences in people's care. * Cons: I hear dark rumors of epidemic bureaucratic entanglements, favoritism, constant organizational reshuffling,  arbitrary deadlines, your typical 1000+ company organizational problems. The pace is very fast. The org is very heavily siloed, more like castles. I haven't met her but the big boss is supposedly a straight-up genius, but very mercurial and hard to work with and sometimes yells a lot. Interviewers told me that I would be mostly on my own because nobody upstairs has any time to deal with me and everybody lower than me can't be trusted to do anything not 110% specified in detail. (H1b workers...)Option #2:* Pros: New programming technology, new languages, would be building a system from scratch with complete control over the product, working with a small team and a manager I deeply respect. It's a cool client in an industry I want to know more. Stress level is likely much, much lower than Option #1, and my friend has always been a very rational person to work for. Pays about 40% more than Option #1, but as a contractor. (I have a corporation). I'll be working for myself again, which I usually enjoy.* Cons: Will only be a 6 month contract to start. May extend another 6 after that but we will have to show big gains to get it. Initial programming is web UI using Google Polymer, which I don't know but can certainly learn, but I'm trying to get away from doing UI work, though this should only be for the first phase. I would likely be doing initial architecture on every step of the data system and I'm only a newb on a bunch of this big data tech. So less stress, but a lot more school time (on my own dime). Both:* Neutral: I would likely work from home for at least 6 months with either job. Option #2 will likely be at home forever, Option #1 will likely require relocation after the initial period. I feel like I have a week to decide one way or the other, though neither job offer is 100% in hand yet, I'm 99% sure I will get an offer for each in the next 7 days. So my question: What kinds of things should I be asking myself to help decide between the two offers? Wow, you made it this far. Insight?;"Reading your post it sounds like you have answered your own question. Take the job that will build your resume. Working for yourself gives you more freedom to finally move forward in your career.  The market is ever changing, time to invest in yourself. Option 2 has you excited, yes it is uncertain, yes you will have to invest a little, but you are investing in yourself. A great reminder to never get too comfortable. #i think questions to ask are:if you chose option 1, are you ready to deal with the politics and new company policies and work environment.  Seems like you are qualified for this role, if youve done 2 interviews, and you know the systems / type of work already.if you chose option 2, the pay is more because it is a contract which is expected.  are you confident in getting another job with your skill set after 6 months?  I wouldn't really bank on the 6 month extension because its not guaranteed, and you can evaluate it close to that time. you may not be fully qualified for this role if you need to learn something new and then build a system/environment from scratch.  Generally, contractors are hired for their tech skills and they should come into work with the skills needed, not to learn on the job. If this company is ok with you still learning the tech, then perhaps you could take advantage of the contract role.if it was upto me, I would stick with Option 1, try the ETL role, get some experience in it, if you like it, stay, if not then apply elsewhere with your newly gained experience and skillset.  I would not take a contract role involving tech that i was not atleast intermediate in.#Age and retirement savings factors how?#Thank you, that was a great insight. I'm no stranger to taking contractor rolls where I'm ""mostly qualified"". It's how you move along in the contracting world, I can't take six months to get good at something before working with it. But I agree that I would not be as confident with my solutions as if I had more experience, and that means stress and learning along with the job, so more late nights. I'm going to put together a good list of questions for the next interview for option one, already scheduled for Wednesday with the big boss. See if I can get a better idea of the Corp structure within this working group. I googled the ""genius"" and didn't find much, she hasn't published or spoken as far as I can tell, maybe she is just a good programmer promoted to management, typically under prepared for dealing with people and offputting to business types.The saga continues...#Thank you for your insight. It monitors my own thought process to a large degree. I'm worried about building a new system from scratch, but I've got a call with the project manager today to get more info on what the rest of the team is like and what the deliverable timeline is like. #I'm 45 and have already funded IRA and 401k for 2016. I'm not worried about either, both will make enough money for me to keep up retirement savings. I'm a good saver.#Then I say contract."
ethtrader;5io8a8;1481894751.0;/r/ethtrader/comments/5io8a8/blockchain_and_big_data_worth_watching_in_2017/;Blockchain and big data worth watching in 2017;;"> It's that time again . . . so here's a selection of blockchain-inspired technology providers which may be making a splash in 2017, and also a couple of people doing some nice work with big data and machine learning in finance.&nbsp  > Parity Technologies> > Parity Technologies (formerly Ethcore) begins production of its Polkadot project next year, to allow diverse kinds of blockchains to interoperate within the same consensus network.> > Polkadot has the potential to integrate so-called ""private"" chains into the same consensus network as public chains like Ethereum, while still retaining their privacy and permissioned safeguards.> > Polkadot is to be implemented alongside Melonport, a blockchain infrastructure for investing in crypto portfolios, similar to hedge funds. Melon goes beyond a normal crypto wallet, providing a ""rule set"" which forces certain elements to portfolios, such as performance calculations and trade restrictions.> > Parity Technologies was founded by Dr Gavin Wood, Ethereum co-founder and inventor of the Solidity language, together with other members of Ethereum, like Dr Jutta Steiner, Dr Aeron Buchanan and Kenneth Kappler."
datascience;5j5z4b;1482147907.0;/r/datascience/comments/5j5z4b/data_science_and_big_data_recap_2016/;Data Science and Big Data Recap 2016;;"I was expecting some re-cap of interesting research, findings and projects that have happened this year. Instead I got a summary of one blog and ""use Apache for this and that"". Shame."
techsupport;5ibqf2;1481735201.0;/r/techsupport/comments/5ibqf2/does_anybody_know_if_theres_some_big_data_breach/;Does anybody know if there's some big data breach right now or something?;My eBay account got hacked last week, my Reddit account got hacked this week, and my fiancée's EA account got hacked this morning.I ran a virus scan last night and found nothing.;Stop reusing passwords#They were all different, and they followed all the safety tips. Caps, lower case, numbers, symbols, lots of characters.#Then it wouldn't matter if there was a data breach somewhere else because it wouldn't give them your password for other services. Do some more virus scanning. Look for rootkits and keyloggers. #In addition to what HothMonster said (run different malware scans because it's probably on your computer), enable 2-factor-authentication (the site will phone or text when a new computer tries to log on) on whatever accounts support it.#Any suggestions on software to use? The EA account wasn't even on my computer, so whatever it is has access to both mine and hers.#Yeah, I am using that now. What's weird is the EA account was on her computer. Mine never accessed it. Is it possible that someone hacked my router? It seems normal...#I'm pretty out of practice with virus removals. I would [ask over here](https://www.bleepingcomputer.com/forums/f/22/virus-trojan-spyware-and-malware-removal-logs/) if I was worried about my shit and not finding a cause.
learnprogramming;5h61uc;1481189382.0;/r/learnprogramming/comments/5h61uc/coutside_of_intro_to_c_programming/;[C]Outside of Intro to C Programming;Hi Fellow Programmers!I'm just about finished learning C and was wondering if any C programming veterans can point me in the right direction as to advancing my capabilities. I am finishing Kings C book Second Ed and will be looking to expand further.What I am looking to do is...well, anything. Big Data, Machine Learning, NN, HPC/Parallel/GPU, Numerical and mathematical programming and optimization, you name it! GUI, CV, human 2 computer interaction, combinatorics and statistical analysis. Just to name an extra few.What seems to get me is the lack of C resources available online (when it comes to written text.[Yes, I have seen this list.](https://stackoverflow.com/questions/562303/the-definitive-c-book-guide-and-list)) There seems to be very few books or modern books concerning the above disciplines. I was either thinking:1.) Asking C veterans what they recommend for books on the above. Provided they are as modern as needed. 2.) Asking Programming veterans of all types if I should continue C or if I should jump to a new language and have C as a catalyst for anything needing to be used for memory and performance optimization. C++ and Python comes to mind, but I am open.Before I close, I would like to state that reading r/learnprogramming has shown that there are many here self-teaching themselves. I am looking to do CS and some math later on, but now would like to spend on learning programming. As to my specific goals, that I have not determined as I have NOT been exposed to much of the CS discipline and cannot make a decision as of now. So, I do apologize for being terse or vague in my post.;Once you finish King's book, you should know C well enough to program in it.  If you are unfamiliar with data structures and algorithms, then that should be what you learn next.  Data structures and algorithms are the tools that form the foundation of programs.  I don't have any specific resource to recommend, but look for one that has programming exercises and at least covers linked lists, binary trees, hash tables, and sorting.After that, you should have the necessary knowledge to build non-trivial programs.  You could then utilize outside libraries to make interesting things, like [sdl](https://www.libsdl.org) if you want to make games, [libcurl](https://curl.haxx.se) for doing stuff with the Internet, [gsl](https://www.gnu.org/software/gsl/) for math, one of the many gui libraries, etc.#Hey, most of the stuff you listed makes it seem like you have an interest in AI. Python might suit you better than C. #Thanks.Can you point me to a list of third-party libraries for C? Would be interested to see what C can support.#Sorry, I don't know of a list of C libraries.  C is a popular language and has a lot of third party libraries available, though.  With google, you should be able to find ones relevant to you.
Futurology;5g8ynt;1480759855.0;/r/Futurology/comments/5g8ynt/researchers_looking_at_international_patterns_of/;Researchers looking at international patterns of emerging technologies found that 3D printing is associated with a “balanced collaboration” mode, big data technology by a radial pattern, centered on the US, and carbon nanotubes and graphene technology exhibits “small-world” characteristics.;[deleted];That title made so little sense I thought I was reading subredditsimulator.#Lol - sorry I was trying to do an /r/science by putting in the purpose, model and findings in the title. A bit hard with this one.  
datascience;5j5v9y;1482145999.0;/r/datascience/comments/5j5v9y/honors_in_computer_science_or_big_data_analytics/;Honors in Computer Science or Big Data Analytics?;Hi All,So I recently finished my Undergrad in Computer Science and I am now faced with a decision of which field to pursue for my postgrad study.I have been lucky enough to be made an offer for both honors in CS and honors in BDA... But I'm having trouble making a firm decision... On the one hand we have CS, which is a field I truly enjoy studying and have been doing for some time now. This program is fairly basic, Consists of 1 compulsory research course and 6 other optional CS courses... On the other we have BDA, Which is a new honors program started at my university (of which they say acceptance is highly selective). This program seems really cool as it aims to bring together some interesting areas of CS and Math, such as Machine Learning, optimization and multivariate statistics... It's a much more structured program than its CS counter part  Consisting of 5 compulsory courses and 2 optional courses...As a new graduate, who hasn't had much experience in the real world outside of google... I was hoping that some of you could help me draw a clear line between the 2 fields? And also which would be (in your opinion/experience) a better career choice in the long run?Thank you!!!;"big data analytics is a buzzword and in  5 or 10 yrs will he scoffed at.  Computer Science is timeless.#Stick with CS and take some statistics classes. Alternatively, consider a Master's in Statistics. These ""Big Data"" programs will become old hat in a few years. Sticking with fundamentals makes more sense, IMO.#It actually depends on where your interests lie,if you have an inclination towards the data science field I would suggest to first get some reviews regarding this program in Big Data Analytics from anyone who is attending or has already completed it.Depending on that,I would suggest you to take the decision.                                               However looking at your description,I think you do not have a particular inclinations towards the analytics field, in that case it would be advisable for you to take up the CS program.#Which college are you talking about?#Thanks buddy...#I'll consult my professor's soon as uni opens...Thanks for the advice man... Really appreciate it!#University of Witwatersrand, in South Africa "
utdallas;5hn29y;1481412761.0;/r/utdallas/comments/5hn29y/what_are_easy_its_classes_that_i_could_take_to/;What are easy ITS Classes that I could take to raise GPA?;Here is a list of ITSS electives that I can choose from:3390   Web Design and Development - Vivek Arora4301   Database Systems - Ravishankar Narayan4312   Mobile Web Application - Thuan Nguyen4340   Enterprise Resource Planning - Luell Thompson4343   Integrated SCM Information Systems - Eugene Deluke4352   Introduction to Web Analytics - Judd Bradbury4354   Managing Big Data - Kelly SlaughterPlease let me know and thank you for the advice.;"I took 4352 for judd. You do a bunch of group projects and quizes that he curves really well. Majority of the class would stink up the online quiz but he would curve ALOT. The projects are easy. Just find a good group to work with. I made a A -  #4343#3390 with Vivek, absolutely, and he's real down to earth. Easiest A you'll get and you won't regret taking him. Slaughter is not easy, he's got nearly 20 years professional experience and knows his shit. Not classes you can coast through and he'll only help you if you're willing to help your self, not just say ""I need help."" He expects you to have been on stackoverflow and come to him with a solution to your problem to only confirm your solution, not to provide one for you. Thuan Nyguen is nice, but there's a HUGE FUCKING language barrier and in mobile app development you literally are in groups and your groups are forced to teach the class. Lou Thompson's awesome and ERP isn't sexy on a resume, but it's good to have (he just goes off on tangents and tells tons of stories). Source: am graduating ITS honors at 9 am :P"
ukpolitics;5gjazk;1480903892.0;/r/ukpolitics/comments/5gjazk/the_power_of_big_data_and_psychographics/;The Power of Big Data and Psychographics;[deleted];And this is a prime example of why I use an adblocker and do not watch TV.I know my information is still collected about me (internet habits, purchases...), but god damn I don't want the information fed back to me in a loop.PS: For those looking for an answer to his final point, this addresses that: https://www.youtube.com/watch?v=NjQDY4JHG_M#I find machine learning and big data fascinating from a theoretical standpoint, but it's application to politics is depressing. It won't be long until they have an algorithm that generates their manifesto. That is when we know we have reached peak cynicism.#I prefer the idea that we can write an algorithm for producing policy with an ideal outcome for as many people as possible, then sack the buggers in Westminster. An algorithm can't be corrupt, cynical or greedy unless it's designed that way from the start.
EngineeringStudents;5jhnzl;1482289929.0;/r/EngineeringStudents/comments/5jhnzl/comp_scieng_vs_information_technologies_management/;Comp Sci/Eng. vs. Information Technologies Management?;"Preface: Never felt CSE was a true engineering major, but I've been interested in computers/how they work for a while now. I've had a job doing data management for two years now (summer job) and freaking loved it. Worked from home, was actively involved in getting results/managing real-world data and can't say enough how much I enjoyed my time and how much I learned.Currently a freshman who just finished his first semester as a CSE major - and I'm actually just despondent. Failed Calc 1 (I've always been bad at math/really uninterested in the subject, and my shitty/small mistakes cost me the course - yes it was a requirement for my major) and my *""intro""* to programming class (how abjectly awful this course was is a story for another day), and passed my micro-econ and bio classes. Aside from me being 100% despondent currently, got me thinking about CS and if it's the right career path.I loved my job. I loved the software (Dynamic CRM, VS) and the languages (VB, SQL) and really liked the concepts that my econ teacher went over this year. After this course, don't know how much I'm interested in ""true"" computer science (figuring the solutions out from scratch) rather than the information I'd rather be managing and making reports on that while using the code to assist in giving me the data I'd need. Projections, sales figures, just big data was a lot of fun to work with and analyze. If this is what I were to be doing everyday, I'd be more than satisfied. Might've just answered my own question in writing this, but I want some feedback on anyone who is/was a CS major, what internships within that field look like/jobs look like, and if I should be considering a switch to ITM (info tech management) from CSE if my career prospects align more with ITM.If this is the wrong spot, let me know. Thanks for reading and I appreciate your feedback in advance. I'll clarify anything further in the comments that needs to be.";Curiousity here. Could you explain the difference between Computer Sci/Eng and Computer Engineering? And also how you don't think it/they are actually engineering?#Why don't I think CS is really engineering? This sub mainly but idk. Made me question stuff. It's not ME, EE, doesn't have to do with thermo, liquid, mechanical, structural, physics, etc. See a lot of that here and not a lot of CS talk. It's like... Pseduo-Engineering. I guess. ¯\_(ツ)_/¯Computer Sci/Eng gives a focus on both the hardware and software, and meets somewhere in the middle. I've always enjoyed PCBs and schematics and such, as well as software, so CSE is a nice middle ground for that. CE focuses solely on hardware and is more akin to an EE major with a focus on Computer electronics. At least, that's what it is at UCONN, can't say for other schools. #You said you never felt that CSE was truly engineering in your original post. I was just confused as, at my school, what you described as CASE and CE is all lumped into CE. So I was trying to understand what you were saying in that aspect. #Eh, sorry about that. Meant more CS than CSE. It's like CE>CSE>CS. Laid out clearer. Sorry about the confusion#No worries. I understand now. 
cscareerquestions;5ht673;1481498888.0;/r/cscareerquestions/comments/5ht673/has_anyone_here_done_big_data_consulting_xpost/;Has anyone here done big data consulting? (x-post r/bigdata);Hi guys,Recently, I've found myself wanting to take more ownership of my career path, and have been looking into switching into consulting. However, unlike most of my consultant friends, I specialize in big data (primarily spark/kafka/hadoop/hdfs etc.) rather than web design/ios.Has anyone else made this transition?If so, I have a few questions I'm seeking answers on:1. Where have you gone for gigs? How do you establish a network?2. Have you noticed a significant change in your compensation compared to when you worked a 9-5?3. What type of jobs have you taken on? Are you primarily architecting systems from the ground up or fixing already existing systems?4. Are there any consulting firms in particular that I should look to apply to? (I've considered cloudera/hortonworks, but those seem more specific to maintaining their products than building new things)Thank you all so much for your help!;I potentially am about to start one. They low balled me on my offer but then again I have only been working for 2 years with BD and don't have consulting experience and am still pretty young 26(I think thats young lol).Cloudera/Hortonworks are sweet gigs for consulting. Yeah they have there own tools but they are all based on open source so it's not big of a deal. And any company you go for consulting will have a stack that they try to push to clients.
europe;5hjvtl;1481372446.0;/r/europe/comments/5hjvtl/big_data_helps_brexit_and_trump_win_cambridge/;Big Data helps Brexit and Trump win. Cambridge Analytica - Article (German) in comments;;"Very interesting - I have the sudden urge to delete my entire online presence... #https://www.dasmagazin.ch/2016/12/03/ich-habe-nur-gezeigt-dass-es-die-bombe-gibt/#[deleted]#This would only really ""help you"" if all the people in your demographic with your attributes would delete it thoguh I guess.#Thats true. But if you think about Brexit and Trump you could argue that it may be helpful in some serious ways.#[deleted]#From everything I have read about the UK referendum, the leave campaign used data much more effectively than the remain campaign.I was one of the activists for Vote Leave in London. On the day of the referendum, the remain campaign were standing at tube stations handing out stickers to commuters. The leave campaign were knocking on doors of people that we knew would were sympathetic to the leave arguments. The latter is just a better strategy and illustrative of better use of data."
technology;5g8nh5;1480752958.0;/r/technology/comments/5g8nh5/amazon_and_aws_democratizing_ai_and_big_data/;"Amazon and AWS Democratizing AI and Big Data Analysis: ""three new AI products, all of them keeping with AWS’ original purpose of making scalable web development apps affordable for everyone.""";[deleted];
careeradvice;5g0s7j;1480645917.0;/r/careeradvice/comments/5g0s7j/how_to_get_your_life_back_on_track_advice/;How to get your life back on track? Advice, suggestions needed.;Hi there fellow redditors. I’m a long time lurker but first time poster. The reason I finally decided to post is that I want a change in my life and I really need your advice and thoughts. I’m a 35-year-old male from India who came to the United States on a green card right after my undergrad.  I got admission in a big research university in Electrical Engineering but unfortunately I just could never click and dropped out. I also isolated myself from everyone else and pretty much was holed up in my room. I ended up using almost 4 years to conclude that I wasn’t good for school and that I need to drop out. In that whole time period, I actually finished all the required courses but the thesis requirement.  After dropping out I went and settled with my aunt’s for few months and took a job at a retail store (during the 2008-09 economic crisis). I didn’t have any confidence or self esteem to muster out of my comfort zone. So I kept on going to the retail job. Finally after almost a year and a half I decided enough is enough and I need to finish my grad school. I enrolled in a local state university and started attending the classes. After first semester, I started getting the same feelings of hopelessness and fear. I felt like this wasn’t for me and my interest in Electrical engineering was weaning. I persevered and finished the grad school in two years but was totally exhausted and felt that I didn’t deserve anything in life. That my life, my money, anything I had to offer was useless. I didn’t even make my professional resume for job hunting after graduating let alone look for or apply for one. I kept on going to the same retail job after graduating and continued until one of my family friends got me a job as a QA in a local software company. I did the job for six months but never felt any passion or motivation to learn QA stuff.  On the weekends I would lose my mind and wouldn’t know what to do with myself. So after six months I again joined the same retail job. After almost 3 years since grad school I started getting suicidal thoughts and for the first time realized that I need to go see therapist. I have been attending therapy once per week since May 2016. I was finally diagnosed with Deep depression. According to my therapist, this depression kicked off when I first came here to the United States. I also showed the symptoms of dysthymia and I probably had it since high school or freshman year undergrad. My therapist suggested that I see a psychiatrist for medication. I have been taking medication for almost a month. But just to think about that I actually blew up almost 11 years of my life to finally get some help is just mind boggling to me. Now that I’m actually working towards getting mentally fit, I wonder what can I do to actually get back on track career and life wise. I have no relevant experience in the field of EE and don’t even know if I really want to pursue it anymore. I need your advice on how to go about it. I have no social contact (friends and limited family) in my life to bounce around ideas. So I’m really confused about the future prospects. In the past year and a half I have self-studied (no certifications) to get infrastructure architect positions. I also took a 2 months long Big-data course through an Indian “consultancy” in the bay area. As of now I’m completely clueless. So any advice, suggestions, mentorship would really lift up my moral and be great help. Thanks in advance. TL DR: I came to the US for grad school on a green card. Messed up a lot of things, didn’t make sound decisions on time. Dropped out of one school and ended up finishing from another school. Got diagnosed with deep depression and dysthymia after almost 11 years. Need advice, suggestions to get back on track career/job/life wise. No real experience just the retail experience and school degree in Electrical engineering.;I'm really sorry to hear what you went through, but I'm also really happy for you that you're getting things back on track!  Looking for a direction is the best thing you can do right now.What do you like to do as a hobby?  To be 100% honest, companies like to see that you have a degree, and singe you do have a degree in an advanced field you can most likely land a job in any field you're interested in - provided, of course, that it doesn't require any specifically advanced degrees.I can't say that I'm an expert, by any means, but I would totally suggest that you search around, and apply for jobs that you're interested in - even if you don't feel qualified.. Most jobs sound more difficult on paper and (almost) every company has training!I truly hope you find what you're looking for - please keep us updated here as you continue on your journey!#Hey, sorry to hear that it took so long for you to seek help but I'm glad that you were able to do so.  To keep my answer short, I think a good fit for you to consider might be engineering sales.For engineering sales, you need to have some technical background (which you have) as well as a bit of sales/communication skills.  It sounds like you are interested in the sales part due to you repeatedly going back to retail.  This kind of position could also help you to be more sociable which may help in your personal life (getting more friends).Also, these jobs are typically easy to get as they are not classic engineering jobs (design, testing, validation, etc).  Might be worth looking into!#Thank you so much! I'm taking baby steps for now. Just posting on reddit and letting someone else know about my situation was a huge deal for me. I actually got a Meyers-Briggs evaluation and SI evaluation. But not sure what to do with it. I think i need to push little bit every time (one step at a time) I thought about the Engineering sales jobs. I'll explore more about them. Also, i have finished non paid MOOCs here and there but not sure what to do with them. Thank you guys for reading this and giving me some suggestions. I really appreciate it. 
hadoop;5ifh4d;1481775649.0;/r/hadoop/comments/5ifh4d/hadoop_certifications/;Hadoop Certifications;What hadoop/big data certifications are actually useful?I recently started a data analyst position in a big data team. There are many certifications out there available but which ones actually forces me to learn and give credential on a resume?Similarly, any advice on certifications on data science would be appreciated. My skills are all over the place right now as a recent grad.I'm looking at http://www.bigdatascienceschool.com/certifications/professional or Cloudera certification?Thanks!;"For Hadoop, the main certs are Cloudera and Hortonworks (vendor-specific implementations).I would not trust (or pay for) a certification from ""Big Data Science School"".  That sounds like something a guy is running out of his garage.#Someone who interviewed me had that on his LinkedIn. Big data Director at a huge bank. I don't know anything else about it though.Which certificates to start off which with Cloudera/Hortonworks?#For Hortonworks, there's a basic ""associate"" cert, then either a developer or administrator cert along with a couple others.http://hortonworks.com/training/certification/I haven't looked into the Cloudera ones.#Ok, thanks! I'll take a look at Hortonworks and Cloudera, and make a choice from learning content, difficulty and price."
bigdata;5ji3ch;1482296833.0;/r/bigdata/comments/5ji3ch/microsoft_azure_vs_amazon_aws_comparison_between/;Microsoft Azure vs Amazon AWS: Comparison Between Two Cloud Computing Giants and How They Support Big Data Analytics;;Direct link:http://www.evontech.com/what-we-are-saying/entry/microsoft-azure-vs-amazon-aws-comparison-between-two-cloud-computing-giants.html
German;5gk7tb;1480915886.0;/r/German/comments/5gk7tb/not_understanding_a_sentence_in_an_article_anyone/;Not understanding a sentence in an article. Anyone mind helping me out?;"Reading an article about Big Data:""Mit einem Studienkollegen stellte Kosinski eine kleine App **ins damals noch überschaubare Facebook**: Auf MyPersonality, so hiess die Applikation, konnte man eine Handvoll psychologischer Fragen aus dem Ocean-Fragebogen ausfüllen.""Bolded is the phrase in question. My understanding is ""Kolsinki created an app with a classmate that was at the time as straightforward as Facebook."" Certainly this isn't right, though. Is ""ins damals"" an expression? Thanks for any help!";"No, 'ins' is contracted 'in das' and 'in Facebook stellen' means 'to put on Facebook'. Personally I think the expression sounds slightly odd....I'd say 'auf Facebook stellen'. However, 'to put on the internet' *is* expressed as 'ins Internet stellen', so maybe whoever wrote this actually had the internet in mind.And 'straightforward' isn't really a good translation of 'überschaubar'. I'd go with 'reasonably small' or something along those lines.#Oh, I see! I knew ins was a contraction, but for some reason was reading ""stellen"" as to start/create, not put up. So it really reads something like ""With a colleague, he put an app on Facebook, which at that time was still reasonably small,"" correct?#Yup#Vielen Dank!"
cscareerquestions;5hev4l;1481302758.0;/r/cscareerquestions/comments/5hev4l/what_is_reference_databases/;"What is ""reference databases""?";I am filling up this form for an interview and I come across this question:> Do you have professional experience in the management of Big Data sets, unstructured information and **reference databases**?Can someone elaborate on what they might be referring to?Thank you.;"Maybe they meant relational databases?#Maybe it means databases filled with standard reference data for testing, like the Northwind data set.#Ask your recruiter?#Sounds like some sort of list to me. Just answer yes, and cram later #If there is something called a ""reference database"", it isn't commonly known as such."
cscareerquestions;5h25om;1481141101.0;/r/cscareerquestions/comments/5h25om/how_did_you_decide_what_to_specialize_in/;How did you decide what to specialize in?;"I have seen many times on here that good developers are ""T"" shaped, with a breadth of knowledge, and then a deeper focus in one area. I will soon be taking my first job out of school doing full-stack development in Java with Angular or React on the front end. I suppose this will start to help me with the breadth aspect, but i'm not sure how or where I want to go deep.Machine learning and big data stuff seem interesting to me. Also, I enjoy working though the DS&A problems on leetcode that everyone uses for interview prep, and wouldn't mind working in a job where I actually used those sorts of things. People who are in these sorts of jobs: what do you do? How did you get there?**TL DR:** How did you figure out what you wanted to do when you grow up, and how did you break into it?";I didn't.I haven't specialised in any way and I haven't really decided on a set career, and don't really feel a need to. That has definitely impacted on my earnings and I am probably missing some depth of knowledge, but I have benefited in terms of general job and life enjoyment and have learned things I didn't intend or expect to learn.I studied CS and psychology at uni then set out to find a job in an industry that interested me. Worked as a data analyst in the pharmaceutical industry on patient data for 6 years. Then was coming to the end of that job and still looked at health related roles, but ended up working in the games industry in a web content role. That led to an interest in testing and I am now a software tester in an industry that doesn't overly interest me, but I really enjoy my job.Health and games are still industries that interest me and I may go back to them in the future, data still interests me, and testing is something I may continue with. AI has always interested me and there's a possibility I may venture that way one day with a testing focus.If you have a specific passion then focus on it and try to get somewhere with it. If you're focussed on money then you may also be best to focus on a specific path. In my experience taking a less conventional path also works, but it really depends on what you want out of your career.#I follow my interests.
Tinder;5gb9nd;1480793716.0;/r/Tinder/comments/5gb9nd/confirmed_tinder_is_definitely_shadowbanning_me/;Confirmed: Tinder is definitely shadow-banning me;[deleted];"[deleted]#[deleted]#I know their swipe data isn't always accurate, because I've not matched with friends who have swiped on me.Shit's broken on their end.#Sheesh, why are there so many deleted comments in this sub? I'm pretty sure the chap I replied to here wasn't breaking any rules, was he?#Yeah, first tried logging out, then letting it be inactive for two months, then deleted in entirely and didn't come back for several months after that. Only thing I can think of, and it seems farfetched, is I once left an annoyed 1-star review on their app page on Google Play#[deleted]#Lol just went to check do I could send a screenshot, guess they deleted it or something. It was back when they started limiting likes and charging, and I wrote something like ""I'd rather have my semen sucked out with a catheter than pay to get more likes"". I got that line from Harlen Cohen in one of his Myron Bolitar novels."
marketing;5gn6p6;1480959127.0;/r/marketing/comments/5gn6p6/innovative_approach_big_data_can_provide_for/;Innovative approach Big Data can provide for Marketers;;This is a special quality of shit post.
politics;5iizym;1481824969.0;/r/politics/comments/5iizym/no_big_data_didnt_win_the_us_election/;No, Big Data Didn't Win the U.S. Election;;As a reminder, this subreddit [is for civil discussion.](https://www.reddit.com/r/politics/wiki/rulesandregs#wiki_please_be_civil)* Do not call other users trolls, morons, children, or anything else clever you may think of. [Personal attacks, whether explicit or implicit, are not permitted.](https://www.reddit.com/r/politics/wiki/rulesandregs#wiki_no_personal_attacks)* Do not accuse other users of being shills. If you believe that a user is a shill, the proper conduct is to report the user or send us a modmail.* In general, don't be a jerk. Don't bait people, don't use hate speech, etc. Attack ideas, not users.* Do not downvote comments because you disagree with them, and be willing to upvote quality comments whether you agree with the opinions held or not.Incivility will result in a **permanent ban** from the subreddit. If you see uncivil comments, please report them and do not reply with incivility of your own.****I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/politics) if you have any questions or concerns.*#The only thing that won the election was the russians and their hacks#Well, maybe the FBI and Trump and/or his supporters had something to do with it too.#Yes, surely the Podesta emails were so damning that they are what caused Trump to win.
datascience;5i6c56;1481664562.0;/r/datascience/comments/5i6c56/data_science_startups_in_focus_bigml_dzone_big/;Data Science Start-Ups in Focus: BigML - DZone Big Data;;
cscareerquestions;5isafz;1481941923.0;/r/cscareerquestions/comments/5isafz/my_role_for_starting_new_grad_job_this_summer/;My role for starting new grad job this summer: best fit vs. learning new technologies?;tl dr: Starting first job next month as full stack engineer, but do not know any of the technologies that I'm going to be using and would be much more suited to work on the backend team. Which team do I work for?I'm starting my new grad job next month as a Software Engineer.  My offer was to join a team that primarily works with technologies that I do not have much experience with.The office has two main engineering teams: 1. Focusing on the backend, working with big data.2. Mostly full-stack engineering, focusing on building applicationsMost of my experiences and interests align with the first team. I love working with the technologies they use and I would love to get more experience with big data. However, my offer was to join the second team. Although I'm familiar with what all the technologies are that the second team uses, I do not have much experience with any of them. My manager said that it is very possible to switch to team one if I really wanted to, although she seemed to think I'd do fine if I stayed with team two.I completely understand that I'm going to be learning a ton and should expect to learn new languages and technologies all the time, but I was hoping to get some advice on which team I would benefit more from joining.Do I look like an idiot starting out not knowing hardly anything about the technologies just to eventually learn much more about a wider range of technologies, developing my skills as a full stack engineer? Or should I join the team that is by far a better fit for my experiences and contribute much more to the office? ;No, you won't look like an idiot because they don't expect a recent grad to have a bunch of experience.Pick the team that is doing the work/projects you're most interested in, and that you think will help you learn and grow as fast as possible.#I completely agree with what u/Riimii said. Growth is far more important than best fit, especially if your manager seemed to understand that you don't have a lot of experience with that stuff.What I'm interested in (and I'm sure you are too) is what are more valuable qualities to develop as a software engineer: backend and big data development, or full stack development. I'd think that developing full stack skills is much more beneficial, but I honestly don't know. Does anyone have input on this?
cscareerquestions;5ilbs2;1481849484.0;/r/cscareerquestions/comments/5ilbs2/im_considering_moving_to_the_states_from_ireland/;I'm considering moving to the States from Ireland. But I haven't had any luck with job applications so far. Is it even worth applying for jobs before I go over?;"I'm a recent graduate (23), with a Masters in Software Design & Development. My thesis received the third highest mark in my class, which I wrote while working on a 12 month internship for a global enterprise services company. My research was in the areas of machine learning and data analytics. I developed sales forecasting models to perform predictive analytics on the company's sales data, and developed an algorithm to identify the most influential factors within each opportunity. My manager loved me, and would provide me with an excellent reference if needed.I've got what I would consider to be a pretty good CV. I participated in two hackathons while on my internship, where I was on the winning team for both (one was an international hackthon involving multiple company sites). I've been looking and applying for some data analytics/data scientist/big data developer roles in California. However I'm receiving no luck with these applications, all I ever get is the ""we've received your application and will respond if you're a match"" email. I guess I'm just looking for advice on whether it's worth my time to keep applying for roles that interest me, or is the fact that I'm not currently living the states a factor that's going against me in these applications? I also know California is extremely competitive for IT people, but I'm just curious about whether the companies think I'm not suited for the role, or that I may be suited, but since I'm in Ireland right now, it's not worth the effort of contacting me.So if anyone has any advice/tips on this situation, I'd love to hear them.EDIT: I don't have any issues with visas. There's a graduate visa you can get in Ireland that will sponsor you for 1 year, on the condition you find work in your degree field within 3 months of arriving. If you want to stay longer than 1 year, your work must sponsor afterwards. I can also go without needing the graduate visa if the company is willing to sponsor me instead. If it looks like my job prospects are good, I'd apply for it ASAP.";"Look at visa H-1B before doing anything. You can't just go to state without a relative and just ""live"" there. H-1B have a very specific request date range and I know now we are not in (they are probably all given for this years). The general idea is that : 1) you need a sponsor (see job offer) 2) you pay ~10k (some company will pay that for you) 3) you can't start before the date your visa start. They have a limited amount of visa and they are ""sold-out"" very early on. You need a job offer ready before they open visa, then I think around October they start to deliver them. If you miss the boat you gotta have to wait a full year. (Note : I wan't to go to US from Canada, I graduate my master off dates, I have to push my project to 2018)#I did a quick search about the visa, and the visa only allows you to apply for internships.  This might be the reason why you're not having a lot of luck.Does the position in the US have to be an Internship placement?    Yes, your placement in the US must be an Internship. It cannot be replacing American workers or filling a general labour need. #Oh sorry I probably should have said it in my description. I know all the craic with the visas. We have a graduate visa in Ireland that lets you go to the states for a year on the condition that you find work in your degree field within 3 months of arriving. My question is geared more towards whether I should apply for jobs now (while awaiting my visa), or after I arrive in the states.#I called the visa company today actually to check on this and you are correct. There is a separate internship visa you can get while still in college, and I was under the impression that the graduate visa was for full time work. My bad. I'll look up where and how to apply for 12 months internships in the states so !"
cscareerquestions;5hs3xh;1481487309.0;/r/cscareerquestions/comments/5hs3xh/a_little_advice_what_do_you_guys_think/;A little advice? What do you guys think?;Hey guys,I have a BS in Physics and Math and going my MS program in Comp Sci both degree BS and MS are from an average school, Loyola Univesity Chicago. I already took intro to programming, data structures, undergrad algorithms. Did pretty level in my pre-req. courses. I have two co-op done, one DBA and another programming internship. I also have 2 years undergrad research done in (tangent) Big data. Currently, applying to more internships for the summer 2017, have gotten a few calls back (coding interviews) and also faced rejections too. I have a github (somewhat active), LinkedIn, been active in both on-campus and off-campus hackathons (website and app). I also working for the IT department on campus 15/hr week right now, Tier 1 helpdesk. Trying to pick-up a second job too (can't afford tuition). I am also working on side projects to which I can add to my resume.In case you are wondering: BS Physics and Math gpa: ~3.0 undergrad comp sci gpa: 4.0 Grad school gpa: 3.5I have also seen my classmate, with BS in Physics and Comp Sci. end up at places such as HP, BP, Google, Abbott etc.I just don't want to go through the same things I did after getting my BS (unemployed for a long time).I am worried bc Loyola University Chicago doesn't have a solid reputation, I wouldn't find a job when I graduate in May 2018 in the software field (developer, engineer, etc).Any tips or advice would be great or comments appreciate it.;You don't need another degree when you have one in Math AND Physics. Just keep doing what you're doing and applying to jobs. #Well everyone wants a CS degree thats why i had to go back #I recommend you at least watch this videohttps://youtu.be/_FioceDs7JAGood luck with whatever you do man
cscareerquestions;5hpgyb;1481450902.0;/r/cscareerquestions/comments/5hpgyb/deciding_between_bioinformatics_data_science_cs/;Deciding between Bioinformatics, Data Science, CS masters?;I'm currently a biochem major graduating this Spring from undergrad. I have interest in bioinformatics, data science and possibly computer science. My main goal is to be involved somewhere in big data in biomedicine, digital health and technology, personalized medicine, or genomics. I have a pretty strong research background in pharmacology/infectious diseases (also clinical research). So I'm getting the chance to do a paid research opportunity this upcoming summer after graduation for big data in medicine (studying cancer using machine learning, modeling). I've no idea what to do after the program ends in August. Should I find other potential research opportunities? What are potential jobs I should look at? Should I start a master's program right away or after a year or two? If anyone could give me some advice in a direction to go? I have some basic understanding of python. I believe these masters programs may require courses I'll have to take post-bac (discrete math, data structures, linear algebra, other languages etc.). All I've taken so far as an undergrad is Calc, Basic stats, and a programming class in python. ;You have a lot of background in bio so bioinformatics will be particularly waste of time. Data Science is for those who know CS otherwise it's impossible to become the great data scientist.So if you get master, get CS one. The problem is you might not like it.#Why is a master's in bioinformatics a waste of time?#this guy is commenting without any base knowledge of bioinformatics.  a BI degree seems great for you, and typically will not cover much bio but will go in depth in CS and bioinformatics related programming / data, genomics,  machine learning, object oriented programming, etc.  it kind of depends on your program, so really look into each program and see which one pairs best with your backgroundI have a MSc in Bioinformatics but it really is a CS degree at the end of the day, I can go into data science or software engineering but I work as a BI software engineer (analyst) and I love my job.  good luck OP#Because you know 'bio' so the 'bio' part will be useless for you I guess.
docker;5ioanw;1481895644.0;/r/docker/comments/5ioanw/docker_yarn_apache_slider/;Docker + Yarn + Apache Slider;Hi all, I am investigating the usage of Docker containers on the top of a YARN cluster by means of Apache Slider (see, e.g., http://www.slideshare.net/hortonworks/docker-on-slider-45493303). It seems to be a hot topic in the Big Data arena: http://conferences.oreilly.com/strata/strata-ca/public/schedule/detail/55936. Does anybody have any experience with this kind of setup? Do you recommend it for production environments?Thanks a lot for your help.;I haven't seen Slider + YARN yet, but I imagine the Mesos world may be a good area to investigate first.They seem to have a head start on containers + Java tie ins.#Are you suggesting to go for something like this http://mesos.apache.org/documentation/latest/docker-containerizer/?Any ideas about its maturity level?Thanks a lot.
trianglejobs;5hyh5x;1481569399.0;/r/trianglejobs/comments/5hyh5x/hiring_principal_software_engineer_and_senior/;[HIRING] Principal Software Engineer and Senior Front-End Engineer to play with Scala, Java, Hadoop and Big Data on the back, React/Redux and D3 on the front. Direct hire in Cary, NC!;Hi there!This role has been open for a little while with a startup that is based in Cambridge and making its 2nd office here in Cary. They have been searching for Senior front-end and big data back-end engineers for a little while and I thought it was a good opportunity to present to /r/trianglejobs! [HireNetworks, the small recruiting agency that happily employs me](http://www.hirenetworks.com/) has helped 9 redditors get jobs with our clients this year.The Principal Software Engineer role is a good fit for Senior engineers who want to play with Scala, Java, Hadoop and big data application engineering. You will be a principal, meaning you help lead decisions on technology uses and mentor junior developers in this role. 6+ years of experience is required, as well as at least a Bachelors Degree and the ability to brag on some significant cool things you've done in your work history. The hiring manager requires a degree from every candidate, so unfortunately this is not a flexible requirement. The Senior Front-End role is perfect for a JavaScript junky who enjoys working with React and Redux or has a serious penchance for Angular and likes to see their code actually get shipped and used by consumers. Again, the hiring manager is looking for folks who have Bachelors degrees and some cool work accomplishments to show off! If either of these sound good for your next step or a friend's, PM me and I can get you more details and introduce you to a hiring manager! The roles are both direct hire and offering salaries from $90,000 - $120,000 with generous benefits... They are on-site at the Cary office. PM me for details!;Might have a hard time finding quality devs with 6+ yrs experience at that range. Pretty low compared to the market right now. #Thanks for the feedback. Most of the folks I've submitted are in the $110-120k range, but there have been a few that needed to make a little more to make a move. What would you say is more market? $115-130k? 2 people have been in the 90-100k range but were not Senior enough, so I think you're right.
datascience;5hu47r;1481510173.0;/r/datascience/comments/5hu47r/big_data_technique_random_sampling/;Big Data Technique: Random Sampling;;
analytics;5h1rfl;1481137266.0;/r/analytics/comments/5h1rfl/sql_is_still_superior_for_bigdata_analytics/;SQL is still superior for big-data analytics;;
bigdata;5i31an;1481627409.0;/r/bigdata/comments/5i31an/big_data_a_game_changer_in_healthcare/;Big Data: A Game Changer in Healthcare;;"The only part worth reading from that link ""The Pittsburgh Health Data Alliance aims to compile data from various sources (including medical and insurance records, wearable sensors, genetic data and even social media use) to draw a comprehensive picture of the patient as an individual, and then offer a tailored healthcare package.  I predict that more and more services like this will emerge in the future."""
bigdata;5htbbe;1481500554.0;/r/bigdata/comments/5htbbe/is_it_a_good_idea_to_shoot_for_a_masters_degree/;Is it a good idea to shoot for a master's degree in statistics after I complete bachelor's in computer science, or should I get a double bachelor's in both statistics and computer science first?;"Basically I only have 1 year of school left. The double major will take 1 extra year.Another option is to just minor in computer science, and major in statistics which will take the same amount of time if I just majored in CS.My only concern with the latter option is if I don't get accepted into a graduate program then I'll be left with a bachelor's degree that has less market value (?) than a bachelor's CS degree.I currently have a 2.8. But after this semester (4 As, 2 Bs  possibly 5 As and 1 B) it might bump up to a 3.00+? Not sure if low 3.00s is enough. Basically I didn't care about GPA and didn't know what I wanted to do during my first 4 years at a community college.My career goal is to work in the ""data science"" / ""big data"" field.If a double bachelor's degree and maybe personal projects is enough to get my foot in the door then I'll forget about trying to go for graduate school. Otherwise, my current goal is trying to get a master's degree in statistics.";I would suggest you to get a CS degree but also take Statistics courses, this will atleast get you a degree that can help you qualify for a wide variety of jobs. If you get accepted into grad school, then you can take Machine Learning and BigData classes.
bigdata;5gfe83;1480857802.0;/r/bigdata/comments/5gfe83/cep_patterns_for_stream_analytics_dzone_big_data/;CEP Patterns for Stream Analytics - DZone Big Data;;
growmybusiness;5gwqhz;1481071358.0;/r/growmybusiness/comments/5gwqhz/feedback_review_about_my_strategy/;[Feedback] Review about my strategy;[deleted];Where are you from homie? I don't really understand what you're asking. You spent $9 and you're surprised you didn't make any money? I spend $50 a DAY on adwords alone...
learnpython;5gy4xp;1481088238.0;/r/learnpython/comments/5gy4xp/please_recommend_a_good_source_to_read_about_data/;Please recommend a good source to read about data visualisation.;Be it a book or online lectures. I have just started up and need to develop a data visualisation product. I already have good primary data to start with. P.S: This post might be off topic for this subreddit but I guess we have a community here that solves problems with big data using Python. ;You could browse the [seaborn](http://seaborn.pydata.org/examples/index.html) gallery for some nice examples on how to plot different types of data, but if you're looking for a more general idea on how to make good visualizations maybe check out some ideas from Edward Tufte.
BigDataJobs;5gy1dl;1481086945.0;/r/BigDataJobs/comments/5gy1dl/seeking_sales_engineer_for_big_data_provider/;Seeking Sales Engineer for Big Data Provider;;That's it? One small, incomplete sentence and no description?#Clicking on the link that the small, incomplete sentence is tied to produces a much longer post with many sentences and a description. 
datascience_at;5gutdz;1481051920.0;/r/datascience_at/comments/5gutdz/anomaly_detection_using_h2o_deep_learning_dzone/;Anomaly Detection Using H2O Deep Learning - DZone Big Data;;
HomeworkHelp;5i6ly3;1481667278.0;/r/HomeworkHelp/comments/5i6ly3/high_school_english_essay_essay_about_big_data/;[High School English essay] Essay about 'Big Data';Hello, I've written this essay based on a documentary we've watched in class, called *The Age of Big Data*, and I'd like some different eyes on it, preferably from someone who speaks english as their native language, which I do not by the way. Of course it's difficult for you to comment in terms of contents, as you haven't seen the documentary, but I'm mostly looking for advice in terms of writing. Please let me know if there's anything that was difficult to understand or could use some editing. I hope the format isn't too messed up. ..***The Age of Big Data***We have seen this documentary created by BBC in 2012 called ‘The Age of Big Data’. It covers various uses of data, available to us - made possible by collecting and analyzing data, and summarizing it into useful information, often in the form of patterns. This term is often referred to as data mining and is predicted to be one of the greatest sources of power in the 21st century. This correlates with the fact, that we have produced more data in the last few years than in all of human history, and we are not about to slow down anytime soon. In the documentary we are presented with five different uses of data mining  The police of Los Angeles using it to predict where crime is most likely to occur, biological uses of data by analyzing different factors like death causes and DNA and using it to diagnose and treat illnesses. It also went over data being used to personalize advertisements by predicting what people might want to buy - sometimes before they know it themselves. Lastly, it covers the application of data in astronomy, where they ‘listen’ to stars via telescopes, in order to unlock the secret of the universe. I will be focusing mostly on the first one, about the police and their way of incorporating data in the battle against crime, since this is a usage I had no trouble wrapping my head around, unlike some of the others, which I find a little abstract. The majority of my points will be applicable to all uses of data though. .I think there are some clear positives and negatives with data mining. Let us start with the positives, the first one being the ability to predict where crime is most likely to occur within the next 12 hours. It works much like a weather forecast, telling us what we can expect, which is not always what ends up happening, but it is fairly accurate.Secondly, the predictions are only going to become more reliable as we gather even more data. The algorithm used by the LAPD is based on 13 million past crimes, a number that is (sadly) only going to increase, giving us a larger sample size to build our predictions on. We also have some negative effects as well, one of them being that the predictions are not always correct, which could lead to a non-optimal distribution of officers if some of them are guarding the ‘hotspots’, while crime is happening elsewhere. Some police officers have also expressed their discontent with this, as they do not like being “controlled” by a computer, and would rather work by their instinct and experience, like they have always done. Another thing to keep in mind is the risk of the criminals figuring out the pattern, and using it to their advantage. .It is clear, that there are both plusses and minuses to ‘big data’. Personally, I am all for taking advantage of data mining, and I think it will be an important tool in the future for learning about ourselves, our planet, and the universe surrounding it, but we have to be cautious as well. We could easily become too dependent on algorithms making every decision for us, based on which option has the highest probability of a positive outcome. Do we really want an equation controlling our life?;"Don't use ""we"", ""you"", ""I"". So in your second sentence you'd say ""...data, available to everyone/available to anyone/available to people, but not ""us"".  Avoid making reference to the fact that you and others watched/read a source unless you must. Address the video directly (such as ""as was mentioned in ""big data""..."" but not ""what was learned from watching this video was"").You need a source for the statement ""predicted to be one of the greatest powers..."" If you reference the movie for that, cite it.If you need more help with the rest I may be able to add more later."
ITCareerQuestions;5ha4ad;1481237174.0;/r/ITCareerQuestions/comments/5ha4ad/msp_or_mct/;MSP or MCT?;"I need some fresh perspective.  Im a certified Linux admin, exchange admin, Microsoft trainer, CompTIA trainer, data center technical specialist.. along with a handful of Microsoft certs.. 11 total.I moved to Utah 3-4 months ago because girl and culture in general.  Working at an MSP currently, pretty decent pay (60k).I have two children back east, and am being offered a position in Boston as a ""big data"" MCT.  AWS and Azure. The pay raise is negated by cost of living basically.What would you do?  Fly the kids out, enjoy the culture of SLC, and stick with MSP work?  Or be closer to family, work with big data, and suffer through the pretentious east coast culture?";If my family wasn't back east.... I wouldn't have come back. If you can move them to you, that's the road I would go. You'll be doubling your salary in 2-3 years wherever you are as long as you stay driven and move towards management I would assume.#I would do what makes me happy.  I moved away from family to be in an area that I liked and realized that I really didn't see them that much when I did live close by.  For you it sounds like staying in SLC is the answer.
datascience;5h1mm2;1481135958.0;/r/datascience/comments/5h1mm2/sql_is_still_superior_for_bigdata_analytics/;SQL is still superior for big-data analytics;;
askphilosophy;5hcro6;1481273134.0;/r/askphilosophy/comments/5hcro6/big_data_future_scenarios/;Big Data: future scenarios;What are the worst case scenarios regarding Big Data in the future? With all of our information managed by governments and companies which will be the implications for us, are we giving up our privacy? Why do we want privacy if we are not doing anything wrong?;"information has value. is  information only of tactical value in a modern society because of morality, shame, and guilt? what if we didn’t feel bad when information about us leaked to people. would privacy be an issue in a completely moral society? is there morality in secrets? in the things that we don’t do? i understand the impulse of the individual to be private, at least in a logical sense. if we were all to develop identical perceptions of a strict set of norms, a desire to conscientiously, diligently, punctiliously, and zealously enforce and individually follow them, perhaps. And you know, it is possible that happens in the future. I mean think of how far we have come in that direction. We were once disparate groups of primates wandering the world, forming their own norms and perceptions of the world, with no communication. I imagine, with such isolation, things got weird. like really weird.imagine being in the early holocene. you are some kind of intelligent hominid that is just deciding,"" you know what, this year, we should probably have more vegetables. it’s getting harder to find enough meat to feed this many people, and we’re no longer just competing with the animals, we are competing against those folks in the next valley who try to kill us every time they see us. maybe it would be better if we figured out how to grow those edible plants nearer to us, so we don’t run into them as often, and it is easier to feed ourselves. it doesn’t have to be that organized, but as long as there are trees and edible plants somewhere we can defend and protect it easily,  we could probably manage.” then, at some point, populations became bigger, territory expanded, different norms came into contact with each other, and boom, here we are today, with a global society that cannot agree on most things. are any of us truly moral? hard to say, probably not. I mean there are definitely some good people out there who have never done anything wrong, but they are a vast minority. for the rest of us, sharing all of our information doesn’t look as harmless. I would rather not have everyone know what I do, regardless of whether or not it is good or bad, what I do on my own time is my own. It is not for other people. Giving that solitude up means that my actions would probably be hindered by fears of social punishment or ostracism   by others. there would be nowhere to be weird anymore, and honestly, most progress comes from someone or a group of people bucking norms and saying “Hey, I know I/We/This idea is weird and different, but you should check us/it out. we might be onto something here”. what if that kind of ingenuity and intellectual and social progress was stifled? we would probably stagnate as a race, and we would never have a chance of reaching that world of no evil. so why do we want privacy? because doing wrong things (not evil things, but wrong things) can be very good, even if the world isn’t ready for them. things like big data can be amazing- but if used to surveil and monitor a population to the point where privacy is nonexistent, and all information is public to some degree, then it could be the most dangerous weapon on earth, because it could quash the weird, or the misunderstood, and halt all human progress indefinitely, or, in a nightmare scenario, could be used by someone evil to accomplish evil ends."
stocks;5j0tzz;1482077159.0;/r/stocks/comments/5j0tzz/discussion_reliq_health_technologies_cverht/;[Discussion] Reliq Health Technologies (CVE:RHT);[deleted];So is it basically a more inclusive Zocdoc?#Slightly similar in function, however RHT has so far focused on monitoring patients as a form of follow-up service  patients are monitored by the doctors who are already working on their case, and have their treatment kept on track once back in their community.Where Zocdoc is about finding a clinician in the first place, RHT is about maintaining outpatient care following an admission to hospital, and integrating the already existing circle of care at home with the healthcare professionals they will have worked with whilst admitted. 
SJSU;5i6mju;1481667443.0;/r/SJSU/comments/5i6mju/opinions_on_the_big_data_certificate_offered_by/;Opinions on the big data Certificate offered by the School of Information?;[removed];
rutgers;5jnxtt;1482371902.0;/r/rutgers/comments/5jnxtt/difficulty_of_economic_forecasting_and_big_data/;Difficulty of Economic Forecasting and Big Data (Landon-Lane)?;[deleted];
PoliticalVideo;5gpue4;1480986070.0;/r/PoliticalVideo/comments/5gpue4/the_power_of_big_data_and_psychographics_keynote/;The Power of Big Data and Psychographics. Keynote of Alexander Nix from Cambridge Analytica - the company behind Brexit and Trump's campaign.;;See articles and links compiled in this threadhttps://twitter.com/gracelynhigdon/status/805404849173131264#This video was 11 minutes and now it's only 52 seconds.  Where's the original?#I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit:- [/r/politicalvideo] [This video was clipped from 10:00 to 52 seconds, apparently just last week. Does anyone have a mirror?](https://np.reddit.com/r/PoliticalVideo/comments/62lf8h/this_video_was_clipped_from_1000_to_52_seconds/)[](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*[](#bot)
Bitcoin;5gz7ca;1481106565.0;/r/Bitcoin/comments/5gz7ca/chinas_jingdong_to_build_big_data_ecosystem_using/;China’s JingDong to Build Big Data Ecosystem using Blockchain Technology;;
dataisbeautiful;5hg4rz;1481315610.0;/r/dataisbeautiful/comments/5hg4rz/hadoop_training_online_big_data_certification/;Hadoop Training Online, Big Data Certification Course in New York;;
explainlikeimfive;5h25l5;1481141073.0;/r/explainlikeimfive/comments/5h25l5/eli5_has_a_picture_on_the_mainstream_internet/;"ELI5: Has a picture on the ""mainstream"" Internet ever been lost?";[removed];Your submission has been removed for the following reason(s):ELI5 is for questions with objective explanations.Straightforward answers or facts - ELI5 is for requesting an explanation of a concept, not a simple straightforward answer * Recommended subreddit(s): /r/answers---*Please refer to our [detailed rules](http://www.reddit.com/r/explainlikeimfive/about/rules)*.#Yes, tons of data has been irretrievably lost before, and that certainly includes some pictures. Here's an article about a few cases:https://www.r1soft.com/blog/6-notorious-cases-of-data-loss-all-hosting-providers-can-learn-fromIf a picture or other piece of data is on the public web so that anyone can access it, and any search engine can crawl it, the chances of it being lost forever go way down. The more popular it is, the chances go almost to zero. I know lots of people who accidentally deleted data and recovered it thanks to Google's cache or archive.org.If the data is private, though, then it's quite possible for it to be lost.#I can't see how it could happen. Big companies have their data backed up in multiple locations to prevent just that from happening
politics;5ggnyi;1480874465.0;/r/politics/comments/5ggnyi/the_power_of_big_data_and_psychographics/;The Power of Big Data and Psychographics;;As a reminder, this subreddit [is for civil discussion.](https://www.reddit.com/r/politics/wiki/rulesandregs#wiki_please_be_civil)* Do not call other users trolls, morons, children, or anything else clever you may think of. [Personal attacks, whether explicit or implicit, are not permitted.](https://www.reddit.com/r/politics/wiki/rulesandregs#wiki_no_personal_attacks)* Do not accuse other users of being shills. If you believe that a user is a shill, the proper conduct is to report the user or send us a modmail.* In general, don't be a jerk. Don't bait people, don't use hate speech, etc. Attack ideas, not users.* Do not downvote comments because you disagree with them, and be willing to upvote quality comments whether you agree with the opinions held or not.Incivility results in escalating bans from the subreddit. If you see uncivil comments, please report them and do not reply with incivility of your own.****I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/politics) if you have any questions or concerns.*#Fun Fact: Cambridge Analytica has worked for the Trump and Brexit campaigns too[https://en.wikipedia.org/wiki/Cambridge_Analytica](https://en.wikipedia.org/wiki/Cambridge_Analytica)#Not a fan of videos: what are 'psychographics'?#Hi `theArkotect`. Thank you for participating in /r/Politics. However, [your submission](https://www.reddit.com/r/politics/comments/5ggnyi/the_power_of_big_data_and_psychographics/) has been removed for the following reason(s):* [Off-Topic](http://www.reddit.com/r/politics/wiki/rulesandregs#wiki_the_.2Fr.2Fpolitics_on_topic_statement): All submissions to /r/politics need to be explicitly about **current US politics**.* Non-political news should be posted to /r/news or to a state- or city-specific subreddit If you have any questions about this removal, please feel free to [message the moderators.](https://www.reddit.com/message/compose?to=/r/politics&subject=Question regarding the removal of this submission by /u/theArkotect&message=I have a question regarding the removal of this [submission.](https://www.reddit.com/r/politics/comments/5ggnyi/the_power_of_big_data_and_psychographics/?context=10000\))#data visualization of psychological profilesEDIT: I assume
politics;5gfoxr;1480862590.0;/r/politics/comments/5gfoxr/big_data_helped_trump_even_after_he_scorned_it/;Big data helped Trump even after he scorned it;[deleted];As a reminder, this subreddit [is for civil discussion.](https://www.reddit.com/r/politics/wiki/rulesandregs#wiki_please_be_civil)* Do not call other users trolls, morons, children, or anything else clever you may think of. [Personal attacks, whether explicit or implicit, are not permitted.](https://www.reddit.com/r/politics/wiki/rulesandregs#wiki_no_personal_attacks)* Do not accuse other users of being shills. If you believe that a user is a shill, the proper conduct is to report the user or send us a modmail.* In general, don't be a jerk. Don't bait people, don't use hate speech, etc. Attack ideas, not users.* Do not downvote comments because you disagree with them, and be willing to upvote quality comments whether you agree with the opinions held or not.Incivility results in escalating bans from the subreddit. If you see uncivil comments, please report them and do not reply with incivility of your own.****I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/politics) if you have any questions or concerns.*
longtext;5ij3bp;1481825884.0;/r/longtext/comments/5ij3bp/big_data_are_reducing_homicides_in_cities_across/;Big Data Are Reducing Homicides in Cities across the Americas;;
IndieDev;5ii12y;1481814948.0;/r/IndieDev/comments/5ii12y/big_data_analytics_offers_the_possibility_of/;Big Data Analytics offers the possibility of understanding the pattern of engaged users for mobile application owner or marketer;;
OnePieceTC;5gw7gf;1481065594.0;/r/OnePieceTC/comments/5gw7gf/do_u_have_to_always_download_the_big_1gb_data/;Do u have to always download the big 1GB data?;[removed];If you're rerolling, you probably want to reroll after your initial rare recruit if it's not a good starter. Definitely don't go through the doom tap if your first roll is garbage.#There's an easier way to do it in the rerolling guide but requires a few things.#nice glad to know i can get someone good with the 5 free gems u get after tutorial and am i aiming for a sumo rare or a 5* luffy? cause he is my favorite
datascience;5i31cr;1481627432.0;/r/datascience/comments/5i31cr/hi_guys_id_like_to_hear_your_feedback_on_a/;Hi guys, I'd like to hear your feedback on a potential book cover for a book that I'm writing. Please let me know which option you like, or feel free to offer alternatives. Thanks for helping;The Money is in the Data: An Entry-Level Introduction to Big DataData Literacy: An Introduction to Big DataDon't be Scared by Data Science: An Introduction to Big DataA Gentle Introduction to Big DataHarnessing Big Data: A Simple Introduction;Will the book feature a section on how to best obtain results via survey?  #Or a section on using double line returns in Markdown?
datascience;5guqag;1481051087.0;/r/datascience/comments/5guqag/anomaly_detection_using_h2o_deep_learning_dzone/;Anomaly Detection Using H2O Deep Learning - DZone Big Data;;
datascience;5ggzct;1480877854.0;/r/datascience/comments/5ggzct/cep_patterns_for_stream_analytics_dzone_big_data/;CEP Patterns for Stream Analytics - DZone Big Data;;
SuggestALaptop;5jge12;1482274540.0;/r/SuggestALaptop/comments/5jge12/looking_for_a_laptop_similar_to_the_asus_k501uq/;Looking for a laptop similar to the ASUS K501UQ for data science programming and possibly gaming;"I recently bought an ASUS K501UQ off Amazon since there was a deal on it where it was ~€900 (roughly 150-200) cheaper than any other shop I'd looked it up in. However the courier mishandled the package and it arrived damaged, so I'm getting my money back, but they have no others in stock to send me. So I'm looking for an alternative to it. It had the exact same specs as [this](http://www.pcworld.ie/product/asus-k501uq-156-laptop-grey/332174/396.0.0) model.* **Total budget and country of purchase:** Ireland, €800-€900* **Do you prefer a 2 in 1 form factor, good battery life or best specifications to your requirements for the money? Pick or include any that apply.** I already have a surface pro 4, so no need for the 2 in 1. I'd like as good as battery life as I can get while not compromising on the specs.* **How important is weight to you?**It's not crucial, but I also don't want to be carrying a brick around.* **Which OS do you require? Windows, Linux, Mac.**Windows, but will probably install Linux on it at some point too.* **Do you have a preferred screen size? If indifferent, put N/A.** 15.6"" preferably* **Are you doing any CAD/video editing/photo editing/gaming? List which programs/games you desire to run. If you have no requirements, put N/A.** I am a graduate data scientist, so mostly I would like to use this laptop for programming and development. Would be running big data tools such as Hadoop, Spark, Kafka, Zookeeper etc, along with programming IDEs such as Intellij, Eclipse and RStudio. I would like to be able to game with it, since I kind of assumed a laptop capable of running those big data tools such be able to handle the processing power needed for gaming. So while a dedicated graphics card is not essential, it would be preferred. Only photo editing software I'd be running would be GIMP.* **If you're gaming (leave blank if you put N/A above...), do you have certain games you want to play? At what settings and FPS do you want?** Games like Portal, Arkham Batman games, Far Cry etc. I'm not an avid PC gamer, so what ever the best settings/FPS I can get, I'll take.* **Any specific requirements such as good keyboard, reliable business grade build quality, touch-screen, finger-print reader, optical drive or good input devices (keyboard/touchpad)?**  Will need a good processor (i5 or i7), and at least 8GB of RAM (would like one that can be upgraded if 8 is what it comes with). Would also like it to have an SSD. * **Leave any finishing thoughts here that you may feel are necessary and beneficial to the discussion.**I think I've pretty much covered what I will be doing with it, so I'll leave it up to your suggestions.";
copypasta;5g1cwi;1480653110.0;/r/copypasta/comments/5g1cwi/the_highestvoted_questions_from_each_stack/;The highest-voted questions from each Stack Exchange site, sorted by site name;[deleted];"How do I give 3D-printed parts in PLA a shiny smooth finish? How should I deal with discouragement as a graduate student? Could a paradox kill an AI? Do different beer glass shapes really make a difference in taste? How do I root my Android device? What differentiates anime from regular cartoons? Got any tips or tricks for Terminal in Mac OS X? Can I program for Arduino without having a real board? How do I keep my smart lightbulb from telling its manufacturer every time I leave the house? How loud would the Sun be? What is the dark spot visible below the cockpit on A-10s? Why ride a fixed-gear bike? Why do I only breathe out of one nostril? What is a good way to concisely explain Bitcoin? Can Blender render pngs with the background transparent? How can I beat ""Big Money"" in Dominion? How much usage can a LEGO piece take before it loses its ""clutch power""? Can the Buddha ever be a woman? Why is gold golden? When is castling possible? Is there a lot of value in learning to write Chinese characters? Can I belive in evolution and still be a Christian? How is CiviCRM different in Drupal, Joomla, and WordPress? Most creative way to display 42? which is better to avoid? How can I figure out how much caffeine is in my cup? How is it that taking a break from a problem sometimes allows you to figure out the answer? Why do Internet forums tend to prohibit responsing to inactive threads? How is Gaussian Blur Implemented? How can I chop onions without crying? What's the best practice for handling data migration and organization across development environments? How to cut a tiny circle in paper? Should we MAC-then-encrypt or encrypt-then-MAC? Why is quicksort better than other sorting algorithms in practice? What's new in purely functional data structures since Okasaki? How big is big data? How do I list all databases and tables using psql? What is the purpose of these holes on my wire stripper? What are the recommended directory permissions? ""River"" detection in text? impossible or improbable? Is there any software that facilitates scanning of a paper book into an ebook? How will non-rich citizens make a living if jobs keep getting replaced by robots and are outsourced? What is it that strips vocals from audio when a 1/8"" audio jack is partially unplugged? One of my apps has a second, fuzzy icon in Plank. How can I workaround this? How does the ""Dalai Lama walks into a pizza shop..."" joke work? What are the practical differences between the various Emacs Package Repositories? Why do glass windows still exist? How do you quote a passage that has used ""[sic]"" mistakenly? ¿Por qué mis programas no pueden hacer cálculos aritméticos correctamente? Does Esperanto have a gender-neutral pronoun that can be used for humans? Why does Ethereum plan to move to Proof of Stake? How important is knowing German in Germany? List of Resources for EE developers and users? Is it healthy to exercise a muscle when it's still sore? How do I get my first job at a freelancing site? Pourquoi place-t-on une espace avant les ponctuations fortes ? How can I effectively manage a hobby game project? How can I tell if a corpse is safe to eat? Can weeds be put into compost, or will they grow again when the compost is used? Should I use the modern (what it is called now) or historical (what it was called) place name? How can I better learn noun genders? Measuring accuracy of latitude and longitude? What is wrong with Comic Sans? Why is Morse Code still in use? Keyboard for programmers? How can I protect my eyesight when using computers? ""A god"" or ""God"" in John 1:1? Why do Hindus believe in cremation instead of burial? Why did Hitler attack the Soviet Union when he was still busy fighting the United Kingdom? What equipment do I need to buy to start making beer? What famous theorems or results were proven by female mathematicians? Is evolution compatible with Islam? Can I say bravo to a female performer? ２次元配列は不連続か? What's the difference between は and が? What is the proper way to make an AJAX call in component? Does ""reputation scoring"" make ""the Torah a crown to magnify yourself with""? Is there an easy way to tell whether any given Korean name is typically male or female? Are there any studies which address the effectiveness of studying multiple related languages simultaneously? Are ""-que"" and ""et"" equivalent? Why are lawyers typically excluded from juries? How can I keep my cat off my keyboard? What characteristics are unique to English (or at least rare among language as a whole)? Security Patch SUPEE-7405 - possible problems? How do you prepare for the stress of a real-life defense situation? Can I use my powers for good? What female mathematician can I introduce to my High School students? Where can I find examples of good Mathematica programming practice? Polynomial bijection from ℚ×ℚ to ℚ? Why is plexiglass not used for car windows? Could we please be a bit nicer to new users? How does Monero privacy and security compare to Zcash? Best way to start investing, for a young person just starting their career? What caused and ended the time loop in Groundhog Day? Why do minor keys sound ""sad""? What does it mean for an album to be remastered? When and how did the Greek mythos transfer to the Romans? Why do we need a 3-way handshake? Why not just 2-way? A database of open databases? How to contribute to Open Source as a non-programmer? What is the most efficient food to take for a 12-15 day hiking trip? What to do with my pre-teen daughter who has been out of control since a severe accident? How to torpedo a bad patent my former large employer is filing? Why does my cat keep patting my face? Was mathematics invented or discovered? Good examples of RAW's advantages over JPEG? Can I compute the mass of a coun based on the sound of its fall? Why use story points instead of hours for estimating? How to deal with people who randomly go all-in? Why were pre-election polls and forecast models so wrong about Donald Trump? Como usar corretamente ""por que, por quê, porque ou porquê""? How do I get myself out of bed in the morning? Como fazer hash de senhas de forma segura? Is this Tetris puzzle solvable? What data sources are available online? Is the Raspberry Pi suitable for running continuously, 24/7? How can tilting a N64 cartridge cause such subtle glitches? Is there any disassembler to rival IDA Pro? Why are Mars rovers so slow? How do I get my PCs to not be a bunch of murderous cretins? Для чего нужны свойства? Чайник остывает или не остывает? Why does ""охуенно"" mean ""great"" but ""хуёвый"" mean ""bad""? End of javascript sidebar workarounds? Recommendations for a usable, fast C++ matrix library? Would the One Ring even work for anyone but Sauron? Short complex password, or long dictionary passphrase? Our security auditor is an idiot. How do I give him the information he wants? Are SharePoint certifications worthwhile? What are some appropriate uses for Sitecore Data Providers? Does torture work well as an interrogation technique? What technical details should a programmer of a web application consider before making the site public? What is a good newbie friendly graphical Git client for Windows? I want to learn how to make electronic music. Where do I start? Can I borrow a lunar rover? How important are accents in written Spanish? Points are given in tennis 15-30-40. Why 40? 1.5 Million lines of code. 0 tests. Where should we start? ""View Vote totals"" without 1000 rep? Why is it faster to process a sorted array than an unsorted array? Better to learn programming, or hire a programmer? statistics vs. machine learning? Why does Windows think that my wireless keyboard is a toaster? Why shouldn't meat be placed in my compost pile? When should I use \input vs. \include? Can I exit from a specific country or node? OK we're all adults here, so really, how on earth should I use a squat toilet? How to design a recursive menu schema? How to list all installed packages? What is the exact difference between aa ""terminal"", a ""shell"", a ""tty"" and a ""console""? Should ""Yes, delete it"" be red, or green? How can I copy text to the system clipboard from Vim? How can I crop a video with ffmpeg? Alternatives for Google Reader (with Android synchronizing)? Recovering a lost website with no backup? How do I take a screenshot on a Windows Phone device? How do I prevent dangerous kickback on a table saw? When should you use WP_Query vs query_posts() vs get_posts()? How should I deal with an employee who has slept with my wife? Tomorrow is Groundhog Day... For everyone. How does society respond? Is there a special software for writers?"
btc;5h6feh;1481196403.0;/r/btc/comments/5h6feh/how_bitcoin_artificial_intelligenceai_big_data/;How Bitcoin, Artificial Intelligence(AI) & Big Data are Converging in Kenya, East Africa.;;
korea;5jpky2;1482396226.0;/r/korea/comments/5jpky2/networking_with_people_in_the_ai_startup_scene/;Networking with people in the AI startup scene;Hi r/korea!I'm working in artificial intelligence (not really big data but related to it) here in Korea and would like to meet and talk to people who have similar interests. Preferably entrepreneurs or people in the startup scene.Any advice on how I could go about it?;Send me a private note#Hey! There's the largest startup conference in Korea happening soon! You might wanna check it out : http://www.techforkorea.com/2017/04/30/koreas-largest-startup-conference-gsc-2017spring-to-be-held-on-may-23th-at-coex/ you can also check out some facebook groups. good luck! 
bigdata;5hsq1j;1481493841.0;/r/bigdata/comments/5hsq1j/all_about_big_data_analytics_tools_how_to_measure/;All About Big Data Analytics Tools: How to Measure Your Goals;;
bigdata;5gshjr;1481025942.0;/r/bigdata/comments/5gshjr/big_data_nightmares/;Big Data Nightmares;;
bigdata;5g1l7j;1480656284.0;/r/bigdata/comments/5g1l7j/7_tools_for_successful_big_data_analytics/;7 Tools for Successful Big Data Analytics;;
cscareerquestions;5jb11h;1482205010.0;/r/cscareerquestions/comments/5jb11h/forget_programming_languages_what_frameworks/;Forget programming languages. What frameworks, tools, and specialized skills are there to learn (to improve employability)?;[deleted];
learnprogramming;5gewf4;1480847638.0;/r/learnprogramming/comments/5gewf4/the_future_with_automation_is_a_scary_one_for_job/;The future with automation is a scary one for job security.. what languages and skills would you recommend to learn, as a beginner, to be the one of the ones automating it all away?;[deleted];Python is big in machine learning/deep learning which powers most of these more sophisticated automated devices. Considering sheer hardware requirements when it comes to machine learning you might also look at C++ as it allows you to play with your hardware at a lower level. That being said - math, math and even more math is what you want. Here's a [list of books](http://web.archive.org/web/20101102120728/http://measuringmeasures.com/blog/2010/3/12/learning-about-machine-learning-2nd-ed.html) that can help you understand how to develop such things.
dataisbeautiful;5hw768;1481543301.0;/r/dataisbeautiful/comments/5hw768/how_to_measure_your_goals_all_about_big_data/;How to Measure Your Goals - All About Big Data Analytics Tools;;
Python;5g0ws3;1480647456.0;/r/Python/comments/5g0ws3/big_data_guide_how_to_set_up_pyspark_with_jupyter/;Big Data Guide: How to Set Up PySpark with Jupyter painlessly on AWS EC2 clusters, with S3 I/O;[deleted];
Futurology;5izqpk;1482058362.0;/r/Futurology/comments/5izqpk/10_predictions_for_the_internet_of_things_and_big/;10 predictions for the Internet of Things and big data in 2017;;
books;5g9q02;1480774481.0;/r/books/comments/5g9q02/cathy_oneils_weapons_of_math_destruction_how_big/;Cathy O’Neil’s Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy;[removed];
todayilearned;5gf1wi;1480851050.0;/r/todayilearned/comments/5gf1wi/til_of_cambridge_analytica_a_company_that_focuses/;TIL of Cambridge Analytica, a company that focuses on campaigning with the help of combining big data mining and big data analysis.;[deleted];
politics;5gk3qw;1480914293.0;/r/politics/comments/5gk3qw/big_data_helped_trump_even_after_he_scorned_it/;Big data helped Trump even after he scorned it;;As a reminder, this subreddit [is for civil discussion.](https://www.reddit.com/r/politics/wiki/rulesandregs#wiki_please_be_civil)* Do not call other users trolls, morons, children, or anything else clever you may think of. [Personal attacks, whether explicit or implicit, are not permitted.](https://www.reddit.com/r/politics/wiki/rulesandregs#wiki_no_personal_attacks)* Do not accuse other users of being shills. If you believe that a user is a shill, the proper conduct is to report the user or send us a modmail.* In general, don't be a jerk. Don't bait people, don't use hate speech, etc. Attack ideas, not users.* Do not downvote comments because you disagree with them, and be willing to upvote quality comments whether you agree with the opinions held or not.Incivility results in escalating bans from the subreddit. If you see uncivil comments, please report them and do not reply with incivility of your own.****I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/politics) if you have any questions or concerns.*
datascience_at;5ga5av;1480780631.0;/r/datascience_at/comments/5ga5av/dive_deep_into_deep_learning_dzone_big_data/;Dive Deep Into Deep Learning - DZone Big Data;;
nosql;5h1p04;1481136617.0;/r/nosql/comments/5h1p04/sql_is_still_superior_for_bigdata_analytics/;SQL is still superior for big-data analytics;;
PoliticalScience;5gm402;1480947509.0;/r/PoliticalScience/comments/5gm402/big_data_scandal_brexit_and_trump_were_supported/;Big data scandal - Brexit and Trump were supported by powerful personalised manipulation algorythem. Study about the efficiency will follow.. (German Article! Sorry didn't found an equivalent in english..);;Translation was too big for one post so here is a link:https://translate.google.ie/translate?sl=auto&tl=en&js=y&prev=_t&hl=en&ie=UTF-8&u=https%3A%2F%2Fwww.dasmagazin.ch%2F2016%2F12%2F03%2Fich-habe-nur-gezeigt-dass-es-die-bombe-gibt%2F&edit-text=&act=url
datascience;5j6acy;1482152874.0;/r/datascience/comments/5j6acy/turning_big_data_into_manageable_data/;Turning big data into manageable data;;
datascience;5j562s;1482132677.0;/r/datascience/comments/5j562s/saturnb2b_next_gen_big_data_analytics_solutions/;SaturnB2B - Next Gen Big Data & Analytics Solutions;;
datascience;5gsae1;1481022433.0;/r/datascience/comments/5gsae1/anomaly_detection_using_h2o_deep_learning_dzone/;Anomaly Detection Using H2O Deep Learning - DZone Big Data;;
analytics;5g34gp;1480683628.0;/r/analytics/comments/5g34gp/data_ingestion_realtime_streaming_analytics/;Data ingestion - Real-time Streaming Analytics Platform | Architecture;[removed];
bigdata;5jj2zh;1482313233.0;/r/bigdata/comments/5jj2zh/taming_big_data_with_mapreduce_and_hadoop_hands_on/;Taming Big Data with MapReduce and Hadoop - Hands On!;;
bigdata;5jiox6;1482305993.0;/r/bigdata/comments/5jiox6/impact_of_big_data_solutions_on_business_sales/;Impact of Big Data Solutions on Business Sales & Marketing;;
bigdata;5ijdep;1481828645.0;/r/bigdata/comments/5ijdep/pcori_federal_agencies_call_for_collaboration_in/;PCORI & Federal Agencies Call for Collaboration in Big-Data Clinical Research;[deleted];
bigdata;5hqwz5;1481474768.0;/r/bigdata/comments/5hqwz5/big_data_and_trumps_victory/;Big Data and Trump's Victory;[deleted];
bigdata;5hd1om;1481278597.0;/r/bigdata/comments/5hd1om/hadoop_big_data_drives_big_impact/;Hadoop Big Data Drives Big Impact;[deleted];
bigdata;5gz3dx;1481104564.0;/r/bigdata/comments/5gz3dx/big_data_tools_benchmark/;Big data tools benchmark;[deleted];I can't believe that the versions of the systems used are not specified.Without that is completely useless.E.g.: Spark version? Spark SQL/RDD?
bigdata;5gs2wv;1481018484.0;/r/bigdata/comments/5gs2wv/longish_big_data_in_improving_student/;[Long-ish] Big data in improving student satisfaction levels at university;[deleted];
bigdata;5grki5;1481008709.0;/r/bigdata/comments/5grki5/streamanalytix_demo_video_realtime_big_data/;StreamAnalytix Demo Video - Real-time Big Data Analytics;;
bigdata;5grf46;1481006179.0;/r/bigdata/comments/5grf46/infographic_big_data_in_banking/;[Infographic] Big data in banking;[deleted];
cscareerquestions;5g4ira;1480699875.0;/r/cscareerquestions/comments/5g4ira/are_there_any_big_dataanalytics_jobs_that_are/;Are there any big data/analytics jobs that are suitable for remote/work-from-home/consulting?;[deleted];Probably not right away as a junior, but if you're good enough I'd guess you could call the shots.
EverythingScience;5ilpoc;1481854269.0;/r/EverythingScience/comments/5ilpoc/how_big_data_may_help_find_cures_for_cancer/;How big data may help find cures for cancer;;
startups;5j1ubt;1482089021.0;/r/startups/comments/5j1ubt/why_most_companies_are_failing_in_strategic/;Why Most Companies Are Failing in Strategic Messaging;[removed];You just posted this article:>https://www.reddit.com/r/startups/comments/5iex8e/strategic_communication_how_to_develop_strategic/Don't pull this spam shit here on /r/startups.In fact, if you make another submission to this sub without contributing 20 quality comments to other submissions, you will be banned.This is your one and final warning.  You will be banned. Thanks.
business;5hvjtj;1481531132.0;/r/business/comments/5hvjtj/all_about_big_data_analytics_tools_how_to_measure/;All About Big Data Analytics Tools: How to Measure Your Goals;;
Bitcoin;5h6ffp;1481196419.0;/r/Bitcoin/comments/5h6ffp/how_bitcoin_artificial_intelligenceai_big_data/;How Bitcoin, Artificial Intelligence(AI) & Big Data are Converging in Kenya, East Africa.;;
conspiracy;5ghcfc;1480881775.0;/r/conspiracy/comments/5ghcfc/how_a_big_data_company_is_responsible_for_brexit/;How a big data company is responsible for Brexit and Trumps presidency;;
environment;5jcgix;1482227308.0;/r/environment/comments/5jcgix/ieee_spectrum_ai_and_big_data_vs_air_pollution/;IEEE Spectrum: AI and Big Data vs. Air Pollution;;
Futurology;5g8nfg;1480752935.0;/r/Futurology/comments/5g8nfg/amazon_and_aws_democratizing_ai_and_big_data/;"Amazon and AWS Democratizing AI and Big Data Analysis: ""three new AI products, all of them keeping with AWS’ original purpose of making scalable web development apps affordable for everyone.""";[deleted];
technology;5j5ogm;1482142412.0;/r/technology/comments/5j5ogm/technology_trends_2017_ai_iot_big_data/;Technology Trends 2017: AI, IoT, Big Data;;
btc;5gz8te;1481107335.0;/r/btc/comments/5gz8te/chinas_jingdong_to_build_big_data_ecosystem_using/;China’s JingDong to Build Big Data Ecosystem using Blockchain Technology;;
bigdata;5imltb;1481866370.0;/r/bigdata/comments/5imltb/drive_your_business_sales_growth_to_the_next/;Drive your business sales growth to the next level with big data;;
bigdata;5i5rfl;1481658942.0;/r/bigdata/comments/5i5rfl/por_el_fracaso_de_big_data_ganó_trump/;Por el fracaso de Big Data ganó Trump?;;
bigdata;5i1gnd;1481601703.0;/r/bigdata/comments/5i1gnd/7_tools_for_successful_big_data_analytics/;7 Tools for Successful Big Data Analytics;;
bigdata;5hcufn;1481274668.0;/r/bigdata/comments/5hcufn/is_big_data_boon_or_bane_for_marketing/;Is Big Data Boon or Bane for Marketing?;;
bigdata;5gxkxh;1481081171.0;/r/bigdata/comments/5gxkxh/big_data_qué_es_en_qué_consiste_y_dónde_se_aplica/;Big Data: ¿Qué es, en qué consiste y dónde se aplica?;;
videography;5ih4de;1481802933.0;/r/videography/comments/5ih4de/aws_big_data_specialty_pdf/;AWS Big Data Specialty PDF;;
compsci;5j2kix;1482097538.0;/r/compsci/comments/5j2kix/computer_science_student_interested_in_big_data/;Computer Science Student interested in big data;[removed];
programming;5g0rcq;1480645622.0;/r/programming/comments/5g0rcq/big_data_guide_how_to_set_up_spark_with_jupyter/;Big Data Guide: How to Set Up Spark with Jupyter painlessly on AWS EC2 clusters, with S3 I/O;[deleted];
MachineLearning;4d7t1h;1459715825.0;/r/MachineLearning/comments/4d7t1h/panama_papers_dataset/;Panama Papers dataset?;I'm looking hard online, and I can't find the panama papers for download. But journalists across the world have access to it. Anyone have any idea how to obtain it? It's a few terabytes, which seems intimidating, but it takes about a day to process petabytes on AWS. To find the names of people involved, we would need to run a PoS tagger in a map job. Might not take all that long to find names in 11.6mil files. It's also possible to dump it all into AWS elastic search, and make it more easily searchable. It feels to me like this is the kind of problem big data was made to solve... and something like this is too precious to be left to journalists alone. EDIT: I posted this yesterday just as the story was breaking. I have newer perspectives, thanks to the comments and reading more news. They didn't give the data as such to journalists, they just made a search interface. It was tedious for the journalists to try retrieving info over 8 months. (A video from the Indian Express explained how they did the analysis, i can't seem to find that now). Wikileaks has started releasing some documents: https://www.documentcloud.org/public/search/Source:%20%22Internal%20documents%20from%20Mossack%20Fonseca%20%28Panama%20Papers%29%22/p2That said, there are very good reasons to not make all of it public as said by people with better knowledge than me in the comments:* Data Privacy. Innocent people can be targets for identity thieves and others with malicious intent, as private addresses, bank details, passports and other such sensitive documents are in the cluster. * Releasing it little by little allows to keep this news current and make sure the effects last. * The guilty might be able to take preventative action to ensure they are protected (though, if someone has the right connections, they dont need a public dataset). * It's quite frankly dangerous! people can die for digging too deep. (But if everyone has the data, we can't all be in danger?). That said, this is the sort of problem we should be working towards solving. people should be able to put out insights from a data dump without having to require deep knowledge of ML/big data. I feel now like the kind of work we all do matters in a real world tangible sense, in combating corruption. ;"Data is likely not going to be released unmodified for a few reasons, including:* privacy issues of people involved* protecting the source* making sure that the full extent of the leak is not known* maybe copyright issues* the media already has the data, in their eyes they are the only ones that are able to responsibly report about it, so there's no need for them to give it to someone else#I doubt we will be getting a data dump on Panama Papers soon. A majority of the released datasets on PP contain a lot of redacted information  it seems like they would rather clean it first and then hand it out.edit: It's not almost here folks. ~~http://offshoreleaks.icij.org/ has a ton of data.~~ (see /u/oberhamsi's [comment](https://www.reddit.com/r/MachineLearning/comments/4d7t1h/panama_papers_dataset/d1p3d0g))#It says ""ICIJ will release the full list of companies and people linked to them in early May.""(https://panamapapers.icij.org/graphs/methodology/)#I've been looking for it too, no luck so far. Would keep checking places like pastebin, wikileaks etc. periodically, maybe something will pop up within the next few days.The whole dataset on AWS elasticsearch would be really great, this needs to happen!!#They say they can't release raw files because of right to privacy : phones, addresses, ...Can't say if it's right or wrong in the end...All I know is that this will be a good week anyway !#[deleted]#I found a link that says they have all the data dor downloadhere: http://www.thereportertimes.com/panama-papers-icij-offshore-leaks-database-documents/23489/it's a torrent file, so I think it should be a goog thing to examine all the files before open them at the computer, but it's te only place I found the data#Not all uses of shell companies are illegal or immoral, so it would be a total clusterfuck if this data went public and basically was just used to drag names through the mud.  Would you want say, your credit card statements or grocery shopping history to go totally public?#There was a limited CSV available on icij.org but the site seems to be up and down at the moment.#Somebody please leak the leaked files lol.#It was released to journalists instead of the public for a reason.  They are being entrusted by the leaker with the responsibility of judiciously releasing the information.  ""Judiciously"" in this context means exposing information that it is in the public's best interest to hear, while not damaging the interests of innocent people caught up in the sweep.  Keep in mind that there are a litany of legal and moral uses for off shore banking and investment, and that the leak includes all of that activity managed by the firm as well.  It might be *mostly* shady activity.  Hell, it might be 99% shady activity.  But a raw and total release of info will expose the private data of law abiding individuals which isn't acceptable.  So the journalists will parse through it slowly using human judgement.  It's inefficient as you say, but they have a certain responsibility here.  #I will wait for the dataset. I think may be available by May. Would be good dataset to teach analytics :-)#While we're at it, I'd like to get my hands on the Unaoil dataset as well.#Good luck. You likely won't ever see all of the data.>Do not expect a genuine expose of western capitalism. The dirty secrets of western corporations will remain unpublished.>Expect hits at Russia, Iran and Syria and some tiny “balancing” western country like Iceland. A superannuated UK peer or two will be sacrificed – someone already with dementia.>The corporate media – the Guardian and BBC in the UK – have exclusive access to the database which you and I cannot see. They are protecting themselves from even seeing western corporations’ sensitive information by only looking at those documents which are brought up by specific searches such as UN sanctions busters. Never forget the Guardian smashed its copies of the Snowden files on the instruction of MI6.[Source of opinion](https://www.craigmurray.org.uk/archives/2016/04/corporate-media-gatekeepers-protect-western-1-from-panama-leak/)EDIT: [This](https://www.reddit.com/r/PanamaPapers/comments/4d8ftq/editor_in_chief_of_sueddeutschede_commenting_on/) might render everything above meaningless.#There is a breakdown of filtypes on the icij.org site. And from the looks of it, a large part of it is photos(probably passports and other ID's), and PDFs(guessing for scans, maybe signed by hand) as well as emails.The journalists state that they've went through the photos and such which OCR, which means that the actual information should fit in a much smaller set. Hoping to see how this develops.#Wikileaks is having a twitter poll of whether they should make the entire set of documents searchable. You can answer the poll on twitter https://twitter.com/wikileaks/status/716772373408718849Edit: It's over 90% yes when I voted. But every vote counts.#[deleted]#@Sukrim is right about the restrictions. Munging alone for this amount of unstructured data is not for the faint of heart. They are using Nuix (http://www.nuix.com/)#here you go -> http://www.thereportertimes.com/panama-papers-icij-offshore-leaks-database-documents/23489/#Shouldn't the semantics be represented much better by a human? I don't see how this is a deep learning problem.#""They didn't give the data as such to journalists, they just made a search interface.""  If this is correct why does John McAfee say in his Op-Ed ""I am just one of over 200,000 people to have downloaded the Panama Papers""?http://www.businessinsider.com/john-mcafee-panama-papers-evidence-we-need-better-cybersecurity-2016-4#All, I run a firm specializing in compliance and cybersecurity for federal, state, and private entities and we deal with data discovery all the time.  We’ve used a tool called EAS Data Light for discovery and text analysis and it’s the best at discovering relationships and extracting relevant information.  It’s done a phenomenal job so far on these docs.  If anyone is looking to boil down exactly what’s here and get ahead of the story, I recommend Data Light.  I’m paying it forward here.  Use this tool – http://www.capaxdiscovery.com/software/dark-data-cleanup/.Partner, c1secure#[here it is](https://github.com/amaboura/panama-papers-dataset-2016)#I'd like a copy of the email files. To Extract the Recipient Date-Time Subjectline.Then sort that file for upload on the net. Even a few million results would not be a huge file. #A portion of the dataset is now available for download [here](https://offshoreleaks.icij.org/pages/database). It is available as a downloadable Neo4j graph database instance (Neo4j was used by ICIJ to make sense of the data and powers the search tool available online now) or raw CSV. It is worth noting that this is the structured data from the leak and does not contain any information from the documents, emails, etc. Instead it comes from internal Mossack Fonseca customer databases.#Here ya go: http://offshoreleaks.icij.org/#149 DOCUMENTS RELEASED BY WIKILEAKShttps://www.documentcloud.org/public/search/Source:%20%22Internal%20documents%20from%20Mossack%20Fonseca%20%28Panama%20Papers%29%22/p2#make's available email adress, phone, private adress, will always be turned off as soon as it will be published. There is no any data link like that in the history. you'll never see the entire file available. it's not because they are using a computer as you do to read them that it means you'll access too. It's like any confidential data revealed.#The panama papers countains more than 11.5 millions of documents and pictures.#[deleted]#I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit:- [/r/conspiracy] [A good point about the leaked Panama files How come the media can easily access but OP seems to not be able to find them?](https://np.reddit.com/r/conspiracy/comments/4d9tak/a_good_point_about_the_leaked_panama_fileshow/)[](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*[](#bot)#Note that the media said they do not know the source, which was apparently smart enough to hide its tracks.#I'm a member of the press and I don't have the documents. A lot of us are out of the loop on this. It's not that they don't think we can handle it. It's just that they want them sweet sweet profits to themselves!We all wish to become masters of our own escape.#the media is in capitalist pockets and is going to release their opponents not their friends anyways#i think it's time to, at least in Sweden, rethink the responsibily of media since it's in the backseat from it's social counterpart and thus get pressed to be faster to publish and not check sources nearly enough. responsibility, like it or not, ends up on youtube, twitter, facebook, tumbler... that's where news are made.EDIT: and reddit - sorry, im a newbie.#Shame is one of the best punishments out there. So any ""privacy issues"" with corrupt politicians and business people, who are supposed to be representing ordinary people (you an me) and follow the laws, are not justified. #> privacy issues of people involvedPeople using their privacy for stuff like this, like robbing whole countries and ripping off their people, if proven guilty should at least temporarily lose any right for privacy until the sleaze is uncovered in all its entirety.> maybe copyright issuesProbably. And it's a shame that criminals can hide behind copyright.#> http://offshoreleaks.icij.org/ has a ton of data.that's the 2013 leak - similar but different :)#who is 'they' though.... media orgs are getting their hands on it worldwide, what is the criteria used to share with them? #Oh please God, let from now on and forever more PP become a shortname for Panama Papers instead of Pay Pal.#I gotta call bullshit on that.  That list will be doctored to hell. They won't hit people who can hit back, which means the biggest names on the list will be omitted. #We are a company working on text analytics. We have made a contextual search engine which maps named entities to action verbs, location and date time. We created this search engine to make sense of data sets exactly like these. zI would be highly grateful if this can be found anywhere. We intend to make this open and free for anyone to use.#YES! Exactly what I was going to do with it. Pretty disappointed that it seems like they won't be releasing it.#They've stated that the intent is to do a staggered release of documents. I really doubt the whole dataset will be available for a while yet.#but how are journalists from around the world getting it? I would like to go through the same procedure and be subject to the same constraints as them. #Politicians have no right to privacy. Especially since they campaign  on denying those to voters#> So it's only a matter of time before someone hacks them and opens the data to torrenting - there are too many access points to the data for any other outcome.So where's the unredacted Snowden dataset then? It was/is available to a LOT of journalists all over the globe...#copying /u/oberhamsi 's post:that's the 2013 leak - similar but different :)#Yes, this is offshore leaks data and also not the complete set (total size ~150MB). However, it looks very interesting. It is organized in nodes and edges and contains names of people and companies, role within the organization and some more. I wonder if this is the data set on which the graph theoretical networks are built from that you see at some places. I'm gonna try and feed it to gephi...#Offshore shell companies are a little bit different than CC statements and grocery receipts.  And why the fuck not be open about your finances? It's a weird American cultural thing to be all uptight and private about shit like that.#of course. but what makes some two-bit journalist in some random country a better candidate for that information than me? #Putin is the biggest news because of the amount of money he is linked to and where it came from. But you do realize there are about 100 newspapers involved in this, not just the 'corporate media'. #Haha, your initial post was nonsense and your edit is just as bad as people have misinterpreted what the journalist said (he has since corrected his intention). Maybe you should be more careful with the judgements that you make (""won't ever see all of the data!"" to ""this could change everything!"").#[deleted]#Thanks#Not release the entire set but 'make it searchable'.#deep learning might not be necessary. good old entity recognition and mapreduce might solve most issues. #Okay, now I'm confused. I'll dig around for more info. #this seems to be a compilation of all the famous people on the list. is that it? #that's a different but similar leak from 2013 https://en.wikipedia.org/wiki/Offshore_leaks#they said US and UK leaks are coming up soon. #It's possible Suddeutsche Zeitung (the original point of the leak) knows the source.#they only want to know cause the guys on the list are really powerful.edit: not because it's right to do so.#Well, in Austria the newspaper with access to the data is leftist and started by accusing one of the largest banks to have tons of offshore accounts.#Not everyone in there is a public figure.#> People using their privacy for stuff like this, like robbing whole countries and ripping off their people, if proven guilty should at least temporarily lose any right for privacy until the sleaze is uncovered in all its entirety.And for those who used the companies services just to start normal businesses, they get to have their rights breached for the same reason? Because thats how data leaks work, you cant just say oh everyone who used this law firm is a badguy.#That would be ICIJ. I don't know about the criteria, but if I had to guess it's probably ""trust"". Snowden dumped all of his data onto 4 (was it 5?) journalists and let them handle the redaction  it looks like they are doing the same.#That is the big question everyone has to investigate about. How, when and why this leak is happening (and previous by same 'group') ? A massive hostile diversion & persuasion tactic is the most accurate answer, looks like destabilization process or offensive scenario designing.Not journalism, just business.#You need to work with one of the newspapers directly. I do think everything should be released to allow communities to dig through it, the newspaper may not want that yet.#Update: Assange has released some documents. We start work on it tonight. Will keep you guys posted here :)#via the ICIJ  https://panamapapers.icij.org/pages/reporting_partners/#They got them directly from the source, so unless you know him/her...#Contact one of the involved media companies then.#Regardless of whether politicians have a right to privacy or not, the papers are not just about politicians. There will be lots of other personal information present, including of people who have done nothing wrong. What other people in the thread are saying is that this personal info will be removed before the data is released#[right here](https://snowdenarchive.cjfe.org) in fact#I consulted for a major oil and gas company, and their use of (some of their many) shell companies was purely to hide some their oil fields from their competitors. They find an oil field, and instead of moving in operations, they would created several shell companies in the local country, and conduct business with them. It was vital that their suppliers not be disclosed, because that would reveal where a majority of their oil fields are (which is apparently a big secret - not an Oil and Gas guy)Nothing shady going on there - more protectionist than anything. I'm not saying there are no shady, illegal, or immoral reasons to create shell companies, but not all shell companies are shady, illegal, or immoral. #Because if you're open about it it increases the chance that you become a target. #""If you have nothing to hide"" argument is a very common sentiment. Allow me to spend 15 seconds of thought to completely disabuse you of that notion. It assumes a number of fallacies:1.) Non-zero cost in the administration of justice, which is demonstrably false due to large legal bills and long time investment in any court case.2.) That the course of justice is infallible, which is false, demonstrated by the large number of innocent people put to death and later exonerated.3.) plenty more if you think about it for more than 15 seconds#The two-bit journalists trusted with this data, chosen by the person who decided to leak the data.https://www.icij.org/abouthttps://panamapapers.icij.org/#It is two journalists from Germany: https://cms.falter.at/falter/2016/04/03/wir-sind-doch-nicht-der-verlaengerte-arm-der-staatsanwaltschaft/They want to fight offshore companies in general but won't release the data to the public or even law enforcement.#What makes you think they are two-bit journalists and that you are better at anything -- including ML -- than them? What makes you think that the two-bit journalists don't have plenty of ML friends that can do just as well as any redditor but can also ensure the privacy of those that still deserve privacy?#Apologies for the double post, but [this](https://www.reddit.com/r/PanamaPapers/comments/4d8ftq/editor_in_chief_of_sueddeutschede_commenting_on/) could change things, rendering most of what I've quoted meaningless.#>Putin is the biggest news because of the amount of money he is linked to and where it came from.The amount of money Putin is linked to is a very small percentage of the total value of investments in MF.>But you do realize there are about 100 newspapers involved in this, not just the 'corporate media'.Yes, I am quite aware. The blog post I quoted was not my own. The author is suggesting a plausible explanation (one of many) of why a large portion of the data will not be available to the public. There are 100 newspapers involved. Each of these newspapers did not all receive the entire leak. The leak was given to Süddeutsche Zeitung, which then passed the management of the leak on to ICIJ, a group funded by the likes of: Ford Foundation, Carnegie Endowment, Rockefeller Family Fund, W K Kellogg Foundation, Open Society Foundation (Soros). Hence, the author's labeling ""corporate media."" ICIJ worked with journalist from these 100 different newspapers, at the discretion of the ICIJ, which doubtfully gave unrestricted access to each of the other media outlets.#Can you clarify my obfuscations?#They dont#edited thanks#The future is scary, man. #I am not sure. best I got#Huh, well still a good place to practice, if you wanna be one leg up on everyone else when the real one drops.#They denied knowing the source. They said that they communicated anonymously through an encrypted channel and that the source fears for its life.#They only communicated over an encrypted chat anonymously.#They are now.#Having said that, I'd bet most of them are...#Snowden claimed he ensured every file that he gave to journalists was something of interest. He did not indiscriminately dump all the data he could get his hands on. Other than that note, I think what you write is correct.#Understand it. And what am saying is that right to privacy is lost in case of corruption. It is common to see politicians use laws meant for common man to hide and Sue those who violate their privacy. However they are quick to deny same privacy to journalists and citizens. Hence, collateral damage is ok if the end result is achieved.#Is most certainly not the full unredacted dataset.#haha. that site doesn't even /claim/ to have the unredacted dataset. if you read their homepage, this is only ""documents leaked by ... Snowden that have subsequently been published by news media."" in other words, the journalists still have the full dataset, and we only have what they gave us.#+1.#but i didn't invoke the ""if you have nothing to hide"" argument. i know it's a shit argument. just commenting that it's a weird cultural thing that seems to be particularly prevalent in US.  #all the links i saw were saying that media people in 70 countries were going through the data. im still unclear about if only two people have seen all the data, or if about a hundred have. if that's the case, why should we have to get this info through our media? the media, at least where i'm from, has proven itself to be a lapdog of the establishment, and has been known to censor information which isn't conducive to its interests. if many people are in the know, i would rather everyone see it. #The first part was nonsense as many newspapers from many countries are part of it (the Sueddeutsche got it first, not the BBC or Guardian), the source you listed is butthurt they (meaning wikileaks) didn't get the first go at it instead of ICIJ which already showed with the Luxembourg leaks that most western corps avoid taxes in legal ways.For the second part here's the [journalist explaining what he meant.](https://twitter.com/ploechinger/status/716773530436825088)#[deleted]#it's highly possible a programmer or some network specialist give them. maybe he is on reddit. maybe he is reading this now. thanks !#[deleted]#> right to privacy is lost in case of corruption.Are you saying the right to privacy of unrelated people is lost because of corruption of politicians? I don't think that the people involved should be protected, however the people who are not involved should not have e.g. their passports public and the source should be protected.#Missed that. thats really stupid. I wonder why? surely Snowden doesn't think they are infallible #here's the list of media who are working with icij on this: https://panamapapers.icij.org/pages/reporting_partners/#The authorized media from my country (Bulgaria) - 24 Chasa, is known to have very strong bias to some political parties and presents a severely distorted view on reality in general... There are actually very few objective independent journalists in Bulgaria, but they exist and they were chosen as wikileaks partners in the past. Why would the original source choose a biased, pro-government, ""yellow"", by western standards, newspaper is beyond me... Almost as if he googled ""bulgarian newspaper"" and took the first result.#That's what I thought you meant, thanks!#I hope whistleblowers finally get a status that grants them protection#Actually a French security blog explored a bit how hard it would be to get into the client database. It is obviously disconnected now but they found that they are using a 2013 Drupal on an old PHP on a server with access to the crucial database. they guess that's how the hackers broke in:https://reflets.info/panamapapers-how-shit-happens/Also they loved the fact that there is a Google Analytics on the login page. Google has a stash of interesting IPs...#Yes, I was talking about the Snowden leaks, as the poster above was also talking about. I'm aware they are not the same as these new panama papers.#Collateral damage. Start Guide releasing the passport and other details of the leaders, and wind it down. Pretty soon privacy legislation will  be introduced, and couched in a language that protects only the leaders. Leak more and change it to include everyone.#But who decides what is to be considered whistleblowing instead of breach of NDA?*edit: grammar*#Like what? Whatever they could hope for wouldn't protect them or their family against the various crime organizations they're screwed over.#Drupal 7.23. Oh my. You can easily get full access to that web server. Probably wouldn't take too long until you could explore the other servers as well.#That's exactly why we need a debate about it. But a first good guideline would be to say that if it is to reveal an illegal action, you can't be sued for NDA breach. These kind of things can be decided by a judge. A whistleblower would be under the appropriate witness protection.#That was painful to read 😞#I believe that when you expose criminality or acts against morality and/or ethics you should most certainly be considered a whistleblower#That's exactly the scope of the [witness protection](https://en.wikipedia.org/wiki/Witness_protection) program.#And download terabytes of data.#we really don't need a debate about it  the law is quite clear. An NDA cannot protect against illegal activity. However, if john doe is working for kramerica industries and blows the whistle on them conspiring to illegally abuse Michigan's aluminum recycling program  kramerica industries can still sue john doe for breach of contract so long as they have yet to be proven guilty. Barring kramerica industries from bringing that lawsuit flips the presumption of innocence.  #Still, there needs to be some measure of proportionality factored in. Otherwise someone at Sony could leak all of Sony's trade secrets, along with evidence that Frank didn't handle the copyright on a song used in a DVD menu.#dang, i knew it... better now?#> These kind of things can be decided by a judgeTypically, the breach of NDA has to be essential for revealing the crime. Reasonable measures to not leak unecessary data must have been taken, etc...#Oh, not because of the grammer, because it rang so true!#In case of the Panama papers, a lot of documents about legitimate companies were leaked as well. This was a blanket dump.#So give the witness a blanket protection the time for the judge to examine if this was necessary given the conditions. Apparently the crucial informations were disseminated in tons of folders and without the help of journalists, sorting unknown figures from relatively unkown people was difficult. Also, the discolusre was responsible: it was not put online on pirate bay but through professionnal journalists who checked the data and kept private data private.Right now whistleblowers are prosecuted anyway, so they have no reason to care about privacy (and even though so far most have acted pretty responsibly IMO). But give them a legal framework and steps to follow and I am sure they'll be happy to comply if that opens up possibilities to be protected.#Don't get me wrong, I'm all for whistleblower protection programs. I'm just saying you have to come at the problem from all angles, because wherever there is potential for abuse there *will* be abuse."
technology;4ege54;1460472243.0;/r/technology/comments/4ege54/your_face_is_big_data_a_russian_photography/;Your face is big data. A Russian photography student has carried out an experiment to show how easy it is to identify complete strangers. Egor Tsvetkov took photos of people in public places and then tracked them down on the Russian social media site VKontakte using a facial recognition app.;;"Take a picture of the beautiful girl sitting across the aisle from you on the subway. Call her when you get home. Or bump into her outside of her apartment.#Just imagine when this becomes automatic.#There was [a study 5 years ago at Carnegie Mellon](https://www.heinz.cmu.edu/~acquisti/face-recognition-study-FAQ/) that did this also, identifying students as they walked past a camera via publicly available photos on Facebook.#Some more in depth articles:https://birdinflight.com/ru/vdohnovenie/fotoproect/06042016-face-big-data.htmlhttps://advox.globalvoices.org/2016/04/07/the-russian-art-of-meta-stalking/#When the camera was introduced, some cultures believed that having their picture taken would steal part of their soul.Ironically that is now not so far from the truth.#Vkontakte didn't exactly put a gun to those peoples' faces to get them to upload their mugs. I find it a lil ironic that people who openly submit their lives on social media freak out when someone actually uses that data  }#Looks like we have come a long way from the days when you could google reverse image search someone's photo to find out where else they are on the internet. This is fascinating.#In order to perform facial recognition, don't all the photos have to be stored locally? How does this ""facial recognition app"" perform comparisons to images online? It would have to download them first, no? Wouldn't that take an immense amount of time? How would you even get a list of all images on a social networking site? #good and criminal records? Cos around 1/3 russians been to prison.#This is why I have a problem with people just casually taking pictures where other people are or could be in the background.#Stalker level : expert.#Every cam girl and porn star that thought they'd remain anonymous...#HahahhahahaaAs if it wasn't the case already #subway scene in minority report#I recently created a facebook account again because reasons and every single picture that has been uploaded and tagged of me where my face appears was not uploaded by me as I purposefully used an avatar to not upload my own face. Every picture was uploaded by someone else.You're not safe just because you personally don't decide to snitch on yourself.#Probably through an API that's about as hard to break as a wet paper bag.#hey, girls love serendipity ""oh it's fate that we meet so many times"" ""uh, YES of course we are meant to be together!""#i like looking at the upsides!"
philadelphia;4cl3ap;1459349558.0;/r/philadelphia/comments/4cl3ap/septa_regional_rail_stats_commuters_meet_big_data/;SEPTA Regional Rail stats - commuters: meet big data!;;"This is wonderful. Thank you.I was debating compiling all this nonsense myself.#Wow.  I don't know what I'd DO with that information, but its vaguely interesting. I assume this is based on what SEPTA has reported about train times, not ACTUAL train times.  They only seem to note late trains as late maybe 50% of the time as near as I've ever seen over the past 15 or so years.I'm somewhat more curious about passenger information, like how many people get on or off at any given station, but I guess there's no way to track that...#Great work Douglas! Come out to [Code for Philly](http://codeforphilly.org) sometime and hang out with other civic hackers#This is great!  Nice job!#Just to keep folks in the loop here, I discovered a possible bug with SEPTA's API.  My train this morning was waiting just outside of 30th St Station, but the API reported Suburban Station as the next stop.  I documented it here: https://github.com/dmuth/SeptaStats/issues/7#Hi,I'm the author of the site.  I wasn't aware there were issues in the accuracy of train display times, but that's one reason why I wanted to build this app, so that train times can be displayed, and maybe those metrics can be used as the basis of seeing what trains are chronically late, ripple effects where one train affects another train, etc.  And hopefully SEPTA will find this site useful too. :-)The data is coming from SEPTA's API, so if you notice that there are specific trains where the late times are just... wrong... please let me know and I can dig around in the data further and look for patterns there.Thanks!#Code for Philly looks interesting, but I have a couple of followup questions.  Is there an email address where I can reach out?#I think it's also how SEPTA calculates how a train is ""late""  to them, a train isn't late until 5 minutes and 59 seconds after it was supposed to arrive/depart#Cool site. Do you know what's going on in the station pages? For example:http://www.septastats.com/station/Airport%20Terminal%20AIf I'm reading that right, it's saying there are 17 trains at the airport at 4AM? The first train outbound is 4:47 and inbound is 5:11 so it's a little unclear to me how there would be 17 trains. And the trains go every 30 minutes so it seems like every other row on that page should have 4 trains. #Okay... next time that happens to me, I will make a note of it for you.#You can hit up the organizing team at hello@codeforphilly.org#Bah.  I've had trains show up as much as 15 minutes late, with zero acknowledgement on anybody's part.#Interesting, I haven't heard of that metric before.  I take regional rail home every night from Suburban Station, and the lateness on the displays there tends to match when the train shows up, down to the minute.#Yeah, that can't be right.I filed a bug at https://github.com/dmuth/SeptaStats/issues/3 and will look into this later.#I like when they cancel a train, but continue to update it as being delayed 15... 20... 30... 45... minutes late until it's just the next regularly scheduled train.#I think you'll only see this in certain cases and I also don't think it will happen very often.  It would be interesting to see how often a train's lateness jumps over 5-10+ minutes between updates.  As long as a train is in SEPTA territory, they pretty much know where it is.P.S.  I might have answered a different question here.  :)#That's one reason I build this app, so I can look at the lateness graph and see if there's a huge spike in lateness.I should probably also work the longitude and latitude data I'm pulling into the reports as well.#I don't like it. :(#But other times they don't cancel and both trains just leave one after the other, 3 minutes apart.  #The train graph already shows the lateness per station it arrived at.  Take this graph for Train 560, for example:https://www.septastats.com/train/560As it completes its journey, the lateness goes up and down between each station.  Trains making up time as they travel is certainly a thing.#Please remain on the platform as this is only an approximate time.#I do like the visualization of the latest per train.Out of curiosity, are you scrapping trainview.septa.org to get the arrival times or are you pulling it from APIs?#I'm only using the official SEPTA APIs.  My source is at https://github.com/dmuth/SeptaStats if you would like to dig around it.#Yea, definitely.  Thanks."
civbattleroyale;4c5gjx;1459083484.0;/r/civbattleroyale/comments/4c5gjx/the_first_release_of_the_battle_royale_big_data/;The First Release of the Battle Royale Big Data Mods;CivBattleRoyale has inspired to me make a mod for specifically for AI-Only games. Reading and watching these games through the subreddits led me to believe that there are some issues in running theses games. I've even run a few AI only games on my laptop.While InfoAddict is a great mod and displays a lot of data in-game, it has some drawback and has been noted to be the cause of the odd crash in the Current Civ Battle Royale. The main reason for this I believe is that it keeps much of the data in memory, and with 62 Civs that is a lot of memory used.Also, there is much data being generated by the game that we as a community hunger for. City Flips, Resouces, Who is at War with whom, Who is Friends with who, and much, much more.As this is the First release of the mods, I'm ever grateful for feedback and any suggestions to include in future versions. Test the mods, and let me know how useful it is, or not as the case maybe.The mods are currently split into 2. The first mod is Battle Royale 62 Civs DLL and allows up to 62 Civs to play at once. The second mod is Battle Royale Data, which requires Battle Royale 62 Civs DLL to work properly, as the DLL has an expanded Lua interface which extracts more data from the game, and a basic text logger.The mods can be downloaded via the Steam Workshop.[Battle Royale 62 Civs DLL](http://steamcommunity.com/sharedfiles/filedetails/?id=653811119)[Battle Royale Data](http://steamcommunity.com/sharedfiles/filedetails/?id=653879056)/u/tpangolin, you might want to investigate the use of these mods for future battle royales. I would love to know how they perform.;You can only summon people in the comments /u/TPangolin #I've been waiting for that 62 Civ DLL in the Workshop for a long time. Thanks! #This is amazing. In fact, I want to try to get this to be used en masse in AI games, because I want to do mass statistical analysis of CIV V. Is there a way to make it so it checks how many land tiles are closer to a certain civs starting position than they are to any other civs?#I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit:- [/r/civaigames] [The first release of the Battle Royale Data Mods](https://np.reddit.com/r/civAIgames/comments/4c5gpk/the_first_release_of_the_battle_royale_data_mods/)[](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*[](#bot)#That's pretty good.#Could we use the 62 civ dll various mod components instead? The one made by whoward69, as it is needed for some other mods.#One question, how do we get to access the data that is stored in the database? I tried opening it with Microsoft Access but it won't let me, saying this is an unsopported .db database. Great mod man, thanks!#nice, can you also edit infoaddict so it shows 62 civs in the Global Relations thing#Cheers. I'll remember that next time.#You're welcome.#Yeah, it is possible to make that check. The data files also record the position of every city founded, so this can also done out of game.Somehow, I feel a third mod coming on. Still got ideas. And I feel as though it is still incomplete.And before I forget, I'm glad you like the mods. I hope it can be used for future Battle Royale games. It is designed to make life for everyone easier.#Cheers#At this point in time, no it can't. The main reason is that Battle Royale Data mod uses an extra LUA function in the DLL to allow the information to be written as a text file. If it is not there, then it will not work. I'm happy to investigate the possibility of making it work with whoward69's dll. #The Databases are in sqlite format. You can download sqlite browser from this [site](http://sqlitebrowser.org/)#🎈🎈🎈#A MOD idea I had specifically for the BR was adding the ability to auto-generate screenshots at the beginning and ending of each players' turn.Basically,1. Start of turn. Calculate extents of territory.2. Save screenshot (or group of images) encompassing all territory.3. Turn happens.4. End of turn. Do items 1 & 2 again.5. Next Player.Is this a possibility? It seems that if this part could be automated, the game could run almost non-stop. The releases could be timed around generation of OC, data, and narration.#A few parts ago, there was a Research Power calculation with total science output divided by cities.  It sounded like that was a better indicator of who is progressing through the tech tree fastest.  Is that something you can add to show who the technological powerhouses really are?#Yeah, that is something that can be calculated easily and added into the mod. 
datascience;4e5g5j;1460286699.0;/r/datascience/comments/4e5g5j/have_you_heard_google_tableau_are_running_a_big/;Have you heard? Google & Tableau are running a Big Data Competition for all skill levels with $500 free credit, free Tableau license & a chance to win a trip to London, UK and Austin, Texas.;;> THE FOLLOWING CONTEST IS OPEN TO VALID REGISTRANTS TO THE CONTEST WHO ARE LEGAL RESIDENTS OFAUSTRIA, BELGIUM, DENMARK, FRANCE, GERMANY, ITALY, IRELAND, NETHERLANDS, NORWAY, SPAIN, SWEDEN,OR THE UNITED KINGDOMI don't think I have ever seen the United States and Canada excluded from something like this before.#Would Tableau run on Linux?#Need payment method (bank, credit card info) to sign up for google cloud platform. #Time to go to war. #You've never seen the United States and Canada excluded from a list of European countries?#Doesn't affect the ability to register :-)#Hey, we do have Data Scientists in Poland  >#Lovely. You get downvoted, but nobody actually bothers to answer your question.Tableau Desktop only comes in Windows and Mac version.#That escalated quickly#YOU'RE GOD DAMN RIGHT#Well they are all in the EU, but the list doesn't include all EU countries ¯\\\_(ツ)_/¯#He gets downvoted because if he typed exactly the same question into Google instead of here he would have known the answer. #And your list of North American countries doesn't include Mexico. It's a list of *some* North American countries.The Tableau list is a list of *some* European countries. It need not to be a list of *all* European countries to explain the omission of a couple of countries in a different continent altogether.#Actually these are not all EU countries, it's missing Czech Republic, Hungary, Slovakia, Poland, Slovenia, Romania and Bulgaria for some reason.
PanamaPapers;4divxb;1459895472.0;/r/PanamaPapers/comments/4divxb/edward_snowden_live_stream_interview_tonight_at/;"Edward Snowden live stream interview tonight at 19:00 PST on ""Big Data, Security, and Human Rights""";In light of recent events I'm sure he will be talking about the Panama Papers.[Event description](https://www.sfu.ca/publicsquare/upcoming-events/EdwardSnowden.html)[YouTube channel of live stream](https://www.youtube.com/user/SFUPublicSquare)Event starts at 19:00 PST, April 5;[deleted]#Wait, is this in 40 minutes?#As far as paneled discussions go, this was one of the best I've ever seen. As a Canadian I am proud SFU hosted such an event and indebted to Ed Snowden for having shared his expertise on such matters. Long live privacy.#Oh this stream is gonna get flagged no? #Snowden is controlled oppositon. CIA stooge. #I found this:https://www.youtube.com/watch?v=e1acfjqPcpASnowden joins the broadcast at (17:10): https://www.youtube.com/watch?v=e1acfjqPcpA&t=17m10s#No links that I have found yet. Hopefully they will make it available.#It's at 7pm Pacific (10PM Eastern). Edited because I'm dumb.#Why would it get flagged?#Thanks for posting. This was an excellent interview. It might be helpful to post the link directly to r/panamapapers#7PM Pacific is 10PM Eastern#At least in the eyes of governments and corporations he is controversial.#Right you are, Ken. 
haskell;4douwk;1459992183.0;/r/haskell/comments/4douwk/haskell_jobs_at_blockapps_build_next_generation/;Haskell Jobs at BlockApps - build next generation infrastructure;"Hello all. BlockApps (blockapps.net) is hiring for a variety of roles, mostly in Haskell. Please see the slightly lengthy JD below.-----BlockApps is a rapidly growing Haskell-based blockchain infrastructure company. BlockApps' platform targets the Ethereum protocol to enable the delivery of Blockchain based applications and services. Our platform is powering solutions across many business verticals including Financial Services, Insurance, Energy and Healthcare.BlockApps is seeking exceptionally talented engineers to round its founding team. These roles are fast-paced and multi-faceted: the tremendous business growth we are experiencing necessitates an ability to deliver solutions to complex technological problems across a variety of business use cases. We are seeking generalists with proven delivery ability and the desire to learn an exciting and novel set of technologies, ideas and paradigms.NYC preferred, remote work possible.Write kieren@blockapps.net with a CV and a single paragraph cover letter for more details. Please include links to Github, and any other information you'd like considered. Do send us a CV even if you think you might not be qualified. The desired skill sets below are for a number of possible positions - don't worry if you only cover a few of the bullets.Desired skill sets include:+ Production experience with Haskell or other functional programming language+ Web services experience, especially REST API design+ UI design & implementation+ Modern Javascript experience (Node, Angular / React, etc.. )+ Cryptographic Protocol Implementation+ Security Engineering+ Experience with TDD / BDD+ Continuous Deployment+ Experience architecting projects and creating technical specs+ Developer Evangelism+ Project management experience+ Client facing experience+ Experience writing clear and extensive documentation for complex products+ Experience with relational databases including data modeling, administration, query optimization+ Experience with modern ""Big Data suite""  + NoSQL databases (e.g. Cassandra)  + Messaging (zmq, Kafka, etc.)  + Stream Processing (Storm, Spark Streaming, Samza)  + Scheduling & Orchestration (Mesos, Kubernetes, etc..)  + Experience with cloud deployments, on public clouds and in enterprise data centers     + Kubernetes, OpenStack, OpenShift, Cloud Foundry, Mesos+ Experience developing IDE plugins+ DevOps experience";"I'm a grad student, so maybe I'm naive, but is there anyone on the planet who hits every one of the desired skill sets? Seems like a lot of specific frameworks to be familiar with, especially when intersected with the requirement for Haskell knowledge. #For anyone not aware, there is currently a huge amount of excitement around ""block chain"" and ""smart contracts"" in the finance industry.#What is developer evangelism? And why is it desirable? #This is a role in California, US?#Are you guys looking for app developers as well?#This sounds like a bad skill to have: `Cryptographic Protocol Implementation`Don't ever implement crypto yourself.#Likely you missed this part - we are not expecting the skills to be present in one human:> The desired skill sets below are for a number of possible positions - don't worry if you only cover a few of the bullets.#Indeed!#I'm not sure the proper name for the role but it means something like ""person who writes great technical blog posts, and is comfortable interfacing with the developer community."" #Quoting OP:> NYC preferred, remote work possible.#Certainly!#Presumably someone has to...#[deleted]#hopefully it meant ""interested and knowledgeable enough in crypto to have tried implementing it themselves"" and not ""I roll my own crypto for all my production security minded projects"".#Crypto protocols are less of a black art than crypto algorithms, and implementations are less of a black art than design.I've done crypto protocol design, I did it out in the open where real experts could (and did) read and review it, and I did it as part of an IETF working group on the subject, not on my own.  It was a good experience, even if I'm not an expert in the subject myself.I won't touch algorithms, though, not for design and not for implementation, there's just no need for either except on the most cutting of edges.Blockchain crypto isn't that cutting edge, as a rule, just application of existing algorithms (and implementations).  And Ethereum relies on proof-of-stake rather than proof-of-work, IIRC, so it's not even trying to be terribly clever with hard but possible crypto.#Ahh, that makes much more sense, thanks! #You may want to make it bold.#Especially with ethereum and the ability to write smart contracts#That's the right term.  The position is indeed often called ""developer evangelist"" and it's the person who identifies the use cases for the product/service and makes it easier by publishing info about it, and also goes to conferences and talks up those features and how they are used, and both pushes the company vision and takes back from outside users and advocates for them internally.  They're usually straddling sales/marketing/tech.#Ah yes, see it now. Thanks.#OK, maybe change that bullet point to:* You have worked at Galois, or you are Vincent Hanquez.#It's still correct to parrot it though. Those people who want to learn to implement crypto have to realize that they need to be an expert before it's safe to use anything they write in the wild.#This is a much better way of saying what I meant :)#> This sounds like a bad skill to have: Cryptographic Protocol Implementation Don't ever implement crypto yourself.For clarification, we don't intend to create any new cryptographic protocols or algorithms, but are interested in hiring individuals with professional crypto experience. #Frankly, the attitude and competence 99% of developers have around cryptography is appalling in my experience and I directly attribute this partially to the pervasive attitude of ""never touch it, it's magic, don't even bother"" that people constantly spewed for the past few decades, often with little experience themselves.I'm not talking about even writing cryptography, I mean understanding its basic principles, ones that address questions like ""why is scrypt better than SHA256 for passwords"" or ""why do you want authentication when encrypting something"".I wouldn't fool myself into believing that we're somehow saving ourselves from a giant mess by parroting useless information over and over again. We might be, but given the state of software security today, and the horrendous state of critical software like OpenSSL, GPG and friends, large amounts of things like user account leaks and data breaches, etc, I'd say that attitude likely got us *into* some messes, too."
vancouver;4dk06y;1459912365.0;/r/vancouver/comments/4dk06y/live_now_sfu_presents_edward_snowden_big_data/;[Live Now] SFU presents Edward Snowden: Big Data, Security, and Human Rights;;"https://youtu.be/e1acfjqPcpA#I wasn't available to watch this live. Anyone know if the video will be uploaded?#Does anyone happen to know what the heckler said at the end? #Thanks for that, it's weird that SFU Public Square can't be bothered to post the video on their youtube channel and we have to rely on third parties.#I heard that it's going to be leaked.#Pretty sure it won't be. They said on the stream it would not be recorded.#Are you referring to someone who shouted something during the closing comments after the panel left the stage? If so, I was a few rows ahead of her, she just said something like ""WE NEED ACCOUNTABILITY AND TRANSPARENCY AND..."" or something like that. Not so much heckling as someone who likes the sound of their own voice.#Nice meme m9, but really, I will attempt to look for a vod or player to view it on. Especially with the recent events going on now."
programming;4c2n76;1459022625.0;/r/programming/comments/4c2n76/how_netflix_is_using_big_data_to_create_better/;How Netflix Is Using Big Data To Create Better, Successful Shows;[deleted];"The important difference between Netflix and traditional television is that Netflix has to sell its shows to its subscribers rather than to advertisers. You see the same difference in the diversity and quality of programming produced by HBO and the BBC. Maybe ""Big Data"" aids them in their decision making, but what really matters is the company's incentives.#How is this programming?#People use the term big data like its a magic talisman, when in fact most of it is fairly rudimentary data analysis that's been happening for decades, now on new data sets.And I wouldn't be so certain about ""big data"" conclusions.  Data analysis is hard  there is confirmation bias, sampling bias, and all sorts of problems...one potential issue with big data is that if the set is big enough you can find almost whatever you want...#[deleted]#if the most recent installments are a result of that they failed.#I wouldn't say they created a show using it, however, they can easy to that. Then again, it would be like Hollywood already.They basically ran the numbers to see if it would sell, and it did. #(did not read TFA)I don't want that. I want someone reflecting on things and producing stuff like Utopia, when you watch it will pull your socks off. Big Data, no thanks. This will be a phase we all have to go through, just like Hollywood had its fads of production and (sometimes) got sane again. But I hope it will be short, as Big Data means more introspection by itself.#Don't think you need data mining to tell you Spacey + Fincher = Success. Also HBOs most popular show probably could not be sold to advertisers, since there is no space within Westeros to slap a pair of Nike shoes on dragons. I totally agree with your comment about their motivations being geared more directly towards the customer. #It's television programming!#ITS #BIGDATA #MANGODB #MICROSERVICES#It broke my rams#  #OHISEESORRY"
haskell;4d6a8h;1459692954.0;/r/haskell/comments/4d6a8h/what_language_would_you_choose_to_make_a_database/;What language would you choose to make a database from scratch? (more info inside);"Suppose you want to make a database from scratch with all this characteristics:- Fixed scheme- 100% immutability (only inserts and selects  nothing about updates and deletes)- Massive concurrency- Massive parallelism- Millions of users- Big data (TB, PB...)- Queries to get some specific set of data (like graph-oriented and key-value-oriented NoSQL databases)- Queries to analyze all data (like SQL databases)What programming language would be the best choice in your opinion?Of course, probably your option would be ""PostgreSQL!"", but I'm talking about a entire new system from scratch. I'm doing a research, just for curiosity. Ignore ""lack of programmers"", ""bad documentation"" or things like that. It's a 100% technical question, assuming an hypothetical scenario where you have a big team that know how to work with that language.Why am I asking here? Because Haskell seems to me the best designed programming language. That doesn't meant that would be the choice for this question, and not the faster, etc.My options would be one of this three:- Haskell- Rust- ATSMy concerns are functional programming and other modern approaches (that's why C or Assembly are not worth).What do you think? Haskell? Rust? ATS? Other language?I'm curious to know your opinions in this :P.";"Rust for memory, disc access and data structures. Haskell for database connection, query parsing and optimization.Rust is great at handling raw memory in a relatively safe and high level way. Haskell is extremely good at transforming tree like datastructures.#I'm going to vote Rust here.Performance, safe, made for mortal programmers.Haskell would be nice too, but us mortal programmers aren't going to be so great at getting all the performance we can out of it, particularly in regards to memory.As another poster said, a combination of Rust and Haskell could be very appropriate.Edit: I do want to point out that Haskell can have very high performance. But that's a consequence of the GHC guys and other Haskell people being very smart and giving us mortals the ability to have our cake and eat it too. Yet, Haskell is built from the top-down -- its features focus on the abstract, letting compiler implementation worry about the mechanical details. So when things don't work out so great, god help us.Rust, on the other hand, is built from the bottom-up, with any abstractions the language provides having some correlation to highly performant underlying code, giving C-like speed by natural consequence, and gives us facilities to think about how our code is utilizing the hardware. It's as much of a ""bottom-up"" language as it is a ""top-down.""#> Ignore ""lack of programmers"", ""bad documentation"" or things like that. It's a 100% technical question, assuming an hypothetical scenario where you have a big team that know how to work with that language.You're basically saying, ""If the concerns that are important for language choice can be overlooked, which language would you choose?"" The answer to that question should probably be ""the one with the best performance""... so something like Ada, Rust, C, assembly or whatever.The reason we have all these other languages (including Haskell!) is because programmers are fallible and we're ready to sacrifice some performance for increases in bug resistance and friendliness to the way people think, rather than machines. If you're assuming superstar programmers that don't have problems with bugs then there's no reason to choose those languages either!...unless you're just using a lot of words to say ""don't care about popularity"", in which case my answer is still Ada because performance sounds like an important part of your system, and performance is easier to get out of a low-level system.#Would Haskell's GC cause problems for a large database? I know RabbitMQ uses only [40% of RAM on a server](https://www.rabbitmq.com/memory.html) because Erlang's GC could (worst case) 2x the memory usage. Giving up all that RAM sucks  with e.g. MySQL I can tell it to use 90% of RAM and not worry about the out-of-memory killer.I'm not familiar with Haskell's GC at that kind of scale—would it cause that kind of problem?#Your question may be hypothetical, but if you're actually considering writing something like this, I would really urge you to consider why you want to write your own. You mentioned PostgreSQL  why is this not a solution for what you're after? Performance?One thing I learned from working at a large software company with a lot of in-house solutions was that rolling your own isn't always the best, in fact, it's usually the worst option. There is a lot to be said for maintainability and usability. Consider that this system you're dreaming of may be in production for many years (I assume, from your list of requirements, like ""millions of users""), this means that several years from now, well after this software has been written and is stable and hasn't been updated in a long time, anyone who wants to go back and change something to it will have a learning curve just to learn how to use it, first off, and an even bigger learning curve for how to modify it.tl dr: If there is a really good, FOSS solution available that meets your requirements, like PostgreSQL, use that instead.#Have you checked OCaml? It's designed to be well performing, it's functional, it's mature. Eg.  [Irmin](https://github.com/mirage/irmin) is a database written in OCaml.#I would use Haskell to write a prototype, in order to verify my beliefs and learn about the domain. Then I would see how far I could get with a Haskell implementation, and ask around if I ran into some major problems. In the best case, since my database is going to be so amazingly great, it will invite lots of community participation and maybe even corporate backing, so it should be possible to solve the major technical blockers if any show up.#Fixed Scheme, Massive Concurrency, and Massive Parallelism are things that would be easy in Haskell.#That's something that bothers me about Haskell. It seems that it should be a good choice for a NoSQL database (safety, less prone to certain bugs, compiled to native binary) but of all the numerous NoSQL DBs none are written in Haskell as far as I know. Why is that?#I'd definitely go with Haskell, but I may be biased.It's not that difficult to write a DB from scratch that can serialize a million or more updates per second on one machine (verifying it is probably 99% of the work). Since you're only doing inserts and selects, you don't have to worry about transaction like interactions and can just split your data across multiple essentially single server DBs each with ungodly amounts of RAM.#Honestly, I'd use Haskell. Of your characteristics, the one that I think would be the source of most of the work is massive concurrency (big data as well, but that just turns into massive concurrency), and Haskell has Cloud Haskell as a great starting point. Once you're at a point where you can easily distribute work and data across a set of machines everything else becomes straight-forward enough.I have to say, I find it strange to look through the responses here and not see a lot of Haskell proponents. Databases are easy to make cache-friendly and Haskell has good support for doing low level memory operations. I would be very surprised if Rust, for example, could out perform Haskell by enough of a margin to overcome the overhead of all the network activity.#ATS: memory-safe, easy interoperability with C, type-safe, good fit for low-level work (can use it without GC, or with custom memory allocator).#https://hackage.haskell.org/package/HaskRel might be relevant.#Serious question: how would you have a database that cannot insert and update? Would you point it at a JSON file or something like that?#JavaScript#[deleted]#You overlook language design. This is what I think Lajto was getting out.#Yeah, ""don't care about popularity"" is what I mean XD.I forgot to mention that I only consider 100% free/open software programming languages :). I like Ada a lot, but you need some private things to get it work perfectly.#You can place limits on how much RAM it will use (such that it will try to stay within that limit and crash if it can't). How much memory you need is entirely dependent on how you use Haskell (you got process literally infinite data structures or have simple loops use infinite memory).#[acid-state](http://www.happstack.com/docs/crashcourse/index.html#acid-state) is a NoSQL database written in Haskell. The largest known deployment of acid-state is [hackage](http://hackage.haskell.org/).The current implementation of acid-state is quite stable and usable. Though there are also many missing features due to a lack of developers.If anyone is interested in filling in the gaps I am more than happy to provide assistance and direction.#Thanks :D.#The post says no deletes or updates. Inserts are allowed.#JSON files are really slow for searching and such.#Can't, no `leftpad()` :(#Is that a joke?#Rust?#Why? I think Haskell would be a fine choice for this.#I don't overlook language design. Language design is just a means to an end, not an end in and of itself. The things I mentioned in my comment are the reasons we care about language design in the first place!#Which private things?#Obviously. I was mostly wondering if the store would serve static documents specified at startup.#Same question.#Explain yourself :3.#GNAT Pro.#Wat. JavaScript would be terrible.#STM would certainly make transactions easier :)#Although all the other alternatives are also commercial, GNAT Pro isn't the only Ada compiler in town.#You know there's a [Libre version of GNAT](http://libre.ad) right? Also most of that work, IIRC, makes its way back into GCC proper. And GPS isn't that awful =)#It's a ""joke"".  I was suggesting that you were also joking.#That's right, but the Haskell GC would produce a lot of memory garbage. In a massive environment, that would be a bad thing :S.#Yeah, but you can only use it in free software or in academia. To me, the ""real"" compiler is GNAT Pro.#Ah ok, I have seen a scarily large amount of people that would genuinely say that.#I'm pretty sure that those problems can be overcome. If your database is immutable anyway, you're probably going to want to keep stuff around.#In a database with immutable data it seems like that data should not even be under the control of the garbage collection. Perhaps some IO based datastructure that manually uses malloc/Ptr or something? That way the GC doesn't spend a lot of time copying the values around hoping that some my might collectable?#Even if data is immutable you most likely want to keep the information from queries around, switch between B-Tree and hash tables, load unused data off to disk and reload on need, etc. Databases are highly dynamic structures, even if noone adds anything to it."
MachineLearning;4d7u6q;1459716259.0;/r/MachineLearning/comments/4d7u6q/how_netflix_is_using_big_data_to_create_better/;How Netflix Is Using Big Data To Create Better, Successful Shows;;"Critics complain about big data removing creativity from making shows but stupid executives and focus testing groups have been doing that for years. At least Netflix isn't making crap and selling it as gold. #The ""Big Data told us to create House of Cards""  line is a PR  myth.  The show is successful for ordinary reasons: talented writers, directors and actors.  #Did you even read the article? They didn't use Big Data to create the show. They just used it to verify if it was worth to invest into something that was offered to them. Basically the same as when people look at the IMDB-rating to see if a movie is worth to watch.#Yes, I read the article. Perhaps your objection is semantic, surrounding my use of the term ""create"". I argue that the decision to go forward with the show had little to do with Big Data.  You don't need Big Data to show you that a blockbuster lead actor, a critically renowned director, and a previous UK version that ranked 84th Greatest British Television Programme spell success.#Actually you do. Because taste is different from country to country and blockbuster-actors are not a guarantee for a hit. Most actors and directors have a sweetspot where they can shine, while they  suck at everything other. Because of that companys use hard data to verify whether their multi-million-dollar investment is safe or just a burn.#Dear sir,I've read your remarks and consider them balderdash. Please be advised.Regards."
privacy;4el5s5;1460547768.0;/r/privacy/comments/4el5s5/big_data_dont_panic_but_youre_being_watched_aust/;Big Data (Don't panic but .. YOU'RE BEING WATCHED.) Aust TV explanation;;"Thanks. Added to https://www.reddit.com/r/privacytoolsIO/wiki/index#Such a distasteful presenter. He's just taking it lightly while saying it's ""really important"". Added sitcom laughs to such a subject makes me wanna vomit.You can see it in the mainstream media now, they are not trying to warn you of the danger, Either by making the subject laughable or giving you the feeling of you can't do anything to change it, they're trying to convince you to stay put and do nothing about it.Governments and media are excelled at passivization of people.Please do not take your privacy lightly.#I'm not sure that's fair. He's a talk show host, not a news network anchor. At the end of the day, he's getting the problem of privacy loss out in the open, which is a good thing. He's lighthearted and joking about it because he hosts a comedy show, not because he's making light of the issue.I agree that political figures and the media at large are absolutely failing to educate the public on privacy, but I don't think a comedy show is the right target."
heroesofthestorm;4ewofx;1460726466.0;/r/heroesofthestorm/comments/4ewofx/privacy_in_hotslogs_what_your_public_profile/;Privacy in hotslogs - what your public profile tells about you;"In hotslogs your profile is **public** by default. This means your profile can be accessed by anyone. Your data include ""Date and Time"" (played) in your game history and i find it problematic because it tells something about you. More than you could possibly think.  It is something easy to exploit in silly ways. ""Total Time Played"" also tells something. The question is first ethical and could even be a legal matter.One example: your employer could track your activity and if it happened that you were playing at work (sure no one does...) he could you use this to fire you. Even if not the main reason someone could use this as an argument. A jealous colleague could also harm you this way. Yes people can be bad.There are many other examples, it could be about your family, your relatives. It may sound futile or paranoiac but at the age of big data this should be taken very seriously. Public data is easy to exploit. Period.You would argue, these are only pseudos and not real names. Well if you know a bit the person or you know how to cross some data in many cases you can find who is behind. Much easier than you could possibly imagine.There is actually an option in hotslogs to make your account **private**. But i'm afraid it's not the good answer. It will remove the links to your profile, remove you from leaderboards and from the search. So in many ways it's bad for the community. If everyone had their profile private, hotslogs would lose a part of its interest and maybe some traffic for the owner. Meanwhile i've put my profile private.The basic solution would be to hide this column ""Date and Time"" from the history. I suggest it should simply be removed. ""Total Time Played"" should also be removed. Alternatively, these could be displayed for the owner of the account only. Or make the history private by default. Or there could be a new privacy option ""public limited"" letting the user choose if he wants this specific data public or whatever. Well there are many possible solutions.I've discussed this a bit with https://www.reddit.com/user/barrett777 who i appreciate a lot for his awesome work and reactivity and i don't want anyone to feel bad about this. But i think it's an important question that all the hotslogs users should be aware of.**TL DR: in hotslogs ""Date and Time"" (history) and ""Total Time Played"" say something about your private life. It should not be public data by default and it would be sad to have everyone using the private option.**";"I think that hiding date and time is a reasonable suggestions. Total Time Played can be easily calculated starting from total games, but it doesn't mean much if you don't know the time frame over it has occurred.#So my employer would happen to know my Battle.net username or Battletag? And he'd casually know about Hotslogs as well? How would he provide proof that it was me who was playing on that account and that I wasn't sharing it with my kid/brother/friend?Don't get me wrong, I get what you're saying, but still, that's a great exagerration. Also, if your employer would want to know if you have been playing video games at work when you weren't supposed to, trust me, there's a lot of easier ways to do so.#It's not private. It's available to 9 other players in that match who are free to do whatever they want with that data, there is no agreement between you and them that they won't share the replay on the internet.The only thing that I could potentially consider private is the in-game allied chat (in case you play in a party for example), but Hotslogs actually deletes alll the chat data from the replays so that's not a problem.If you are paranoid you can make your profile private. Thank Ben for that because I think he doesn't have to give you that option.Also, match history and total games played are available in game too. You just need to appear on a chat channel.#If you're irresponsible enough to play hots while you should be working you deserve to get fired anyway.# A jealous colleague could also harm you this way. Yes people can be bad.Do you use your real name as the nickname? #this is really only a problem if 1)your boss knows your username, 2)knows you play hots (more likely), 3)has become an actual problem at work. a random dickhole boss probably isn't going to be able to find this information unless you have it linked to something that points to you being the account holder, which is probably only a situation in which you're getting paid for playing the game or something#Unless your BattleTag is your real life name, this doesn't show any private information at all. #I only wish everyone were this paranoid/concerned about data that actually DOES matter. Not that it doesn't matter in hots, as per your examples, but this is small potatoes compared to most of what we give up on a daily basis.(Sorry, security nut here.)The nice part of this, is someone needs to know hotslogs is a thing. And it's not unheard of to play some hots when you call in sick from work or something. It's not like saying you're sick and in fact at a concert or, worse yet, committing fraud by claiming disabled when in fact playing sand volleyball every day.For your examples, though, it's possible the person playing too much hots actually has some other underlying problem/addiction? Just a thought.#Honestly I don't see any real reason *not* to have something like this. #agree with that!#What i gave is just an example. I don't really want to enter in the discussion on how it could ever be used. I consider it to be private data and should not be public by default. #Well he would have grounds to have you banned for account sharing.#What can be found in-game is not a problem imo.About the replay files you're totally right in theory, but in practice most of the replays end up here in hotslogs.Fine, maybe i'm paranoid. FYI machine learning is one of my interests, just to say this kind of data is a piece of cake to process. Anyway i made my profile private. I just found it a bit sad. And still i think some players would put back their profile public if this data were not displayed.#ahah, pretty sure there are lot of things you should not do at work but still do  )  But as said this was just an example. #No. But as said in many cases it's known in your circles and it's not very hard to find out by anyone if you really want.#Sorry but you are wrong. Just one example: between colleagues it's not unusual to share this info. Personally I know many cases.#Privacy in this world of data is a huge concern. In hotslogs some people already put the profile private. Why so? If this was so futile no one would do it. Well i think this kind of data is the main reason. I don't want to judge people, but what can be changed here technically. Hotslogs would be better if everyone had their profile public.#Also to say, i may be a bit distorted professionally as one of my interest is machine learning. Data available like that is very easy to process. But yeah for normal people i understand it can sound completely paranoiac /kappa#what do you mean? Should this info be hidden or it's fine if it's public?#And what employer would possibly contact Blizzard in order to get his employee's account banned because he told him his son is using it? What employer would know Blizzard's TOS?Unless your employer is actually Blizzard Entertainment, no chance of this ever happening.#>What can be found in-game is not a problem imo.Well, it's about the same information as on Hotslogs. But yes, harder to access (but not impossible).>About the replay files you're totally right in theory, but in practice most of the replays end up here in hotslogs.Well, that's what I'm saying. Every player playing with you can upload the replay wherever he wants because it's not private.>Fine, maybe i'm paranoid.I think so. :) I mean, there might be some people for whom this is an actual problem, but they can make their profile private (and that'd probably a very small group of players). Unless you actually play the game at work, I can't see any way someone might use Hotslogs data against you (especially that you don't give your boss your Battletag).>FYI machine learning is one of my interests, just to say this kind of data is a piece of cake to process.I agree, though I can't see how that's relevant. And I have no idea what could you extract from someone's game history with machine learning that would be interesting. Oh, you know at which hour I go to sleep? Cool.>Anyway i made my profile private. I just found it a bit sad. And still i think some players would put back their profile public if this data were not displayed.I think that the amount of people who made their profile private is rather small and the amount of people who made their profile private because of privacy concerns (and not hiding MMR or maybe hiding practice matches by pro players) is completely insignificant.I just can't see why date and time of playing games being visible could be a problem for somebody. Maybe you could give me some particular examples why an average player would be concerned with that, because for now this thread looks like ""I think this function should be deleted because of some very rare hypothetical situation when it might harm someone"".#So you shared your private information with other people, that's your problem.#There's also the friends list. One of them may use their common online username, which might be a Twitter handle, has their location, and you can assume they're a real life buddy, or other information due to association with people who aren't as concerned/careful.#>  In hotslogs some people already put the profile private. Why so? If this was so futile no one would do it.Hiding MMR usually.#I mean there's no reason not to implement this sort of thing. #You can also track network traffic but that's a whole different discussion. My point was just about this specific hotslogs data. You can find it futile and i respect that point of view.However there must be a reason why some people already put their profile private. I don't want to discuss the personal reasons but only the technical reasons.#I'm a manager and I know Blizzard's TOS. Now, I'm not saying I would try to interfere with my subordinates lives but I'm sure some would go to such lengths. #Blizz does not show any public info to any other people who are not in my contacts on bnet. I can remove someone there at will. It's not the case for hotslogs. I put my profile private in hotslogs but it's not a satisfying solution as i explained in my post. #But you see the MMR of private profiles in your own history.#I wouldn't say that removing something is ""to implement"" it.#I don't mind adding this feature at all. It doesn't help me but it doesn't hinder me either, so sure, why not?However, my point is that showing the time and date of the matches as well as your total number of hours does not reveal anything that can affect your private life. If someone does indeed think this is the case, they can hide it altogether with the private function. People hide it for other reasons such as not wanting everyone to see their performance, others just want to keep their own private match history and more advanced stats than Blizz currently offers but not show it to anyone else, etc. I've studied and am still studying security for a while now this sort of data is not really something to be concerned about. If you are afraid of security risks, it's best to not even create an account on a 3rd party website.Also as a side note: Blizzard's WoW armory has an activity feed where it shows what you've been doing in the game. As far as I know there is no way to hide that either, and it shows the date at all times and hour if in the past 24H. Pretty much anything you do in WoW shows up there. Dungeon/Raid kills, Achievements, Items looted, etc.#>Blizz does not show any public info to any other people who are not in my contacts on bnet.You can see the profiles of people who are in the same chat channel as you, the same game as you (random people) and party members (technically not always Bnet friends). Probably someone else too but I'm not sure.#Maybe, but I can't:- check someone's MMR before I finish playing the game with him- check Khaldor's MMR unless I play a game with himSo in most cases it's enough for someone who wants to hide his MMR from teammates or the public.#It's implementing the option to hide it, I thought. #Right, someone else mentioned it. I didn't mind the fact that people want to hide the performance. Still i think the timestamps are something that should not be available and i thought it could be of interest for others. Everyone can make its own opinion. Anyway i made my account private  )#right, it makes sense. Also this thing with HotsStats. I just tried it but i don't use it anymore. Even knowing who is potentially the highest MMR it won't affect my way of playing."
wallstreetbets;4d4hie;1459649939.0;/r/wallstreetbets/comments/4d4hie/nvda/;$NVDA;Has been on a tear this year. Has broken $34 resistance level. Looking overbought so trying to add on a decent pullback. Leader in visual computing chips (GPU). Video games, television, virtual reality, autonomous cars, big data. They surprisingly have a dividend of 1.4%. Revenue and cash flow are at all time highs. Facebook is the first company to adopt NVIDIA Tesla M40 GPU accelerators to train deep neural networks. ;Also check AMD. Gone from 1.84 to 2.73 with recent news of VR use etc. low price play with some added risk in the same sector. #I regret not picking more $NVDA up in the $26 range back in Feb when I had the chance. $NVDA could very well keep up this momentum, it's a highly stable growth stock. At the very least, I don't think any pull back that could happen in the near future would be very significant. Likely around 4%. #ive owned nvda for years and just decided to make some trades involving them in the nxt 2 months.i am bullish on it long term and can see the stock at 100+ in 3-4 year range, but right now i think like most other things in the market it is becoming a bit inflated.http://seekingalpha.com/article/3915666-nvidia-will-drop-q1i read this article a while back and it sort of seems to be coming together. it broke all time highs almost, 10 years ago the 37ish high still stands. i see big upside with VR, cars, mobile gpus needed in every device etc. they are on the edge of entering some big money markets.for the short term i think i will get calls for late may or june as i expect it to climb for earnings. they also have an unveil on the 5th of their pascal processor. i dont see how it can be bad unless its stats are worse than amds by a large margin. it should increase the stock being overbought even more when rsi is already at 70. based on the article i am not sure what to expect on their earnings, you can look at the surprise %s and stuff yourself may is poor for them. i might get puts in early may before earnings on the 5th.my ideal scenario would be to sell the calls early may for profit, buy cheap puts, sell them after earnings drop and then buy more stock if it drops.  the dividend is pretty solid and i love their stuff. i think the more tech oriented we become the more they will be needed.#upvoted for your trill username stay icey#NVDA is an excellent long investment.#You missed every entry point possible tho. The best pullback was in January. NVDA will never go to such lows again unless the Pascal GPUs are a massive flop.#I don't really see how it can go anywhere but up. They practically have a monopoly, they are the defacto standard gpu maker for any high performance computing and they are the best gpu for gaming. Easy long term play in my opinion.#nVidia's biggest competition is AMD though with their Radeon cards, and AMD is killing them in the VR market because everyone is using AMD tech in their headsets (like Oculus, HTC). Plus unless you're an nVidia fan boy, most people are using AMD in their gaming setups because their video cards are generally cheaper but have just as good of performance if not better. I think unless nVidia does something soon to bring back the gaming market, we see it start to drop.#I put all my shit in it lol rekt up 40% so far#yes#I only allocate about 15% of my portfolio tops in buy and hold stocks.  I'm a day trader, I need my capital to remain free , not tied up, , and I trade with the remaining 85%. I don't envy you for going all in on such a safe stock, believe me.    #And it wasnt even a yolo, nvidia's a bluechip#May I ask what trading platform you use to day trade?#Think Or Swim 
InsightfulQuestions;4ehk9g;1460487197.0;/r/InsightfulQuestions/comments/4ehk9g/will_the_big_data_bubble_eventually_burst/;Will the Big Data bubble eventually burst?;Seems there's a lot of money in collecting consumer data right now e.g. shopping habits, location history, browsing history, location history, employment records, contact information and even genetic data.  Will there be a point of little/diminishing returns?  In other words, is there a point at which knowing any more about a person doesn't help in extracting more money from them (outside blackmail)? Otherwise, given how cheap data storage has become, are we stuck with companies recording every interaction in the hopes that some of it can be put to use?;"Well Big Data isn't just about gathering data, it's about being able to perform the right analyses. With the rise of machine learning and data science, I can only see Big Data getting even bigger. Also most data is proprietary, so it's something that needs to be actively accrued by every company, although again, most of the work is in the analysis, not the gathering. #> is there a point at which knowing any more about a person doesn't help in extracting more money from them (outside blackmail)?Yes, definitely. But unlike selling commodities, where you have to give the person say a frappachino to get their $5, In ""big-data"" markets, you just observe them for free (almost), and then sell or use the resulting data. This supports extracting much smaller sums of money from people before the decreasing returns become a problem.#Confirmed.  Most of the big data companies want the holy grail of ROI on ad spend.  Source:  worked in big data.#I don't know, I think a large portion of 'big data' collection schemes are pretty useless. There's the classic example of getting tons of ads for tires after you've already bought tires, and IMO pretty much every extension of data-based advertising is an extension of this. You can't know what someone will do before they do it.#it's easy to scoff at, but that's because most companies do this poorly. On the other hand you have giants like Facebook and Google making billions off of this stuff. And it's not just ads- data is being used to drive some of the most interesting machine learning problems, like Google's self driving car off the top of my head, and (big data) even more so for things like facial/text recognition and other sorts of computer visual processing tasks. #Sure you can.  You can look at everyone who buys tires and find trends in what they're searching before they start looking for tires.#Amazon comes to mind. They suck at this particularly hard, pretty much advertising the last thing you looked at or whatever is in your cart. I'm sure they will improve at it eventually though.#you got google and facebook making billions selling people this stuff. They've been able to do some pretty cool stuff and I don't even doubt some of it will be useful and even make money. But, is big data going to be for every business? Probably not. #You know the best way to tell if someone wants to buy tires? If they're currently expressing interest in buying tires. Not expressed interest two months ago, not demographically or geographically similar to others who've expressed interest, and not someone who your algorithm says subconsciously wants tires. Current expressed interest.Other than marginal improvements like ""does person X own a car,"" there's not much you can do to target people who need tires except targeting people who tell you they need tires. "
bigdata;4db71w;1459778667.0;/r/bigdata/comments/4db71w/will_big_data_tools_replace_manual_etl/;Will Big Data tools replace manual ETL?;"With all the new technologies emerging in the Big Data industry I'm wondering where all this is going. Seems to me that everybody is still trying to figure out the best way to process the high volumes of data.You've got Messaging handlers like Kafka etc. and processing tools like Spark. I'd say the ""plumbing"" is still done manually with companies like Talend catching up with tools and with companies like Hortonworks offering complete platforms.So I'm wondering if the current state of writing Spark jobs manually, configuring your platform manually will soon be replaced by full suites offered by vendors like IBM. Similar to all the Data Warehouse tools today. And that it's just a ""transitioning phase"" right now.Or are the problems too specific and the solutions will always be too complicated?What are your thoughts?";"I wouldn't call the distinction manual vs automated as much as packaged solutions vs custom solutions.ETL has had packaged solutions since its inception in the early 90s.  They haven't completely dominated the field and replaced custom solutions for a variety of reasons that still apply:   * many are basically frameworks using diagram-driven CASE technology from the 1980s that make the easiest 80% of the job slightly easier and the hardest 20% a lot harder.   * many have been expensive   * few have supported the best features and flexibility of highly productive general purpose languages: unit test frameworks, CI testing, version control, devops, daemonizing/scheduling, logging, platforms, monitoring, etc   * most programmers have not wanted to work with themSo, in spite of vendor excitement about monetizing this space, it seems like the problem domain resists most of these efforts.  Kinda like how frameworks like FrontPage didn't replace writing web apps ten years ago.#For plenty of use cases, yes ETL is replaced. Splunk handles this by applying most schema decisions at search time, making the T phase largely obsolete, shrinking the time to value down accordingly.Disclaimer: Splunk employee#You might find real user reviews for all the major ETL and Data Warehousing tools on IT Central Station to be helpful. Regarding Data Warehousing tools, the IT Central Station user community currently ranks Exadata as the #1 tool in this category. This user writes, ""The system is engineered to run both databases and enterprise applications unlike other engineered systems, which are either tailored only for databases or only for applications."" You can read the rest of his review here: https://www.itcentralstation.com/product_reviews/oracle-exadata-review-36620-by-suresh-muddaveerappaAs for the future of ETL tools, this Hyperion Applications Manager writes, ""It's highly flexible, and can interface with almost any technology. One of the best ETL tools."" You can read the rest of her review here: https://www.itcentralstation.com/product_reviews/oracle-data-integrator-odi-review-33449-by-krishna-marur. Hope this helps!#Sure, custom solutions still exist even in established areas. But from my experience ETL in enterprise is mostly done with tools from IBM, SAP etc. And yes they definitely lack features. What I'm seeing with Big Data is that even those same companies now develop custom solutions. #Right, that's actually another scenario. Not simplifying the ETL process, cutting it altogether like with Data Lakes or schemaless imports in Splunk or Solr etc.#Seems like the sweet spot for that is when your source system's data is exactly what you want for searching & reporting, your reporting needs are simple, and you don't have two sources that you need to standardize.#>  But from my experience ETL in enterprise is mostly done with tools from IBM, SAP etc.You see that a lot with ""Corporate Data Warehouses"" - where a single team manages the integration of for an entire company into a single repository.  It's one of the few cases where packaged ETL can excel: you often have a large team of low-skill programmers supporting a single tool.> What I'm seeing with Big Data is that even those same companies now develop custom solutions. I think you're right, and can suggest a few reasons for this:   * The roots of the current surge in big data & data science come from academia & open source communities, whereas data warehousing primarily came from corporations, big business and government.  The big data space has been famously unaware of data warehousing.     About five years ago I was at a Strata conference and during a panel discussion the panelists agreed that data ingestion was the hardest part, but none had ever heard of ETL.  Since then I've seen the acronym ETL pick up a lot of recognition within the big data space.  But its definitely a late-comer.   * Every new platform provides an excuse to compete with established players by claiming to be a native solution to that platform, and possibly shifting terminology.  So, Hadoop has orchestration solutions (like Oozie, etc) that overlap ETL solutions.   * Hadoop is often sold as a silver-bullet for corporate data access and analysis.  ETL is often seen as a bottleneck to getting data onto hadoop.  So some are advocating the elimination of that bottleneck, that we're better off just copying source data to hadoop and letting analysts figure out how to transform data at query time.   * I think today's big data developers are a bit more technical than their data warehousing counterparts.  And so, they are even less enamored by clunky frameworks, less intimidated of writing a lot of code if necessary, and more willing to investigate how to stream or micro-batch billions of rows a day from sources not even yet supported by ETL tool vendors.#I respectfully disagree. Speaking for how Splunk works, the point is that *you don't transform prior to load*. Whether transformation is even needed depends on the use case.Extract can use your existing methods, or Splunk can poll with RDBMS queries, arbitrary scripts, etc.Load consists of dumping the data in as it is, as it's produced, in real-time, which Splunk facilitates a variety of ways such as monitoring files or listening on network ports. Step #2, search and reporting time, you build queries using the Splunk Processing Language, SPL. A simple keyword search just works, and shows you the data broken up into time series events with minimal added structure such as time received, host it came from, a couple of other ""index-time fields"".To build on this, you can extract new fields at search time using a variety of methods such as regular expressions, or parse a known format, or define custom ones. This late binding schema makes dealing with transformation more of a non-blocking problem, and one that can be dynamic as a data format changes, or new ones are added.You can also use SPL commands that will output a table (as opposed to the raw events), combining unstructured and poly-structured data into a single stream that can be further processed and then analyzed.Happy to go deeper.Edit: if you have a mess of data already extracted sitting in Hadoop, we can work with that also. Separate product called Hunk, same front end features for search time reporting and viz, plus the ability to seamlessly combine that data with your real-time sources.#Thanks for your insights!>large team of low-skill programmers supporting a single tool.Well said, a reason why I won't stay in that area for long.>The big data space has been famously unaware of data warehousingYeah and the same applies vice-versa. Lots of mix ups here. But you're right, the overlap isn't quite there yet.>that we're better off just copying source data to hadoopThe dreaded Data Lake. In my company actually the only use case they could think of for Big Data. Classic!>I think today's big data developers are a bit more technical than their data warehousing counterparts.That's probably it. Like you said, a different driver. And I just hope that it stays that way honestly. But I guess it will really boil down to simplifying the process and providing easy tools for the ""low-skill"" programmers.#> Happy to go deeper.Thanks - this seems consistent with OP.So, lets say I've got two IDS solutions in house.   I get 200 million rows/day from each and want to keep data for five years, and use use it for both adhoc analysis with a median query response time of 10 seconds, and on a detailed dashboard with plenty of drill-downs with a median query response time of 1 second.System A has columns that are enumerations like: severity_id, signature_id, sensor_id, threat_cat_id.  To get the actual values we'll have to extract from additional tables and join them.  Since it keeps some data in other tables, it has a lot more data about each of these.System B has columns that contain the actual values like: severity, signature, sensor, threat cat.  Very little sensor data is provided.  However, more sensor data is available through their API.   This solution is planned to be shut down in 12 months, though we must keep the data for the next 5 years.Given the above, how do would Splunk enable time-series analysis of IDS across both products with 1 second response times and plenty of drill-downs?   Who & how translates values from System A to what their corresponding value would be in System B?#>  But I guess it will really boil down to simplifying the process and providing easy tools for the ""low-skill"" programmers.I'm sure that there will be 50 vendors swearing that they have the silver bullet to solve this problem.  But I don't know that we'll see huge adoption from the sharpest organizations.Three-stage (extract, transform, load) ETL pipelines are very easy to build for simple feeds of moderate volume.  And whether you're talking about classic data warehouses or new hadoop not-warehouses, this covers the majority of feeds.It gets a bit harder when you ramp up the volume to billions of rows a day or the latency down to 15 minutes.  But that's still completely doable with standard python on a couple of modest ETL servers.  In both of the above cases you can include unit-testing, CI testing, standard logging, standard daemonizing methods, standard deployments, etc.   In neither does any ETL tool make it easier.   And when you move beyond the above: to extremely complex data structures, to 50 billion rows a day, etc - then you really, really want to use a custom solution most of the time anyhow.#Let's set aside the response time SLOs for the moment because that's a much different discussion about architecture requirements (which we could also go into here or elsewhere), and instead focus on the data problem. 200MM rows/day and low-second response times are quite achievable.Let's call these systems data types ""sourcetypeA"" and ""sourcetypeB"", ""sourcetype"" being the term for how Splunk categorizes data sources. (Contrast to ""source"", which is how the data arrived, e.g. ""UDP:514"".)Let's also assume you've already got the data in one place, in Splunk, using whatever methods I hinted at above. Next steps might look like this:* Build a set of lookup tables to solve the data mapping. These can be static or dynamic. Let's go simple and say you have a set of two-column CSVs that map between the ID and values for each of your fields in question. For example: signature_id, signature.* Using some config files (so things are persisted for all consumers of this data), you will tell Splunk: ""For sourcetype A, extract the fields this way, lookup field values from lookup tables 1-6, make some field aliases"", and so on.* Do similar for sourcetype B as needed* (Optional) Define some tagging rules, and perhaps other specific field extractions to conform to Splunk's [common information model for IDS](https://docs.splunk.com/Documentation/CIM/latest/User/IntrusionDetection), because that's a super common thing to use Splunk for.Then at search-time, maybe your SPL is as simple as:    tag=idsOr, without the CIM mapping:    sourcetype=sourcetypeA OR sourcetype=sourcetypeBThe resulting events will appear consistent in format, and an analyst can slice and dice away.In many cases, the above work has been done for you, with 3rd party data collection, mapping, and perhaps viz being encapsulated within a [Splunk App](https://splunkbase.splunk.com/). This also goes for some cases where the good data can only be obtained from an API, so you might have an integration script or automation on one side or the other that goes and grabs that data and gets it into Splunk for correlation to your events.#Thanks - that helps and makes sense.   It sounds like this doesn't eliminate the transformation - it just moves the easy stuff into Splunk via config files, data mapping, tagging, etc.   Harder stuff - like explode a wild-carded ip address into separate rows for each ip so that these can be joined to your ids data I'm guessing still require preprocessing.> Let's set aside the response time SLOs for the moment because that's a much different discussion about architecture requirementsBut note that it is one of the primary reasons for ETL: to preprocess data to support faster loading, faster queries, greater consistency & concurrency at lower cost.#By the way, can Splunk be used like for example Elasticsearch? So not only for logging data but to let's say index (business) data and serve it via an api? Splunk is always marketed for machine data #> this doesn't eliminate the transformationIt could or it could not, depends on each individual use case. In this example, you're right.> explode a wild-carded ip address into separate rows for each ip so that these can be joined to your ids data I'm guessing still require preprocessingNope. You would be *very* hard pressed to come up with an analytical case for pre-processing, at least for text-based data. We've had >10 years of experience in this area. Lookups support [wildcards](https://answers.splunk.com/answers/52580/can-we-use-wildcard-characters-in-a-lookup-table.html) and [CIDR matches](https://answers.splunk.com/answers/305211/how-to-match-an-ip-address-from-a-lookup-table-of.html). Or you can use a case function. Or you can [split a field's value](http://docs.splunk.com/Documentation/Splunk/latest/SearchReference/CommonEvalFunctions#Multivalue_functions) into multiple values. Lots of options. I'd have to see the data to give you a more concrete example. Maybe that's a job for /r/splunk though.> one of the primary reasons for ETL: to preprocess data to support faster loading, faster queries, greater consistency & concurrency at lower costFair point. I guess it all depends on what you are trying to accomplish. Are you making *network packet routing decisions* or doing *automated stock trading*? That's a millisecond-range use case, and Splunk isn't designed for that. Ok, use your ETL+RDBMS for that.On the far other end, I would say that your 5-year reporting needs most definitely can wait a bit. :D And anything in the, as I said, ""low second"" range on up is in Splunk's wheelhouse.If you are presenting data for use by a single-tasked human operator, 5-15 min lags are usually fine. If you are building long term reports, minutes or an hour is fine. If you are integrating systems and have automated processes to consider (e.g. auto-remediation following an IDS warning), maybe you are in the >1m area. Splunk handles each of these scenarios.Not trying to dodge the sizing question though. We have a whole book on capacity planning. tl dr a 12-core system with fast disks can index 1.2 Tb of new data a day, but [under typical search loads](http://docs.splunk.com/Documentation/Splunk/6.4.0/Capacity/Summaryofperformancerecommendations), handles more like 300GB / day. Daily index volume is the primary metric used when sizing Splunk, not number of events. So you could take your 200MM rows, look at the average (or actual) size of the events, and come up with a preliminary figure that way.edit: assuming 90 bytes per event, that's 18 GB, easily handled with one server.#* Human-generated documents: generally, no, but if your document is XML or JSON, yes* Document metadata: yes* API: yes (REST API + half-dozen SDKs)But Splunk isn't geared for some use cases that document engines like Elastic or Solr handle well. Not my area, but for example, this might include features like: word-splitting, language parsing, ranking results based on fuzzy logic.That said, I've seen [some crazy stuff](http://blogs.splunk.com/2013/10/18/images-search-with-splunk-and-hunk/). :) #Thanks for the detailed answer.   > You would be very hard pressed to come up with an analytical case for pre-processing, at least for text-based data.This looks almost exactly what is called ""ELT"" for extract, then load, then transform.    Does Splunk use that terminology?#Huh interesting, I'll take a look at it. We already have Splunk in our company but for log files.I was looking for a way to index data in an Oracle database and to serve it in an xml format on the fly.#I've rarely even used the term ETL more in a week than today, in this thread. :) No, I've never heard the term ELT before. I suppose it could fit somewhat, but I do want to emphasize that customers aren't doing much transforming in the way you're thinking. The raw data is always preserved. Search time transforms don't alter the data, and they're very granular and contextual. Splunk is about giving everyone access to the data (while still having robust access controls). The person next to you may have different needs, so they'll create different ""knowledge objects"" (field extractions, mapping, lookups, dashboards, etc) that only they see--or these could be shared with a team, or the whole enterprise.What I'm saying is that when transforms are needed, it's not a global requirement forced upon the data, if that makes sense. Therefore, I don't really like ELT, as that implies that you always transform as part of a data onboarding process.#If y'all aren't already using [DB Connect](https://splunkbase.splunk.com/app/2686/), check that out, or you could do integration steps on the Oracle side. And API docs are at dev.splunk.com."
canada;4dn7f6;1459968996.0;/r/canada/comments/4dn7f6/edward_snowden_talks_about_bill_c51_at_simon/;Edward Snowden talks about Bill C-51 at Simon Fraser University Public Square on Big Data;;The part on C 51 starts at about 55:20. He carries discussing the Canadian context after as wellThe whole thing is worth a watch in my opinion #This was super informative and eye opening.  Came for the C-51 rant, stayed for the relevance to life as we know it.  Have an upvote#[deleted]#It was late, so just caught the last half hour, gonna watch the full thing today.
GamerGhazi;4dwndk;1460126074.0;/r/GamerGhazi/comments/4dwndk/how_big_data_harms_poor_communities/;How Big Data Harms Poor Communities;;"This is something I've been thinking about for a while, the idea of ""bias in algorithms"".Specifically with machine learning, I have some amount of worry that an algorithm designed to optimize for X fact will make and produce many results that people will be willing to follow, and accept as not biased at all, with negative consequences.Imagine an insurance company that makes a machine that predicts potential damage to the insured goods, and the machine learns over time that less money means higher chance of damage.  The company trusts this machine as an unbiased source of info, and explicitly starts charging poor people more money.This would be a source of bias that you can't attribute to anyone, and as the machine has no ""default racism/sexism/classism"" built into it like a human does, it may be hard to get discrimination charges to stick.It's not even in design, either, I don't think this is a result of a lack of diversity in tech, but the nature of relation-machines.  When you start making relations, you start stereotyping, and when you start doing this you create biases and activities that can harm people based only on the group they are in.The machines will be accurate in making these assumptions, and I don't think society has learned the fact that discrimination is often done for valid reasons, it's just that the harm we do to people by discrimination is more severe than the benefit we get.It'll be interesting to see that side of things develop, and I'm sure that in the long run things will turn out OK, but there will be bumps on the road for sure.#> His arrests, she said, were “typical of someone who doesn’t have a permanent home”—loitering, for example—and none led to convictions.This reminds me of the similar problem cycle of filtering people out based on their credit- you're poor so you have had credit problems so nobody will hire you so you can't get a job and continue to have credit problems.  I don't understand how conservatives can honestly believe just working hard can lift you out of poverty.  Not in the US, for sure.#Completely off topic and only somewhat related.Another thing that isn't talked about - access to cable, internet, etc.Something like 50% of the population (really low) is online, and only a small portion of that.Something like 50% of the population has cable.90% of this year's presidential debates have been online, on cable, but *not on network television*.  The only exception is CBS News's hosted debate.That's a huge amount of the population without access to this, and only gets that information disseminated as ratings-friendly soundclips.#Yep. Data is only as good as the people interpreting it. I've never seen anything good come from massive generalizations based on statistics that lack context to region or municipality. The privatized intelligence community is pretty freaking scary too. Thompson-Reuters manages a database called World-Check that has the ability to black list people as terrorists. Last year it was revealed that 40% of the people black listed had absolutely no ties to terrorist organizations at all, and had largely been targeted by algorithm looking for ""suspicious sounding names."" In other words, if you're name is Adam, you're fine. If your name is A'da Abu Hamid you're fucked. Not only that, but World-Check is used by the Department of Homeland Security, so some of these people were lucky enough to get on the No-Fly list! Companies like Hire-Right and national banks also use World Check, so sometimes these people can't get jobs or even open bank accounts. I work for state government and we ALSO use World Check, so I can confirm first hand--it is crap. #I was reading Scott's ""Seeing Like A State"" and it reminded me of this very much, and also described attempts by the oppressed to circumvent this by purposely obfuscating things in their environment to evade state control and therefore oppression.   #You might enjoy reading Jeremy Kun's blog posts on algorithmic fairness [1](https://jeremykun.com/2015/07/13/what-does-it-mean-for-an-algorithm-to-be-fair/), [2](https://jeremykun.com/2015/10/19/one-definition-of-algorithmic-fairness-statistical-parity/).#The worse one is the ones who understand you can't always pull yourself up. But because they had to do it, the other poor should have to as well. No reason other than bitterness that someone else gets help they didn't have.#I think a lot more people have internet than cable, though. #both of which negatively affect low-income families, however."
datascience;4cqaid;1459435173.0;/r/datascience/comments/4cqaid/causal_discovery_software_available_for_big_data/;Causal Discovery Software Available for Big Data Analysis;The Center for Causal Discovery (CCD) (www.ccd.pitt.edu) has released the Fast Greedy Search (FGS) algorithm (an optimized version of Chickering's Greedy Equivalence Search algorithm) for use by biomedical investigators who are searching for causal associations in large sets of continuous data.  A technical paper describing the optimization is available at http://arxiv.org/abs/1507.07749.  It is available as free and open source software. This release is just the first step toward providing a suite of algorithms that will assist biomedical researchers in analyzing their data to obtain causal insights. Using simulated data, FGS was able to learn a causal network on data containing 50,000 variables and 1,000 samples in about 15 minutes on a laptop computer. While FGS does not model hidden variables that cause two or more measured variables, an upcoming release of another algorithm will do so.FGS is available as a command line implementation (Causal-cmd) that calls a local Java library or as a Java web application (Causal-web) that runs the analysis at the Pittsburgh Supercomputing Center  the API’s can also be run through R (R-causal) or Python (Py-causal). Additional details and instructions for downloading both these versions of the software are available at http://www.ccd.pitt.edu/wiki/index.php?title=Tools_and_Software.Our goal is to help the biomedical community use causal modeling to gain novel insights and drive innovative research, so we hope to make these tools as usable and useful as possible.  We welcome any and all feedback that you might have, which will help us improve this and future releases. ;
forhire;4dh8j3;1459874184.0;/r/forhire/comments/4dh8j3/hiring_san_francisco_ca_housecanary_is_hiring_for/;[Hiring] (San Francisco, CA) HouseCanary is hiring for 7 jobs: Senior Software Engineer, Software Engineer, Web Developer, Project Manager, Automation Engineer, Director of DevOps and Senior QA Engineer.;Please [send me a message](https://www.reddit.com/message/compose/?to=jungrothmorton) or leave a comment with any questions you have! Click on any job title get the application page for that job. All jobs are not remote, and require being in the appropriate office during normal hours.At HouseCanary, we're using big data and analytics to predict the future of the real estate market in the US. Our goal is to use this data to help people make better real estate decisions. HouseCanary platforms forecast real estate values at a local level, and every month, we forecast 36 months into the future, and our models predict more than 95% of the variation in price over time.# [Data Engineering | Senior Software Engineer](http://www.housecanary.com/careers/?gh_jid=66545&gh_src=82ai1f)San FranciscoWe're seeking a passionate Senior Software Engineer to help build out the dataaggregation and ingestion platform powering the most accurate real estateanalytics tools in the world.**What you'll do:**  * Ingest large amounts of data from numerous sources  * Develop complex queries to solve data mining problems  * Write reliable and efficient programs scaling to massive datasets and large clusters of machines  * Collaborate with talented data scientists to implement predictive models  * Create optimized ETL jobs to power industry-leading front-end applications**What you have:**  * 5+ years software engineering experience  * Expert level Python ability (or willingness to get there)  * Advanced level SQL knowledge  * Excellent communication skills  * Collaborative and proactive personality  * Ability to work through ambiguity and deal with shifting priorities# [Data Engineering | Software Engineer](http://www.housecanary.com/careers/?gh_jid=66933&gh_src=82ai1f)San FranciscoWe're seeking a passionate Software Engineer to help build out the dataaggregation and ingestion platform powering the most accurate real estateanalytics tools in the world.**What you'll do:**  * Ingest large amounts of data from numerous sources  * Develop complex queries to solve data mining problems  * Write reliable and efficient programs scaling to massive datasets and large clusters of machines  * Collaborate with talented data scientists to implement predictive models  * Create optimized ETL jobs to power industry-leading front-end applications**What you have:**  * 2+ years software engineering experience  * Advanced level Python ability  * Strong SQL knowledge  * Excellent communication skills  * Collaborative and proactive personality  * Ability to work through ambiguity and deal with shifting priorities# [HouseCanary Appraiser | Senior Software Engineer](http://www.housecanary.com/careers/?gh_jid=65914&gh_src=82ai1f)San FranciscoWe're seeking a passionate Senior Software Engineer to help build out ourappraiser integrations team.**What you'll do:**  * Manage and build client API integration  * Work with application and big data services to implement business requirements  * Build RESTful APIs to power our HTML5 and iOS applications  * Design and implement scalable features to support growth**What you have:**  * 5+ Years Software Engineering experience  * Advanced level Python preferred  * Advanced level SQL knowledge  * Excellent communication skills  * Collaborative and proactive personality  * Ability to work through ambiguity and deal with shifting priorities**Bonus points for knowledge of:**  * Django and Django REST framework  * Real estate markets  * Complex client integrations # [Web Developer](http://www.housecanary.com/careers/?gh_jid=184660&gh_src=82ai1f)San FranciscoWe're seeking a passionate Web Developer to join our team to help build andmaintain our corporate site, develop internal tools and assist with marketingcontent.**What you'll do:**  * Own HouseCanary.com and associated microsites  * Use bleeding-edge HTML5 features  * Work with design and marketing to build new pages  * Develop world-class email campaigns  * Build internal performance dashboards   * Push the boundaries of modern web technologies**What you have:**  * Mastery of HTML5 and CSS3  * Javascript skills  * Collaborative and proactive personality  * Experience building HTML emails  * Ability to work through ambiguity and deal with shifting priorities**Bonus points for knowledge of:**  * d3 or SVG  * Databases  * Python  * Experience with AngularJS (or any frontend MVC)# [Project Manager](http://www.housecanary.com/careers/?gh_jid=162192&gh_src=82ai1f)San FranciscoWe're seeking a passionate Project Manager to help manage customer projectsuccess and product lifecycle for our world-class products.**What you'll do:**  * Manage timelines, resource planning, quality and delivery for customer engagements  * Lead software projects across HouseCanary to successful completion  * Collaborate with all groups within HC (Appraiser, Pro, data engineering, product, etc.)  * Generate and maintain project documentation  * Organize and direct planning and implementation of all project activities**What you have:**  * A customer-oriented approach  * Experience managing multiple customer projects simultaneously  * Extensive exposure to guiding enterprise projects into production  * An agile and continuous delivery mindset  * Expert-level knowledge of SDLC  * Ability to work cross-functionally   * High level of attention to detail  * Bachelor's degree# [Automation Engineer](http://www.housecanary.com/careers/?gh_jid=63567&gh_src=82ai1f)San FranciscoWe're seeking a passionate Automation Engineer to join our team to helpenhance our test automation environment.**What you'll do:**  * Scale our automated testing framework for end-to-end, integration, API and mobile  * Help instill a testing culture  * Partner with the engineering team to integrate test suites into the continuous integration system  * Improve code coverage metrics**What you have:**  * Experience with modern testing methodologies (BDD, TDD)  * SaaS application testing expertise  * Strong development skills in Python or JavaScript  * Substantial exposure to Selenium  * Agile mindset**Bonus points for knowledge of:**  * AngularJS/Protractor  * Appium  * BrowserStack  * Calabash  * Jenkins or TeamCity  * Databases# [Director of DevOps](http://www.housecanary.com/careers/?gh_jid=140131&gh_src=82ai1f)San FranciscoWe're seeking a passionate Director of DevOps to help manage the softwarerelease process for our world-class products, implement monitoring solutions,and manage our AWS infrastructure.**What you'll do:**  * Own build and release management practices  * Drive infrastructure strategy and operations  * Lead operations service delivery and support  * Implement systems monitoring solutions  * Ensure application and infrastructure security  * Work with an awesome technology team building unmatched products**What you have:**  * Team leadership experience  * An agile and continuous delivery mindset  * Strong Linux skills (RedHat or Ubuntu)  * Deep understanding of AWS  * Experience with infrastructure automation (Salt, Chef, Puppet or Ansible)  * Versed in continuous integration tools (TeamCity, Jenkins, etc.)  * Substantial knowledge of SCM (SVN, Git, Perforce, Mercurial, etc.)  * Experience with application server frameworks, and web servers (Rails, Django, Nginx, Apache HTTP, Flask, etc)  * Monitoring tools expertise (pingdom, nagios, icinga, sensu)  * Relational database mastery (MySQL, PostgreSQL)**Extra credit for:**  * Performance management   * Capacity planning  * Internal office infrastructure experience  * Fantastic sense of humor# [Senior QA Engineer](http://www.housecanary.com/careers/?gh_jid=94664&gh_src=82ai1f)San FranciscoWe're seeking a passionate Senior QA Engineer to help ensure the highest-quality software releases in the industry.**What you'll do:**  * Become an authority on our products  * Perform integration testing with partners  * Test incoming data from partners to ensure accuracy and completeness  * Assist with automated regression testing  * Manage story acceptance testing  * Manually test all components of our apps**What you have:**  * An agile and continuous delivery mindset  * Experience testing web and mobile apps  * Knowledge of relevant tools (Cucumber, Jasmine, etc.)  * Pragmatic attitude and eye for quality  * Experience building test plans  * Excellent soft skills**Extra credit for:**  * Programming experience (Python/JavaScript)  * Previous use of Selenium  * Some understanding of SQL   * Fantastic sense of humor;"Only  US citizens need apply? #Seems to be addressed by your comment below, but just to confirm, all work will be done in your SF office, right? No remote work.#[deleted]#[deleted]#Visa / Green Card Sponsorship ? #You don't have to be a US citizen, but you do have to be able to legally work in the US and be present at our SF office.#All jobs are not remote, and require being in the appropriate office during normal hours.#I'm sorry, but for all of our developer roles we're looking for people with professional experience.#We don't have an ""official"" program in place, but it's something we do if it's the right person for the job. It would just be a conversation during the interview/hiring process.#We will sponsor an H1B visa for the right candidate. If you think you're a good fit, go ahead and apply!"
compsci;4cq5w2;1459433337.0;/r/compsci/comments/4cq5w2/what_should_i_read_in_order_to_be_able_to_read/;What should I read in order to be able to read Judea Pearl's Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference?;"Hi everyone! I'm self-learning computer science. I hope this isn't the wrong place to post this.I heard good things about the book ""Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference by Judea Pearl"" and want to be able to read it.However, on a first read, it seems above my level and I'm not familiar with much of the jargon used. It seems to presume some knowledge about A.I. (of which I have little). I am only a beginner - I've completed MIT's online offerings of 6.00.1x (Intro to CompSci), 6.00.2x (Intro to Computational Thinking), 6.041x (Intro to Probability), some data analytics modules, UCB's Big Data with Apache Spark course, among others.Could you please suggest textbooks for me to read before attempting Judea Pearl's book again?Thank you!";"Try 6.034 (AI), and make sure that you have enough probability/logic to understand Bayesian inference.#I haven't read that book by Pearl but attempted to get anywhere with one of his later ones called ""Causality"". I'm not sure if that's any use to you but for ""Causality"", you'd need some measure theory, probability theory, and graph theory. #Pearl has a new book out [Causal Inference in Statistics: A Primer](http://bayes.cs.ucla.edu/PRIMER/)> This book is accessible to anyone with an interest in interpreting data, from undergraduates, professors, researchers, or to the interested layperson.I think the new book is aiming to get the work on causal inference into the undergraduate curriculum and might be your best starting point.#Thanks for the suggestion! UCB has an archived course on A.I. and I'll definitely check that out!#Don't need no measure theory.#I have borrowed the book from a library and it seems like just the thing I need. Thank you for the great suggestion!"
Entrepreneur;4cq5cz;1459433144.0;/r/Entrepreneur/comments/4cq5cz/help_me_find_a_new_perspective_on_a_product/;Help me find a new perspective on a product;"To give you some background, I am a software developer based in Johannesburg, South Africa. I've been approached by a medical doctor who is currently complaining about the high price and poor quality of medical practice software in the industry.I've been asked to enter into a partnership with the doc, and together he envisions us ""disrupting"" the medical industry with a new practice management system for the medical industry. With a quick Google search, you can pretty much gauge that there are a ton of software systems that exist already, with all of them pretty much doing the same thing:* They are all standalone desktop applications* They all look like shit (The user interface is ancient and none of them are web applications)* They are all charging a high price and making shit tons of moneyI suppose that they are all good enough for the African continent in general, as internet access and speed are our major challenges. (4MBps ADSL line is considered a luxury in most areas)So basically I need to bounce some ideas around and also get some new ideas from the community here so that it would suit the kind of environment we operate in, as well as offer more value than the current competitors at less than half the price.My ideas for the model would be:* develop a simple practice management system using a bunch of API's that already exist for this type of system (links welcome) and sell add ons at a premium*Sell a full system at a reduced price, and have doctors agree to share information on the system for use in analytical applications (Big data in healthcare - could possibly generate revenue by selling data from a large user base)*Sell the system at a reduced price and have advertising within the app?Basically I want to create a product that provides a better experience, at the best price.Potential Challenges:1. Reluctance to move over to a new system because of all the patient information. How could we incentivize this?2. Best platform to build this? Web app or less shitty desktop app I'd appreciate any feedback, ideas and motivation you guys might have. :-)";"Hi Moe,The medical software that is out there, is a joke.  Not only from the use of doctors but from the end users.  I lived in Washington, DC for 3 years and was working with a gentleman there on a medical application for the VA system in the US.  This was my experience and it may only relate to the US.There is an incredible amount of red tape and hoops you have to jump through to get a medical application in practice.  I could write a full post of all the challenges we had but I'll summarize them.1. Certification - If you are providing to private practices (in the US), you have to be HIPPA compliant.  This is an expensive process to get certified.  $10K+ to get.  If you are supplying to the US Government (VA) they require an even stricter certification that was $50K+... so you have to pay to play.2. Getting practices to switch - The current systems are so deeply embedded in their operations its really hard to get them to switch.  Why would they incur all the costs to switch?  Even if you provide it for free, their time has a cost to it.  It's not like they are hurting for business, and patients won't stop going to them because of the their poor software.  These types of changes will only come when they are required.If I was to try to do it, I would start on the patient side.  Build something that would allow them to tap into the medical system and create the demand and pressure from their side.  Of course you have all the security issues, and most of the current medical applications don't have open APIs.  However, trying to tackle this from the practitioners side is going to be long, frustrating, and expensive.  You have to know the right people.  We had an ""in"" at several places with a world renown doctor and still couldn't make an headway. I don't want to discourage you, but I wanted to set proper expectations.  Where normal business practices would seem to prevail, the medical industry doesn't follow those rules.  Meaning saving money, lower cost, more effective, better experience, etc. doesn't always prevail.#If I ever need to go through a medical procedure, I absolutely don't want to know I'm treated by doctors using poor quality software.Get patients to realize this fact.#The voice of reason. #Yo sanmanThanks for this, there is definitely a lot to take into consideration and I suppose my questions are being answered the more I ask people about this. Now as an entrepreneur, you are encouraged to go through the road less travelled and shut out all the critisicm. However there also needs to be a real problem to solve - one of which shitty software isn't really a problem as long as the current needs serve the market. In Africa, we are realistically between 3-5 years behind the more technologically advanced places in the world. So concepts like SaaS are a bit more foreign. Which is a good thing, because it enables us to learn from the mistakes and trends being set by Silicon Valley and also allows us to do our own implementation. Which is why this project interested me - maybe a different take on the traditional way of doing things could disrupt the medical software industry.Another problem I have with the idea is that only the doctor who wants this seems to believe that we can be profitable. He also has a ton of contacts in the medical industry, but if your experience is anything to go by, I can think of much better ideas to spend my time on. Passion is good, but he doesn't really understand the vision for how to roll this out successfully. I like your comments about the normal business practices and how it doesn't apply to the medical industry, and on my next meeting with the doc I will be sure to consolidate all my findings (especially your comments) and let him see the light. I really appreciate the time you took to give your feedback on this. Chat soon man and keep in touch!#You aren't treated by software, you are treated by a doctor. The software is invisible to patients.#I would suggest starting with something small and niche and trying to get momentum that way.  For example, there are a lot of rare diseases people have in the US (probably world) to find treatment for because doctors just don't know enough about the disease.Find a couple different diseases to focus on at first and create an app for tracking symptoms, activity, etc (you would need to learn from doctors what they want to track for which diseases).  For example, some disease might need to track exercise, diet, etc.Here is why it will work.  Doctors and medical professionals will use it because they want the information the patients are tracking.  If a doctor is focused on that disease and lives in CA, he doesn't have access or even know about the people across the country or the world.  This makes it very hard to understand when you are limited with information.Patients will track it because they want a cure to their disease.  This is very true with parents who have a kid who has this disease.We came across this idea at the end of our venture and by then we were out of money, time, and patience.  However, it was very promising and our initial research was very positive around demand.  We never addressed the business model and how we would monetize this.  Anyways thought I would share.#Your story sounds very similar to mind.  I knew one of the most well respected Doctors at John Hopkins and he had tons of contacts.  I heard all the criticism from outside sources, but ignored them.  Healthcare is a huge problem here in this country, and one of the reason its so bad, is the industry is so far behind from a technical stand point.  We just passed a law that at least standardizes medical records so they can now be transferred electronically.It's a very political industry, so like I mentioned before, normal business forces aren't in play.  Wish you the best of luck!#Clarified."
compsci;4dojh7;1459987311.0;/r/compsci/comments/4dojh7/recommend_2_courses_for_a_engineer_trying_to/;Recommend 2 courses for a engineer trying to immerse himself in computer science.;I am an engineer at UT-Austin and I have already taken three CS courses, MATLAB, C, C++. Can ya'll recommend 2 more classes for me to take before I graduate. I am trying to immerse myself in the subject because I have recently learned how important CS is to any field. I have the following classes listed below. You can also recommend other classes too, my objective is to build a strong foundation to then be able to teach myself other subjects. I am especially interested in big data and how to implement it in the oil industry. Thanks guys.CS 320N Topics in Computer ScienceCS 324E Elements of Graphics and VisualizationCS 326E Elements of NetworkingCS 327E Elements of DatabasesC S 328E Topics in Elements of Computing (requires CS 303E as a pre-req)Elements of Computing in SocietyIntro to Game DevelopmentElements of Navigating CyberspaceElements of SecurityCS 329E Topics in Elements of Computing (requires CS 303E and CS 313E as a pre-req)Elements of Data VisualizationElements of Mobile ComputingElements of Web ProgrammingElements of Programming Languages;"Data structures and algorithms.  Without being able to see the course descriptions I can't tell you which course that is, but it's usually a pre-req for most of the rest of the other advanced courses.  #* Data structures and algorithms * Programming languages.Everything else you can pick up on the fly.#Most employers in the cs field have told me data structures is the most important class you can take, and data structures are very important, so my vote is cs228#CS324E or CS327E and whatever the Elements of Data Visualization is.#OP, just so you know, you haven't yet taken any actual computer science. You've just taken courses covering programming languages and basic programming techniques (which is very important for an engineer), but data structures and algorithms will be very different than what you're used to (though you've definitely gotten a taste of data structures before, this course will be significantly more in depth). If you're interested in big data and its implementations, you should take statistics courses instead, especially ones that require you to learn R/S. Data structures and algorithms will be very useful courses if you want to end up as a software guy, but if you're wanting to be an engineer working in oil, then you should take stats and not data structures/algorithms. If you don't believe me, look through [CLRS](http://bayanbox.ir/view/4177858657730907268/introduction-to-algorithms-3rd-edition.pdf), which is the standard algorithms course for sophomores. I highly doubt this is what you're wanting, and it definitely won't be covering big data type issues. Definitely take some stats courses, especially since UT-Austin has one of the best stats programs in the world.  #being very comfortable with relational databases will be a huge benefit for an engineer (particularly for one interested in big data) so ""Elements of Databases"" is by far the most pragmatic for your situation.#https://www.cs.utexas.edu/~lin/cs314h/syllabus.pdfThis is the equivalent syllabus for the course.#This. And since you said you're interested in big data, maybe consider taking a database or data mining course.#Does programming languages just incorporate all languages?#Looks like i'm going with data structures.#You are correct, I have hardly covered any real foundations. Jobs in the oil industry now require having a relative willing to hire you on  in other words, there are no jobs for petroleum engineers. I am trying to do a quick lateral move into comp. sci. and hopefully gain enough knowledge to be employable by the time I graduate.#wise advice from the two repliers above. i second data structures and algorithms + a data course (database, data mining, etc, depending on your school's offerings. they probably have something good)looking at your school's web site - looks like you have a few options on #2 - 347 Data Management, 363D Introduction to Data Mining#Usually it's about alternative programming paradigms like typed functional programming (Haskell, F#, OCaml, Standard ML), untyped functional programming (Scheme, Racket), and logic programming (Prolog, Datalog, SQL).If you don't see any of those programming languages, then in all likelihood your your PL course is shit and you shouldn't take it. If it covers more than three languages, it's also crap.I looked at the syllabus for the PL class at UT Austin though, and it looks entirely reasonable. (Yay Haskell!)#Can you suggest me a book/website/source that helps me understand much of the jargon used in this field? Like something that explains the differences between functional programming, untyped functional programming, and logic programming?#Pierce's TAPL for typed functional programming, Abel & Sussman's SICP for untyped functional programming, and *The Reasoned Schemer* for logic programming.All three are classic works, I'd recommend them to just about anyone.#I would second SICPhttps://github.com/sarabander/sicp-pdf/raw/master/sicp.pdfhttps://www.youtube.com/watch?v=2Op3QLzMgSY&list=PLE18841CABEA24090"
privacy;4egqi8;1460476773.0;/r/privacy/comments/4egqi8/your_face_is_big_data/;Your face is big data;;[deleted]   ^^^^^^^^^^^^^^^^0.2942771641523676  > This comment has been overwritten by [this open source script](https://greasyfork.org/en/scripts/10380-reddit-overwrite) to protect this user&apos s privacy.  The purpose of this script is to help protect users from doxing, stalking, and harassment. It also helps prevent mods from profiling and censoring.    > If you would like to protect yourself, add the Chrome extension [TamperMonkey](https://chrome.google.com/webstore/detail/tampermonkey/dhdgffkkebhmkfjojejmpbldmpobfkfo), or the Firefox extension [GreaseMonkey](https://addons.mozilla.org/en-us/firefox/addon/greasemonkey/) and click Install This Script on [the script](https://greasyfork.org/en/scripts/10380-reddit-overwrite) page.  Then to delete your comments, simply click on your username on Reddit, go to the comments tab, scroll down as far as possible (hint: use [RES](http://www.redditenhancementsuite.com/)), and hit the new OVERWRITE button at the top.#Your face is big ^^^^data#Same.#Same.
politics;4e1edt;1460211418.0;/r/politics/comments/4e1edt/our_politicians_have_a_big_data_problem_if_you/;Our politicians have a Big data problem. If you can't lie can you be in politics?;The problem starts with [this](http://www.vox.com/2014/8/4/5967147/how-a-computer-model-got-to-predict-70-of-supreme-court-decisions). Add prediction modals with [big data](https://en.wikipedia.org/wiki/Big_data) and you can come up with something like panama papers.  Then add something like this [robot lawyer](http://www.digitaltrends.com/cool-tech/free-robotic-lawyer-appealed-3-million-parking-tickets/)  and you have a shit storm. I don't have the resources to do something like this. But I know it can/and more than likely has already happened. And see how this can be used on me. I may matter little in politic. But I don't make choices or millions of people. I look forward to their disgrace. And the destruction of their legacies as most are sub-humans that feed on people.     ;
DataHoarder;4elb0z;1460550282.0;/r/DataHoarder/comments/4elb0z/australiaabc_charlie_pickering_on_big_data_user/;(Australia/ABC): Charlie Pickering on Big Data (User tracking, Purchase tracking, Life tracking etc etc).;Not my video.AXCIOM has better user tracking than any other company out there.Video (analytics likely enabled): https://youtube.com/watch?v=_iRQnghpHp0Download of video via Mega.nz (no analytics): https://mega.nz/#!XNlkhSrY!VKBMFo_INIogeaGTcr6agkzRrWxNWgxkLe018VEs120Transcript: Coming soon.---If I posted this in the wrong subreddit, please alert me as to where this *can* go.;this isn't the best place for it, we hoard data ourselves here. /r/hailcorporate might enjoy this or point you somewhere else.however i would say leave it for now and see how it does#OK.Edit: going to /r/Technology
indonesia;4dle1t;1459943331.0;/r/indonesia/comments/4dle1t/we_know_the_indonesian_government_should_use_the/;We know the Indonesian government should use the data for decision making but to what end/for what purpose? Why is data-driven decision making good? How can the government use big data?;;"Worked on data governance and big data use inside Indonesia govt here. Truth is, ministries & agencies who claim to have big data actually don't really have one. Consider census data which is used for virtually all development indicators and target: you can fit the raw data in a $20 USB flash disk, it's only renewed once every 10 years, and most decision making process uses the aggregated version of it (which usually fits within e-mail attachment limit). Hell, we don't even know how much people actually earn since so few pay taxes anyway and so many things went unreported. Second biggest problem is that we lost a lot of data because nobody really bothers to think of archival process. Case in point, last presidential election is the first time where we actually record and have multiple copies of results in polling booth level. Nobody even have anything lower than provincial level for the election before 2004.Some exception do apply. LAPAN and BIG heavily invest on the necessary infra & people to store their terabytes of satelite imagery, and their data is actually used for other ministries. Beyond that, I dread every meeting where ""data driven decision"" and ""big data"" phrase is mentioned. More often than not, my reaction is a deep sigh.#As business intelligence person I think I can answer this.  Through big data, government can see the characteristics of their population. Depending on how expansive their data gathering is, they can know how people spend their money, how much time spent by people doing things, what kind of demographics that are prone to be poor, unemployed and/or uneducated.  Using all this information, they can come up with targeted programs to deal with vulnerable areas (e.g. Welfare program that subsidize big part of poor people's spending, more investment to schools in areas with high risk of uneducated people) or it can go to even be more nuanced public relations (e.g. What media they should use to make certain announcement to receive the greatest exposure to their audience, what wording that would be most effective to cause desired outcome)#well, it's good for anything and everything. Making decision without a basis of data is what we call a guesswork. We don't want our government to make wild guess based on a hunch, do we?This is why we should support any and every government programs that aim to collect data of its citizens. We must sacrifice individual privacy for the better of our country. Remember what Jesus, Buddha, and Muhammad jointly said in their respective autobiographical novels: ask not what your country can do for you — ask what you can do for your country.#After I read this article about paradox, I think big data can be used as political tools to do what he want (for good or bad thing) https://blog.forrestthewoods.com/my-favorite-paradox-14fab39524da#.w40dm8kblTo quote from the article >No matter how much data you have you still have to ask the right questions. It’s painfully easy to have good intentions but ask the wrong question and find the wrong answer.#[deleted]#Wow, why I'm not surprised.#Could small consumer goods business utilize big data too?#did they really say that? i thought kennedy was the one who said that...#Home work...real work...Reddit is an amazing sounding board when you want to hear/read what people really think. The conversation around data is tough. We all know it has potential, but we know how tired we are of hearing Indonesia and potential in the same sentence. #any business should ideally use big data. however it's a luxury and not a need (you can still do your business without using it), not to mention that it's not cheap (data gathering, software, and employees). depends on how many information you want to gather, it may not be as expensive and the data may already be there, waiting to be mined. for example:  - from transaction records you can gather what kind of goods people like to buy together, so you can put them close to each other or offer a combo.  - ask customers how do they know about the business and keep record, build marketing strategy around the most popular ones  - ask customers where do they live, what their occupation is, etc, and you'll get better insights of what kind of your customer base is. you can then come up with products or offering based on customer base's characteristic.   if you notice, most of those things have been done by many businesses, without realizing what they're doing is small scale data mining. big data just means that they do it formally in much much larger scale (even by acquiring extra information about customers from survey agencies or government organizations). not sure how much information survey agencies and government organizations in Indonesia have though.#Kennedy was born muslim, converted to christianity and became buddha when he died.#[deleted]#Very interesting... #I apologise if there was any confusion. It was not homework. I am not a student. Thank you for the offer to discuss further. I will let you know if I have any questions. Thank you for the insight. "
technology;4dgfbp;1459863233.0;/r/technology/comments/4dgfbp/how_big_data_is_changing_our_understanding_of/;"How ""Big Data"" is changing our understanding of history";;reddit hug of death, confirmed.#with only 14 upvotes, and your the only one who commented? I dont think reddit had anything to do with it.
scala;4dz0rx;1460158486.0;/r/scala/comments/4dz0rx/no_entry_level_scala_jobs/;No Entry Level Scala Jobs;"If you go to a website like Monster, Indeed, or Dice and search ""Scala"", you will find a lot of mid-level and senior-level Scala jobs. You will find jobs that pay a lot of money and involve big data. But you will not find entry level jobs.I recently took a HackerRank coding puzzle that was emailed to me as part of a job search and HackerRank offered Scala as one of the languages that you could do the puzzle in, but all the Jobs were Java/Python.This annoys me. I am looking for my first paid coding job and I went through a lot of trouble to learn Scala, so it frustrates me that none of the jobs that involve Scala are available to me.What can we do to bring Scala to the younger, entry level, and junior  developers?";"Just apply for the mid-level jobs. Good teams hire for attitude and desire to learn, not for a list of checked tick marks. You'll figure out who's good and bad quickly.#Just apply for mid level jobs anyways. There isn't that much difference in responsibility in a junior and mid level developer outside of perhaps being able to work more autonomously. So be prepared the emphasize that in your interview.Also, it may just be your location, a quick search for junior positions on Indeed in my area(Washington, DC) revealed about 100 positions, I did not find my own place of employment on the list which is looking for Scala developers at all skill levels, so I don't believe it to be comprehensive.#The [Underscore Scala jobs board](http://underscore.io/jobs/) highlights jobs where junior applicants are welcome. Location and the possibility of remote work are also listed.#I would think that [scala.js](http://www.scala-js.org/) might be a possible path. There are probably more entry level web development jobs, and given the unsuitability of JavaScript for programming-in-the-large, more employers might be sympathetic to the use of Scala as a web development language.Disclaimer: I'm not connected to the development of scala.js, just a grateful user.#Learning one language and then finding a series of jobs that use that language is only a practical way to go for languages that have massive usage, like Java and C#. I'm sure that with hindsight, you would have checked Scala demand before investing a lot of time into learning it, as opposed to skills that are easier to get that first job with. I strongly believe learning a language like Scala is a great career investment, but it may not have minimized time-to-first-job. I wouldn't get down about it, because your Scala skills will eventually come in handy, once you build some work experience.As someone who has led Scala teams, I would rather frankly rather hire someone who is an accomplished programmer with a strong interest in learning Scala than a person with Scala experience but no track record. I'm sure many would feel the same way. So, the way I see it, you have three choices.- You can keep trying for an entry-level Scala gig. That's going to be  a tall order.- You can find ways to build proof of your Scala skills through independent work. To many places who are hiring, accomplishment in open-source work is on par with accomplishment in paid work. There are lots of great projects out there to contribute to in the Scala ecosystem.- You can learn a language that has better employment on-ramps, like Javascript.As an aside, reading your responses throughout this page, you should consider putting some work into how you present yourself. Someone dropping a ""that's retarded"" in normal, public conversation would be a red flag many places.#You dont nessecerily have to know the language the firm code in, in order to get hired as a intern/junior dev. All programmers have been where you are right now, but what all professional programmers have done at some point, is to just let go of that anxiety and fake it till you make it. So who cares if they program java or python and you code Scala, they don't expect you to know it from the beginning anyway, what they expect you to do is to go home and read a book about it. #What are you talking about? I have never had an internship or a job other than fast food. I never fixed a bug for anyone other than myself at any point in my life.When I say ""entry level"" I mean like internship or first job ever. #Umm... mid level jobs still ask for 2-4 years of experience. I never fixed a bug for anyone other than myself at any point in my life.Java and Python have plenty of jobs and internships listed with zero experience requirement what so ever. When I say ""entry level"" I mean like internship or first job ever.#Thank you#> ""You can keep trying for an entry-level Scala gig. That's going to be a tall order."" Thank you for admitting that. I never actually learned Scala for the job, lol. I learned it because I was taking a design patterns class and the prof let me use whatever language I wanted and I picked Scala for design patterns. The most popular piece of open source work that I have created is this:https://github.com/JohnReedLOL/scala-trace-debug/I know it's not the flashiest thing ever, but most of my projects are related to networking or concurrency, so I spend a lot of time doing multithreaded debugging and this tool (which I originally implemented in Java) has served me well in the past.Also, there is a difference between how I talk to other people my age (on the internet) and how I talk to someone who is older. I mean that if I had a business I would hire the right people for the job instead of hiring the wrong people and then spending double time on training. Not that I know anything about running a business.#That's retarded. If you hire a bunch of Python programmers to do a functional backend in Scala with someone with a Haskell/Erlang background and tell the Python programmers to ""read a book"", they will probably suck and it will probably take several months before they cease to suck. Heck, if you take seasoned Java programmers with no functional background what so ever and no understanding of any of the features they will still probably suck. Do employers seriously waste 1,2,3,4 months just getting people up to speed?#Well, you need to start somewhere. It's a cliche, but it's true. Huge movie stars tend bar or wait tables before they hit it big. You have to settle for starting with HTML/JS/CSS (or anything, really) code monkeying before you can climb up to mid-level Scala.#A lot of the time requirements are overstated. Certainly if you've covered everything else they're after I wouldn't worry about not having the amount of experience they're asking for. Mention in your cover letter that you have Scala abilities commensurate with the more senior position and that your answers to their problems demonstrate this. Anything that can demonstrate real-world programming experience will help too  (e.g. open-source contributions or projects of your own) - IME the biggest disadvantage fresh graduates have tends to be an overly theoretical/academic view, so anything you can do to show you're a real working programmer is great. Alternatively, just take the Java position and then look to transition into writing Scala (not with a big process, just propose to do the next component in Scala). You'll need solid JVM knowledge and the ability to drop into Java occasionally in any case if you're going to have a career in Scala.#That looks like a pretty impressive project, clearly you know what you're doing! Maybe reach out to some of the consultancies, like Cake Solutions. They're always looking for people with a strong command of the language.> Also, there is a difference between how I talk to other people my age (on the internet) and how I talk to someone who is older.I don't know what your age is, but I'd just be aware that you're not necessarily only communicating with people your age, but you may well be communicating with people who know where entry-level gigs can be found. And even when it comes to people your age, you never know who might be insulted by careless choice of words.#Yes, they do waste that money. I was in your position about 1 year and 3 months ago. I only knew how to do  Java desktop applications and was only 1 year into my study. And i was hired at a firm mostly working in  .net and php. in the past month ive delivered the first project to a customer by my self where the company i work for actually for the first time made some money on my programming. I guess they did earn a little on me in a period where i was to teach a company about their new LMS for 1 month, but that wasn't programming related at all - so i dont think that counts. #My age is 22. Also, since you commented on it, I added a new feature to it. https://github.com/JohnReedLOL/scala-trace-debug/blob/master/README.md^ The screenshot that says ""Logger Integration""#What on earth did you do for 1 year 2 months? Also, Java isn't really used for client side desktop applications in the real world - occasionally I will see it for an installer or PortMapper or whatever, but you will almost never see serious desktop applications using Swing.Also, since you are new to the language, try my library. https://github.com/JohnReedLOL/scala-trace-debugThe JAR file it is in ""scala-trace-debug/target/scala-2.11""#Hiring programmers for different languages is perfectly sensible.Java is used a lot for client side internal tools in the business world. Though there's a shift to HTML-based UIs these days.I don't understand how you think you know all about business practices when you have no experience. And you certainly won't get a job if the interviewer tells you how they work and you say ""that's retarded"". Lose the attitude. #> ""I don't understand how you think you know all about business practices when you have no experience."" Well I have interviewed a couple dozen people in order to hire people for a prospective startup that never got off the ground. I kind of have a minor in business administration, but that is more focused on general business practices than on software business practices.>  And you certainly won't get a job if the interviewer tells you how they work and you say ""that's retarded""There's a difference between how I talk to other people my age (online) and how I talk to someone 10, 20, 30 years older (face-to-face). I mean that if I was trying to create a business I wouldn't hire a PHP/Java/Swing person to do a C# application unless I was sure they were insanely smart. > Lose the attitude.I'm used to being a ""lone wolf"" or a ""lead sled dog"". I mean I am usually ahead of people (who are my age) or doing something on my own, so saying things like ""What on earth did you do for 1 year 2 months?"" is not a weird thing for me. I would lose the attitude, but the whole ""wtf is this shit"" thing is sort of a part of my personality."
OpenBazaar;4bzag6;1458954237.0;/r/OpenBazaar/comments/4bzag6/how_much_data_is_likely_to_accumulate_on_ob_will/;How much data is likely to accumulate on OB? Will it really scale?;Anybody with Enterprise IT architecture, or Big Data, experience tip toe into wagering a guess about how much data is going to pile up? And, if so, how fast?Update: I had a pre-conceived notion that OB worked off a growing block-chain or torrent-scheme, where as time progressed the data (listings, transactions, merchants, users, reputation, etc.) would accumulate.  ...clearly I have some reading to do.;"Do you understand the structure of OpenBazaar? Where exactly are you expecting data to ""pile up?"" #Your question is about centralized systems.  Like saying ""how does Facebook manage data?""But OB is decentralized, it's a protocol.  It's like asking if BitTorrent will run out of storage, or asking who's responsible for storing email.It's distributed, the storage for your transactions and charges are on your machine.  When you run a store, that data is on your machine.  No-one but you is expected to store your data.#Andreas Ant. discusses this in the video that was posted in this sub:  https://www.youtube.com/watch?v=1Hin6etppaI&feature=youtu.be&t=9680He had no concerns about scaling and explained that each person's ""store"" requires very little data and that millions of stores can be saved on the memory available in a typical smartphone.#I have a vague idea about the distributed nature of it, relying on P2P sharing of listings.  But I don't have any idea about, for instance, are images part of a listing? Or are merchants expected to host their images on a separate service? Are transactions stored on the network - even temporarily?If OB grows to 10% the size of Amazon...we're at 20 million listings.  E-bay has 1M to 10M new listings, per day (per a 2013 Quora post).#How are reputation scores stored and shared to new users?#So copies of listings don't propagate across the network, making some kind of per-node copy?#The images are hosted on your store server/node.#No, although I hear some caching of content by nearby nodes will be a feature that they will add later, so you don't have to keep your computer on 24/7 to run a store.But even then, it will only be your ""neighbors"" holding your listings for a few hours.I'm not exactly sure how the search functionality works.  It's either everyone pinging your store node directly, or the listings transmit over a chain of nodes.  But the bottom line is that no-one else stores your data for you.#I've got the client running, just did a search.  Won't searching start to really suck, without some indexing/cache strategy?#Not sure if I'm able to go further into detail, as I haven't dug into OB's infrastructure this far.But this is the job of the OB server you're running, and I know it uses a DHT (Distributed Hash Table).  That allows for simple searching over the network, indexed by keyword phrases.But I also know that your listings do not stay online if you shutdown your server, so I guess the other nodes are just passing along information, not storing it.I guess in theory, your local server can handle more than enough of the searching and traffic needed for your usage.  It's certainly more scalable than a centralized system.#Yes, and we'll likely be relying on third parties to do this (just like with torrents) unless there's some breakthrough in decentralized search. "
techsupport;4bz0pn;1458949747.0;/r/techsupport/comments/4bz0pn/screwed_mbr_partition_on_asus_rog_gl552vw/;Screwed MBR / partition on ASUS ROG GL552VW;"Yesterday i bought a ASUS ROG GL552VW. It only had a SATA HDD. So i bought a SATA M.2 SSD to run the OS on.There are no boot priority options in the BIOS for the different drives. Only Windows Boot Manager and the DVD drive if there is a DVD in there. So i just booted the windows DVD and installed Windows 10 on the SSD. This worked fine and the clean windows 10 install boots every time.So sofar so good. I wanted 1 big data partition though for the HDD. The HDD was split into 4 partitions. I was not able to merge any of them in windows. So i booted the windows installer and deleted all of them there. This obviously screwed my boot up. My drives look like this now:- Drive 1: Unallocated drive of 1 TB- Drive 2: 16 MB reserved partition and 465 GB partition with my windows (which i want to keep intact)So yeah i just want to be able to boot the windows that's still there and keep drive 1 as a data disc.Here are my observations:- The BIOS doesn't show the Windows boot manager anymore as a boot option. Only the DVD drive- I think the HDD is still the primary drive. I have no idea how to change this to the SSD.- I've been trying a lot by booting with the windows DVD and going to the command prompt and using bootrec.exe. But no luck. The laptop only boots to the BIOS and there is no windows boot manager there. Commands like /fixmbr and /fixboot say operation completed. /Rebuildbcd finds the windows installation. But when i add it to the boot list it just says ""the requested system device cannot be found""";"This is happened to me before. 3 days and no answer so I doubt there is much hope of recovery. Wipe and road, and hopefully you have kept good data practices.#I got it myself. I will list the solution here for others:1. Fixing the MBR is fairly easy with bootrec. I went with option 2 on the link below. Probably it was not needed but i wanted to be sure it would be restored on the SSD.https://tweakhound.com/2012/11/13/how-to-fix-the-windows-bootloader/2. The bios of the laptop is Aptio Setup Utillity. There is a mapping there with the UEFI. By formatting the HDD i removed the original mapping. So i had to remap it to the new location on the SSD manually. See the link below:https://www.thomas-krenn.com/en/wiki/Restoring_UEFI_boot_entry_via_motherboard_replacement_or_BIOS_update#Entering_the_UEFI_Boot_Entry_manually_in_BIOSEdit: Well i got windows to boot. But now i'm unable to shut it down, shut down just takes me to the login screen. I'm doing research now...#When in doubt, throw it out. Remove the M.2 drive and see if you get different results. #why not just boot of a windows USB and delete all of the damn partitions and start fresh?#Oh this is simple. Hold shift and right click the start button. Press disk management. Right click the unallocated drive and press ""create new simple volume"" or something like that. Allocate the full size of the drive, then give it a drive letter and file system type (NTFS works best on windows but only windows with some exceptions), wait and you should be done. The reason its doing this is because windows has no idea what kind of drive it is, because its blank. So you need to tell it is has a file system type of X (such as NTFS) and is Y megabytes big.You can also use an Ubuntu USB and some programs to fix the MBR. Such as this http://ubuntuforums.org/showthread.php?t=622828#Yeah i do have my important data. I just put some work in the install. And a lot of downloading time. On a slow connection here right now. So that's why.I'm pretty sure this is fixable because the windows install is still there. There are just several things i don't know.#Thanks for posting this. I'm looking into getting the same laptop. Didbyou figure out your problem with shutting down? (the desktop I use at work does the same but I think it's some setting they use to never shut it down on purpose)Also what do you think of the laptop in general? Are you happy with your purchase or do you wish you went for somethibg else now?#The M.2 drives works fine. Besides i want everything on there. Including the boot info.#That will probably work yes. But i want to keep the install and that's the stupid solution. Also not sure it will work because i think the laptop somehow is only looking at the HDD to boot. I' considering to pull out the HDD for that. I think non of this is needed though. Just need to recover the MBR of UEFI or whatever. I lack experience..#Getting the partition as one is no problem. Doing that is what made me remove the MBR.The Ubuntu solution could work, i'm not sure with my laptop. Old post though. I can load the bootrec.exe tool in the windows installer just fine. I'm just unable to fix it with that. I think now i will try it again and somehow targeting the SSD the install is one.#Sorry i just saw this. I still haven't figured out what's up with the shutdown problem. I still use this shutdown.exe shortcut:%windir%\System32\shutdown.exe /s /t 0I don't really care that much. But this is 100% a windows / software thing.I'm definitely happy with the laptop. It's good value for the price point. I do recommend a SSD. But then you have best of both worlds as well. Fast SSD and decent storage.#This comment has been overwritten by an open source script to protect this user&apos s privacy.  It was created to help protect users from doxing, stalking, and harassment.    If you would also like to protect yourself, add the Chrome extension [TamperMonkey](https://chrome.google.com/webstore/detail/tampermonkey/dhdgffkkebhmkfjojejmpbldmpobfkfo), or the Firefox extension [GreaseMonkey](https://addons.mozilla.org/en-us/firefox/addon/greasemonkey/) and add [this open source script](https://greasyfork.org/en/scripts/10380-reddit-overwrite).    Then simply click on your username on Reddit, go to the comments tab, scroll down as far as possibe (hint:use [RES](http://www.redditenhancementsuite.com/)), and hit the new OVERWRITE button at the top.     Also, please consider using [Voat.co](https://voat.co) as an alternative to Reddit as Voat does not censor political content.#Haha great. Yeah man it's such a must have. Have fun with it!"
Music;4cfsc5;1459263541.0;/r/Music/comments/4cfsc5/big_data_dangerous_alternativeelectropop/;Big Data - Dangerous [Alternative/Electropop];;"Very cool and creepy song, but after not too many listens I realized they kinda nicked the bass groove from NIN's ""Only,"" and now I can't unhear it. #This is the most absurd music video I've ever seen. Good song.#I didn't realize that.Also wanted to add, the first time I saw this music video it scared the crap out of me, now I just think it's hysterically funny."
HiTMAN;4cmw77;1459373076.0;/r/HiTMAN/comments/4cmw77/music_to_garrote_to/;Music to garrote to...;What kind of music do you guys listen to when you play Hitman, or makes you think of Hitman? Lame question, I know. Ah well, here are a few of mine:Daft Punk-Dafunk: https://www.youtube.com/watch?v=n1ZqN_VFhdo Wings-Live and Let Die:https://www.youtube.com/watch?v=b07Z_qfchFk(Video is the intro to the Bond movie of the same name)Big Data-Dangerous:https://www.youtube.com/watch?v=E8b4xYbEugoDean Martin-That's Amore (for Sapienza):https://www.youtube.com/watch?v=OnFlx2Lnr9Q Frank Sinatra-Fly Me To The Moon (for everywhere else):https://www.youtube.com/watch?v=mhZ2X9znPxMMetallica-Sad But True (just kidding):https://www.youtube.com/watch?v=O_4OfD-wmGs Well? What do you think? And let's see if you have music of your own for me!;"Ave Maria#I want the ""Call Me 47"" song and Sanguine runway music on my phone for runs in the morning and pre-drinking at night. Make it happen, IO!#Killing strangers marolyn manson#Codename 47 soundtrack was baller.#https://www.youtube.com/watch?v=rY0WxgSXdEE&ab_channel=QueenOfficialAnother One Bites the Dust - Queen (For homicidal runs) #Play the old games music.#24/7#Precisely. Followed closely by *In the Hall of the Mountain King*, for comedy value if nothing else.#I'm still waiting for ""Apocalypse"" to play in-game. And I want to find that trailer music...#Sounds scarily appropriate...#Damn right! Pretty much all the soundtracks were pretty...**Silverballer!** *ba-dum TISH*#Thanks man! I have yet to try a homicide run on Paris. I'll get around to it *sometime* this week. Any other songs come to mind?#It is hard to think of music when there is essentially just one map so far. If their is a beach level I will be playing some very Hawaiian music. "
bigdata;4dvyah;1460114775.0;/r/bigdata/comments/4dvyah/geek_professor_drops_rap_video_song_about_the/;"""Geek Professor Drops Rap Video"" - Song About the Power of Big Data :)";;I love it when you call Big Data...  Too good!  lol
haskell;4dq28m;1460015027.0;/r/haskell/comments/4dq28m/workflow_automation/;Workflow automation;"Hello,I am facing a problem that I feel like smart people have solved so I would like to discuss it with you.My current workflow involves more than a few tasks that it makes sense to automate. When I started working on the cluster of projects I am currently working on I used makefiles (which was my goto tool for automation/system state management) but things got out of hand very quickly so I wrote some bash scripts to help out but that didn't help too much either. So I started experimenting with [shake](http://shakebuild.com/) but that also fell short after some time. I think the best tool would be something all the cool kids use lately for deploying agile containerized microservises to process big data on the cloud like ansible or chef (ie not a build system), but I tend to be suspicious of new technologies that might use `leftpad`. I value the opinion of fellow functional programmers so I wanted to hear what you think before I switch yet again.To give you a feel of the kinds of tasks I am dealing with, here are some examples:## Simple build system stuffMake sure binary files are up to date with source files.## More complex build system stuffDownload archive, extract it, make some changes, archive, rsync with server.## Manage git repositoriesI need some git automation tasks to act as dependencies for other computation. Some of these tasks may be simple like ""make sure X repo is at B branch and that branch is in sync with upstream"" and sometimes may are fairly complex:- Clone a project or pull the ""development"" branch- Create or switch to a branch based on some version- Merge development into that branch- Maybe apply some automated changes to the source tree (eg sync some files, update versions in manifest files etc)- If changes were applied push the branch.## Run processes that need to succeedBasically make sure everything is in order and run tests before doing anything that would upload anything anywhere.## Run processes and waitMostly this would mean fire up a bunch of server applications (http, database) if they are not already there, make sure the proper files are compiled and in the correct directories, and open a browser at a specific page for manual testing.";"It sounds like nix might be interesting for you: https://nixos.org/nix/#I use Shake for a lot of this stuff at work currently. It's well documented, but doesn't convey a lot of what you can do with it super well until you spend some time staring at the API or asking on the mailing list.#[Propellor](https://propellor.branchable.com/) might be worth a look - although I'll also second Nix/NixOS/Nixops.#First of all split up building and deployment. Building gives you deployable artifacts (binaries, apt packages, docker images etc).> apply some automated changes to the source treeLooks like a major red flag - why do automated changes live in the source tree but not derived and applied at build time?> Mostly this would mean fire up a bunch of server applications (http, database)Is this about your development or production setup? Regardless, you can use docker-compose for development environment setup. For system setup, you can use Ansible (it's the best system setup/deployment orchestration solution :)#I have used nix but I thought it was only for package management and generally only system wide. I will look into it more.#I also am increasingly using Shake and finding it great. OP, you didn't say why you are ruling it out ?#Porpellor looks awesome! I will definitely give it a shot.#It's definitely not only system wide. I know a few people using it to manage software on Mac OS X or Ubuntu, and one of the reasons I like NixOS is that Nix does a good job of managing packages on a per-user (or even per-project!) basis.The other part being that package management naturally subsumes at least part of your workflow automation, but I don't know exactly how much Nix can do for you and how much you'd have to integrate other tools like Shake into it.#I'd heard about it in other contexts, but I had a closer look after hearing about the combination of [Shake, Bake, Propellor and Docker](https://speakerdeck.com/abailly/haskell-all-the-way-down-2).#What is Nix? Nix describes itself as a package manager. It sounds like it's actually more general than that.#I'm just a casual user of Nix so others would be able to give more details. As I see it, it is ""just"" a package manager, but one that provides enough functionality and flexibility to carry out other roles as well.In particular, it provides a level of control and isolation that can be used to ensure reproducible builds and deployments. I have some friends at a startup that use it to develop and deploy their server-side software for this reason  Nix is fulfilling a common use case of containers. "
datascience;4crt3j;1459454795.0;/r/datascience/comments/4crt3j/master_in_statistic_or_computer_science/;Master in Statistic or Computer Science;Hello everyone,I'm about to graduate in May with a B.S. degree in CS. I’m planning to go to graduate school immediately afterwards. My goal is to become a data scientist focusing on machine learning and AI.I’ve looked at my school M.S. program for data science and most of the classes are Big Data related. One of my friends said I should get a M.S. in Statistics instead because it will be more useful.Which M.S. degree should I go for (CS/Math/Stat)? It would be greatly appreciated if someone can tell me the pros and cons of these degrees. ;"Firstly, if you want to work seriously in machine learning and in particular AI, with focus on the mathematical and algorithmic development side, you're going to go up against some extraordinarily talented competition.   (By this I mean being able to publish papers in JMLR for instance). You may be up for it, but that's unquestionably a top-level PhD route, probably in CS or, secondarily, Statistics from a ML friendly department like Stanford. For getting a decent commercial job with a master's, I think that a CS with more heavy software focus will be more generally applicable.  At my job we hire from various backgrounds, but we won't hire somebody who uses ""just packages"", i.e. has just light scripting experience and uses R and SAS, which is what many statistics programs do.   (if you're going into biomedical statistics, an entirely different area, then that's fine).  We want people who can really program.  Significant Java/C++ systems are OK, don't need kernel drivers. In a practical year long project in industry, I've seen averages of  around about 4 weeks of 'analytics/machine learning', 30 weeks of software engineering and 18 weeks of data cleaning with business & project meetings & powerpoints interspersed continuously. On the resume, generally CS = higher salary than Statistics or Math in the beginning  at least there is the perception that there is more competition for good CS graduates.#It's good that you already know what career path you want to follow because that alone tells you which classes will maximize your ROI. The exact title of your MSc matters little to none. That said, look for classes that will make you more employable. For academic ML, that's any class that covers some area of mathematical statistics. For a data science org, that's algorithms, presentability and business acumen. If there are classes which expose you to companies (via a long project, dissertation, etc) opt for those.#Would you rather study the data, build the models and fine tune them,  or develop the software the handles the data before being fed into the model.  I would recommend stats but take a lot of comp sci data classes.  Ultimately computer science means you get a job, and statistics means you don't have to deal with a UI.  What you do the 5-10 years after grad school will determine if you have what it takes to work in machine learning and take that stats to the next level.  I am currently on year 3 out of undergrad with a stats major working on a development team considering if I should go back for my masters in the next 5 years.  so take this with advice grain of salt.#Way to highlight the fact that enterprise level machine learning isn't just a team of 1 person.  You are going to have experts in many different fields.  OP can really go either direction.  I would say computer science is most important but OP already has a BS in comp sci so I think stats is an option.  #Is Java/C++ a requirement for your openings or would I be fine with Python? #Are there any schools that are particularly well known for the AI-focused PhD programs?#Can you elaborate more on biomedical statistics? #It could be acceptable for some entry level positions that are not targeted towards a heavy-software engineering profile.  Anything above that it would be significantly limiting and people would wonder about your breadth of experience.  If you came from a CS program it would be very odd if you've used only Python. Generally a python-only candidate has less experience dealing with higher-performance transaction oriented issues or larger scale software systems, or software engineering methodologies like continuous integration, unit tests, etc. E.g. some various tasks we deal with may be write simple REST servers, talk to databases, write code for Spark, Big Data frameworks, etc.  Our more software focused hires may have experience setting up VM's, distributed systems on AWS or other cloud systems, administering Jenkins continuous integration servers, Maven build systems, etc.   Again, this is a subset of people, certainly not everybody. But my group deals with reasonably high transaction volumes for production systems which is not everybody. #Stanford, University of Toronto, UC Berkeley?, MIT, CMU?.  But it's more of finding the right individual professors.  At the PhD level departments matter less than individual professors.There's really a wide variety.Go to some top journals and see where the authors are from. "
snowden;4dhdzh;1459876074.0;/r/snowden/comments/4dhdzh/edward_snowden_live_webcast_at_7_pst_tonight/;Edward Snowden LIVE webcast at 7 PST tonight;Edward Snowden live in conversation tonight, hosted by Simon Fraser University. Audience members will have the opportunity to submit questions via Twitter using the hashtags #snowden and #bigdata during the discussion.;Will I be able to rewatch it tomorrow? 19:00 PST is 03:00 UK :-(#Stream: https://www.youtube.com/watch?v=crM0CTXCJm4#I'm not sure -- I've been told that the contract allows the university to host the recording on an internal library archive -- but I'm not sure if the library archive is allowed to be accessed by anyone who doesn't have an sfu.ca email account. #Ah ok :-)
bigdata;4cceeq;1459202242.0;/r/bigdata/comments/4cceeq/can_big_data_help_psychiatry_unravel_the/;Can Big Data Help Psychiatry Unravel the Complexity of Mental Illness?;;
programming;4dgpn2;1459867371.0;/r/programming/comments/4dgpn2/mariadb_corporation_today_announced_the_upcoming/;MariaDB Corporation today announced the upcoming release of its big data analytics engine, MariaDB ColumnStore, another significant milestone for the MariaDB open source community.;;"""MariaDB® Corporation, the recognized leader in open source databases""Ummm? I'm not sure this is 100% accurate.#CTRL+f infinidb. Yep, there it is."
GrassrootsSelect;4cl9ox;1459351896.0;/r/GrassrootsSelect/comments/4cl9ox/looking_for_information_about_how_voter_data_is/;Looking for information about how voter data is discovered and handled, and what it means to grassroots politicians;From what I understand political parties contract software vendors, and under this contract party runners are given access to the party database. Each individual campaign is responsible for populating their share of the system and hires their own data team.Its also my understanding that voter data is incredibly dynamic and can target a range of information such as what you buy, what you wear, who you've donated to, your health, ect. (I'd like to learn more about this). This data is somehow captured, and I suspect bought from a range of sources by... the vendor? The party? The campaign? Once this data is in the system, whose responsibility is it to keep safe? I don't think a specific campaign would be the entity to directly buy voter data, but they would be collecting data freely from calling and polling in a variety of ways where info is offered by supporters. This data is most likely structured, much easier to process.So what about the type of data that is unstructured? Audio, images, email, call center transcripts, social media, forums, blogs, GPS, mobile data, PDF files, etc.. are grassroots politicians given the same chance at buying, storing and analyzing this kind of data? The type of database for analyzing unstructured data is very different from structured data, is their access to the party database and the tools they use to analyze that data equal to one another, or does this depend entirely on the data science team of each campaign? My suspicion (ungrounded, I'm just trying to learn more with this) is that handling unstructured data is at a higher cost so whatever entity that is filling campaign databases with unstructured data (if that's the case) would be backing an establishment politician. I'm not sure if that entity would be the campaign, the party, or the vendor, or even a super PAC. I don't know if there are rules against a super PAC passing data on to campaigns for targeting voters.  If I got any of this wrong please correct me. I'm familiar with big data and data warehousing processes, right now I'm researching data lakes, but not at all with how political campaigns handle it let alone a grassroots candidate.;
cscareerquestions;4e1eq0;1460211581.0;/r/cscareerquestions/comments/4e1eq0/with_how_much_more_significant_machine_learning/;With how much more significant machine learning is becoming, is the security of developer jobs in the future at stake for those who have not been formally taught machine learning or the mathematics that go into it?;And not just machine learning, but the advent of a lot of other things such as big data and AI.  How are developers who are already working expecting to work with the oncoming changes?  Go back to school?  Climb up company ladders?Forgive me.  I know I've been asking a lot of questions on this subreddit, but I guess a lot of my question asking is drawn a lot from fear of not finding stability in the future with a career in development.  ;"> With how much more significant machine learning is becomingThere are actually very few machine learning jobs. Take a look at some job sites. I just did a quick search on LinkedIn and it shows 168 local jobs mentioning Java and just 6 mentioning Machine Learning. Most companies hiring developers aren't doing cutting edge software. The main source of jobs these days is web, mobile, and in-house (web) applications to run the business.> How are developers who are already working expecting to work with the oncoming changes? Go back to school? Climb up company ladders?Here are some ways: learn on your own (books, videos, tutorials, side projects, etc), get your company to send you to training, do a bootcamp that teaches the skills you're looking for, move up into management, find a job that is a blend of what you know and what you want to know, take night courses, etc. > stability in the futureThere is no such thing as stability in software development. If you're 20 now and expect to work to the usual retirement age of 65 (which will likely increase as people are living longer and longer these days), that's 45-ish working years. 45 years ago people were giving computers input on punch cards and there wasn't the Internet as we know it today. You'll have to learn new things throughout your career.#Oh absolutely. I feel sorry for all those developers who never learned mobile development or web development. They are completely unemployable. No other jobs except mobile and web.Every five years or so if you don't learn the new trend, that is the end. No more jobs. You're just unemployable. All those C++ guys? Nah, they haven't jobs in **decades**. VB? Don't make me laugh, unemployed since the early 2000's. Embedded development? That trend passed years ago.#I really think you're overestimating what machine learning can do. Machines can't program (once they can at the level we can we have bigger issues than 'having jobs'). ML has created some new jobs but if it's taking jobs away it's data entry jobs, not development jobs.#If an area is hot now, there is no guarantee it will still be hot 5+ years from now.  Then the market will be flooded with experienced people who have now-obsolete skills.If you pick the wrong thing, you can wind up unemployable in 5-10 years.  There are no guarantees.#Machine learning is not desirable in areas where you want specific hardcoded processes, which covers most of what we do.#Strong sense of sarcasm duly noted.  Point taken.#Oh you learned C? That was invented before Taylor Swift was even born. Obviously outdated. It's all about Swift now. That's why it's in the name!  *""Which name? Taylor's or the programming language?""*  Yes!  #Pshhh maintaining legacy systems? Who needs that shit just let it go, man. "
Cornell;4c82pf;1459126750.0;/r/Cornell/comments/4c82pf/big_data_data_science/;Big Data / Data Science;[deleted];In terms of majors, CS is a good option for setting yourself up to get into data science, mainly because of the emphasis on coding and algorithms (a lot of data science job postings look for CS or other related majors). I don't know a ton about Info Sci, but ORIE (my major) can be applicable to data science although there's more of an emphasis on statistics and optimization.I'm pretty sure I've seen some things for a Data Science Club. I wish I had heard about it before I graduated.#Info Sci is the first one that comes to mind for general application. Statistics is another one that comes to mind, though I'm not sure how much it would go into big data.I believe there is a Cornell Data Science club on campus. At least, there was when I was an undergrad.#Statistics, CS, and ORIE are all good options. Computer Science has vectors (think concentrations) and there is a Machine Learning track within AI if that's what you're more interested in. There's also a Databases route. I'm an active member of the Cornell Data Science  Club so can confirm it exists. We mainly engage in semester long machine learning based data analytics projects. Please check it out. Membership hasn't been so strong recentlyThere's a quantitative trading club too. Although I haven't really seen what they do. CDS has a very low barrier to entry unlike other Cornell clubs so no one will turn you away, although depending on your experience you may have to find a project with the best fit. Let me know if that helps if not I can speak more. 
buildapc;4c2q2x;1459023887.0;/r/buildapc/comments/4c2q2x/under_1600_usd_for_data_analysis_graphic_editing/;[Under $1600 USD] For data analysis, graphic editing and gaming PC;Hi, I am a independant researcher, working in the field of forest ecology. I work with big spatialised databases. I do database manipulations, work with ArcGIS and other specialized statistical, modeling and simulating softwares on a daily basis. On my free times I play some games, although I would not define myself as a heavy gamer. I am planning on building a pc on which I will work and play. What do you think of this build ?What will be the bottleneck ? Consequently, what should I upgrade or downgrade ?About the RAM speed, I have heard divergent opinion. Some people told me that it doesn't really matter and that I should not invest too much in that. Others have told me that for heavy spatial analysis, faster RAM is important. Any thoughts on that ?**Have you read the sidebar and [rules](http://www.reddit.com/r/buildapc/wiki/rules)? (Please do)**Yes**What is your intended use for this build? The more details the better.*** Data analysis: GIS (georeferencing, spatial analysis,3D analysis), database management, statistical and multivariate analysis, ecological modeling and simulation, big data* Graphic editing: With adobe Illustrator and Photoshop* Gaming: Light to moderate gaming**If gaming, what kind of performance are you looking for? (Screen resolution, FPS, game settings)**Resolution: 1080p is ok but more is always welcomeFPS: 60FPSSettings: Light to moderate settings is ok, but more is always welcome**What is your budget (ballpark is okay)?**Under $1600 USD**In what country are you purchasing your parts?**I live in Canada. I could buy either from Canada or US online stores**Post a draft of your potential build here (specific parts please) Type|Item|Price :----|:----|:----**CPU** | [Intel Core i7-6700K 4.0GHz Quad-Core Processor](http://ark.intel.com/products/88195/Intel-Core-i7-6700K-Processor-8M-Cache-up-to-4_20-GHz?q=6700k) | $363.94 @ Amazon**CPU Cooler** | [Thermaltake NIC C5 120mm](http://www.thermaltakeusa.com/Cooling/Air_Cooler_/NiC/C_00002029/NiC_C5/design.htm) | $47.51 @ Amazon **Motherboard** | [Asus Z170-K](https://www.asus.com/us/Motherboards/Z170-K/) | $132.99 @ SuperBiiz**Memory** | [G.Skill Ripjaws 32GB (4 x 8GB) DDR4-3000 Memory](http://www.gskill.com/en/finder?cat=31&series=2275) | $139.99 @ Newegg **Main storage** | [512GB Samsung 950 Pro M.2 PCIe 3.0 SSD](http://www.samsung.com/global/business/semiconductor/minisite/SSD/global/html/ssd950pro/overview.html) | $321.99 @ SuperBiiz **Data storage** | [Seagate 1TB 7200 RPM 64MB Cache SATA3 6GPS](http://www.seagate.com/ca/en/internal-hard-drives/desktop-hard-drives/desktop-hdd/) | $45.89 @ OutletPC **Video card** | [EVGA GeForce GTX 950 GDDR5 2GB](http://www.geforce.com/hardware/desktop-gpus/geforce-gtx-950/specifications) | $147.99 @ NCIX US**Case** | [Apevia X-Cruiser3](http://www.apevia.com/productsInfo.asp?KEY=X-Cruiser3-BL) | $61.98 @ Newegg**Power supply** | [600W Corsair CX](http://www.corsair.com/en-us/builder-series-cx600) | $35.99 @ Newegg**Operating system** | [Microsoft Windows 10 Pro 64 bit](http://www.corsair.com/en-us/builder-series-cx600) | $124.75 @ OutletPC**Total**| (Prices include shipping and discounts when available.) | USD $1423.02;"you can get an os for around 25 bucks on reddit lol. i cant remember the subreddit (/r/microsoftswapkeys/)?? dont need to spend 125 on a os. then with the spare money, get a r9 390x or an r9 380, if you go with an r9 series card, you might also want to upgrade the power supply. a gtx 950 wont do for graphics editing.#Can you give a link that goes directly to PCPartPicker?#http://pcpartpicker.com/p/6hjzbv#Any specific reason why you went with that case?#No one is asking what software you are using for your analytics. Depending on the software (R, Python, Julia?)  The gains from a good video card  is not trivial. Also more ram is good when you use R. How big is your big data?#No, any other case that do the job will work for me. It looked to me as a relatively good rated case, for a good price, with 5 fans included. The fan speed controller and the gauges, although gimmicky, looked as an interesting addition#The biggest shapefiles I work with are about 30GB. The biggest non-spatatialised databases are about 50GB. I am also beggining to work with LiDAR data (both aerial and terrestrial LiDAR)#If you have any questions please ask.[PCPartPicker part list](http://pcpartpicker.com/p/qDbJvK) / [Price breakdown by merchant](http://pcpartpicker.com/p/qDbJvK/by_merchant/)Type|Item|Price:----|:----|:----**CPU** | [Intel Core i7-5820K 3.3GHz 6-Core Processor](http://pcpartpicker.com/part/intel-cpu-bx80648i75820k) | $351.98 @ Newegg **CPU Cooler** | [Noctua NH-D15 82.5 CFM CPU Cooler](http://pcpartpicker.com/part/noctua-cpu-cooler-nhd15) | $88.50 @ Amazon **Motherboard** | [MSI X99A SLI PLUS ATX LGA2011-3 Motherboard](http://pcpartpicker.com/part/msi-motherboard-x99asliplus) | $222.98 @ Newegg **Memory** | [G.Skill Ripjaws V Series 32GB (4 x 8GB) DDR4-3000 Memory](http://pcpartpicker.com/part/gskill-memory-f43000c15q32gvrb) | $139.99 @ Newegg **Storage** | [Samsung 850 EVO-Series 500GB 2.5"" Solid State Drive](http://pcpartpicker.com/part/samsung-internal-hard-drive-mz75e500bam) | $149.99 @ Newegg **Storage** | [Seagate Barracuda 1TB 3.5"" 7200RPM Internal Hard Drive](http://pcpartpicker.com/part/seagate-internal-hard-drive-st1000dm003) | $45.89 @ OutletPC **Video Card** | [Sapphire Radeon R9 390 8GB Nitro Video Card](http://pcpartpicker.com/part/sapphire-video-card-100382ntoc2l) | $309.99 @ SuperBiiz **Case** | [Fractal Design Define R5 w/Window (Titanium) ATX Mid Tower Case](http://pcpartpicker.com/part/fractal-design-case-fdcadefr5tiw) | $89.99 @ SuperBiiz **Power Supply** | [EVGA SuperNOVA P2 750W 80+ Platinum Certified Fully-Modular ATX Power Supply](http://pcpartpicker.com/part/evga-power-supply-220p20750x1) | $99.99 @ NCIX US  | *Prices include shipping, taxes, rebates, and discounts* | | Total (before mail-in rebates) | $1521.30 | Mail-in rebates | -$30.00 | **Total** | **$1491.30** | Generated by [PCPartPicker](http://pcpartpicker.com) 2016-03-26 17:07 EDT-0400 |#Thank you !No Samsung 950 pro M.2 drive ? I thought that it could be a good improvement to increase the data reading and writing speed on my main drive#It's a big improvement as far as an SSD goes, but is not worth double the price [here's a review that covers 850 evo vs 950 m.2](https://www.youtube.com/watch?v=4aLW7Bk5Zgk)"
learnpython;4e757c;1460315933.0;/r/learnpython/comments/4e757c/best_way_to_cache_unique_items_while_iterating/;Best way to cache unique items while iterating through data?;"Say I'm going through json responses, extracting data I want. I want to add unique usernames to a list and skip duplicates.  I've done it by simply saying:      users = []    user_return_count =  # appropriate json response    for user in range(0, user_return_count):        if user not in users:            users.append(user)        else:            print('--Skipping duplicate user {:s}'.format(user))  This works, but will it scale very well? Basically I'm trying to figure out if having 5 different lists of 500+ items in memory at once is a bad thing. I'm not worried about my computer running out of memory, but it still feels dirty.  Is this the kind of thing that introduces a need for databases? Or will that be unnecessary until you're getting into ""big data"" like in the 10s of thousands?";"There is a type of collection that is called ""set"" If you add a duplicate to a set, it will be ignored because only unique items can exist in a set.Here is a simple example:        dudes = set()        dudes.add(""Highlander"")    dudes.add(""Highlander"")    dudes.add(""Highlander"")    dudes.add(""Highlander"")        print dudes#If you can keep your data in memory that's good. Avoid writing your data to disk unless you really have to.Usually you only need a database if you want to keep your data between different runs of your program.#awesome, I didn't even know that data type existed. Gonna save some code, thanks#[deleted]#As a heads up, sets only work with hashable data. So if you can't use it as a dictionary key, you can't store it in a set.#It's also possible to just write stuff to files to store results persistently. A database is not anyways necessary.#So just strings? Or are there other things that work?#Lots of things work:* strings* ints* floats* frozensets (yo dawg)* tuples made of hashable types* date, time, tzinfo, datetime, timedelta Generally, lists, sets and dicts can't be used. But most other things can."
Futurology;4ersii;1460649377.0;/r/Futurology/comments/4ersii/gpupowered_deep_learning_emerges_to_carry_big/;GPU-Powered Deep Learning Emerges to Carry Big Data Torch Forward;;
datascience;4dx8vk;1460133969.0;/r/datascience/comments/4dx8vk/my_journey_to_a_data_science_position/;My journey to a Data Science position;[deleted];It's amazing how varied the DS interview process is from company to company (and financial versus startup versus established). #howd you get the interview?  getting through the door is where i'm stuck.#Yeah they are more tech than traditional finance, and I left out a bit of the process and just included the DS bits. The true test seemed to be the work trial project and communicating effectively in the presentation. #amazing how the definitions of the roles vary too - some are very devops/engineering some are very marketing#Are you getting follow ups based on your resume? If not your resume (or experience) is the problem. If you have the experience for the position then you likely aren't presenting yourself well enough in the resume. If you are stalling out after a later step but before on-site it's likely something else. #It was via a recruiter within the company. I sent my LinkedIn and did a phone screening then started the traditional interview process. 
footballmanagergames;4dcg27;1459795148.0;/r/footballmanagergames/comments/4dcg27/data_extraction_capabilities_of_fm/;Data Extraction capabilities of FM;Hi everyone. I'm a weird fan of FM games. I'm completely addicted to FM, but I never play it because I stay so busy and don't have the time. I'm in graduate school, and I have a project on Big Data visualization (essentially, the manipulation, analysis, and visualization of very large data sets.) For my project, I wanted to pick a soccer-related dataset and work with it. Unfortunately, there aren't very many great options out there. So, my question is this: If I were to put FM on holiday for say, 50 years, would I then be able to extract the data from the game of the 50 years of soccer that was simmed? Everything from World Cup winners down to assist leaders in League 2? And if so, what format would the extracted data take? Excel files? CSV?Or, is this not possible at all?;"similar to this? https://www.reddit.com/r/footballmanagergames/comments/3fioa1/the_millenial_sim_is_here_1000_years_of_simming/#I'd do a bit of research into what file format the save files are, generally if you just do a Google search of ""XX file format"" it gives some indication as to a bit of background about the format and usually programs that are capable of opening the file (if any). I'm assuming Sports Interactive have applied some level of encryption to the data otherwise rival companies could steal the base data and pass it off as their own. One program that's been developed to read the live data in FM is Genie Scout, if you search for that the website which hosts it may be able to assist as it has quite an active following and they may even be able to put you in contact with the author (this may be a long shot). He may be able to give insight into if it's possible to extract the dataMy assumption is the data is stored in a large flat data table having used Genie Scout, it should be straight forward to manipulate once/ if you figure a way to extract itEdit: Spelling#I have a 20ish year save of FM currently. I could upload the save file and you could look yourself if you wanted.#I would recommend contacting the OP of the post /u/Earlofnorthumberland posted!"
OSU;4c297m;1459016890.0;/r/OSU/comments/4c297m/osu_datafest_2016_looking_for_a_partner_possibly/;OSU DataFest 2016? looking for a partner possibly;Is anyone doing OSU Datafest 2016? It's April 9-10https://data-analytics.osu.edu/datafestI signed up...and should have probably made this post earlier. Would anyone be maybe interested in partnering up? I don't have any team and it turns out you need team members of 2-5 members, otherwise they give you a random teammate. I don't really know too much in terms of statistics and data analysis exactly, but I am a CIS major so I have some programming skills, and I've been working on learning R and Python and plan on it over the next 1-2 weeks in prep for datafest if I still decide to go so I'm not lost and completely useless. I'm not too interested in a random teammate being assigned because I don't want to hold them back if they seriously know what they're doing, so I was wondering if there were any other noobs to data analytics who wanted to maybe try something out or use this as a learning experience maybe..or if you're advanced and don't mind a noob on your time? I'm pretty interested in big data and all so thought this would be pretty cool. ;I'm the exact opposite.Political science major and statistics minor and I know a decent amount about R and fairly good at visualization but know absolutely nothing about anything outside of R and statistical tests/theory.Going to be my first Hack-a-thon-like event so I'm totally down to have a not-overly-serious team if you want to team up! I could definitely teach you some R basics and introduce you to some of the more popular packages.
marketing;4clo15;1459357176.0;/r/marketing/comments/4clo15/analytics_the_new_marketing/;Analytics the new marketing?;is analytics future proof?  i am looking in getting ms in marketing, focus on marketing analytics.  i am currently in sales for att and would like to move into their marketing org.  i love tech, love numbers, love vr, etc.   i really want to do product marketing but i want to have some foothold as i strongly believe the future is about big data and numbers.  anyones two cents is appreciated.;"Data or ""Big data"" as some call it will always be important. But even more important is what you do with that data.SO many companies focus on ""getting data"" that they almost over-data themselves to death...causing a situation where they have so much they cannot even make any actionable decisions off of it.In my opinion, analytics will always be a factor. The bigger picture is really attributing acquisition. With all of the different outlets out there (websites, landing pages, social media, TV, print, etc.) it is important to be able to see what happened so that you can make strategic decisions and quantify ROI. The more granular you can get the better.What I would focus on is:-Learning and understanding analytics-Learn and understand platforms that businesses use-Learn and understand KPIs (Key Performance Indicators, which are a set of quantifiable measures that a company or industry uses to gauge or compare performance in terms of meeting their strategic and operational goals. KPIs vary between companies and industries, depending on their priorities or performance criteria.)Data is important, but understanding what to do with it is key.Let me know if you have any other questions. Hope this helps.-Rob#[Describing future patterns with today's big data.](http://flarrio.com/describing-future-patterns-with-todays-big-data/)#There will always be a demand for strong analytics capabilities, and judging by our client base its an increased focus among organizations. As someone who works in analytics at an ad agency I've found that the most important thing is being able to translate data into business objectives/insights.We've struggled to integrate individuals with a statistics background largely due to their inability to tie the numbers to the business itself and have had much more success with more traditional business professionals who've demonstrated an aptitude for analytics.  If you're looking to set yourself up for success I would look to pursue this line of education.  Be able to understand and work with data, but most importantly be able to tie it back to the organization and clearly communicate learnings from that data.#Hi rob,Sorry to hijack - do you know any good places to start learning about using data in an ecom site?#No worries! There are many resources - this is a pretty good starter guide:https://blog.kissmetrics.com/intro-to-ecommerce-analytics/#Thanks!"
datascience;4cvyph;1459521826.0;/r/datascience/comments/4cvyph/undergrad_classes/;Undergrad Classes;[deleted];I've been a data scientist for only two years, so my suggestions aren't hard and fast requirements and don't represent the views of all data scientists, but I think it's still valuable advice. First, I want to say that I think your classes look good. For stats, I think Advanced SAS programming is going to be superfluous (from my experience), though a lot of large companies and government agencies still use it instead of R. If I am interpreting the course correctly, AI is going to be heavy on machine learning content, so I think that will be helpful as well. Parallel computing is an important class to take - I do a lot of parallel calculations, and the reality is that for most problems, the computational answer is not to buy a bigger box  it is to rent more boxes. Knowing how to manage that is a valuable skill.The other thing I would like to stress is that while there are some classes that you need to take and that you definitely need a lot of math, I only have a BA in math and a BA in economics. While at college, I used most of my electives to get a minor in Russian, and I got my master's in nonprofit leadership. I did not take half the classes you are taking, including differential equations, or a single comp sci course, and my intro to programming was Stata. Your coursework seems important, but I got my first job by showing some visualizations I had done at a previous position and then I learned R on the job in my first month or two.Missing out on a single class can seem like a big deal, and if you have no math experience, yeah - it's going to be hard to be a data scientist. But your coursework decisions really aren't as life changing as it seems, and not learning something in college doesn't mean that you'll never learn it.#You've done a good job loading up on the technical skills you'll need to be a data scientist! However, I honestly think you need more than that to be a good data scientist.I came to data science from a Sociology/Poli Sci background (lots of stats, not much advanced math or CS), so I think I have a slightly different angle on this than other people, but the technical work is really only part of the job. It's also largely a matter of business acumen, presentation skills, and being able to understand and scope a project to solve a particular problem. The stats classes will get at some of that a little bit, but you should also consider at least a couple business classes, project management classes, or even domain classes in an area that you find interesting. Context is important!#At a glance, Computational Science (mainly parallel algorithms) does not seem necessary.  You are missing Machine Learning or Data Mining (Maybe as an independent study if your school doesn't offer a course?).  Focus on R and not SAS as most Data Science positions are rooted in open source.  This looks fairly well rounded, but as I am not a Data Science (I just dabble), I don't have any further advice.#[deleted]#Parallel computing is useful for Data Engineering, but not Data Science.  Data Engineering is more concerned with moving data around quickly and efficiently, whereas Data Science is more concerned with learning from the data and leveraging it for business decisions and processes.#I disagree. When your data doesn't fit in memory you must parallelize it somehow or you can't even train your models.
bigdata;4c7vuc;1459123563.0;/r/bigdata/comments/4c7vuc/junior_developer_looking_to_get_started/;Junior developer looking to get started.;Hi I'm a junior developer with nothing more than some classes in machine learning and data mining and have started to take the big data university classes online, I'm just wondering advice for getting started out learning about the field out of interest? Any information is appreciated, thanks so much! ;https://blog.treasuredata.com/blog/2016/03/15/self-study-list-for-data-engineers-and-aspiring-data-architects/#Awesome, I'll add this to my list 
environment;4cpq2z;1459426212.0;/r/environment/comments/4cpq2z/how_americas_big_data_centers_are_going_green/;How America’s big data centers are going green. Tech companies could substantially bolster the clean energy market.;;
datascience;4e0dwr;1460185295.0;/r/datascience/comments/4e0dwr/easier_to_work_remotely_as_engineer_than_data/;Easier to work remotely as engineer than data scientist?;[deleted];[deleted]#I will be messaging you on [**2016-04-13 01:37:06 UTC**](http://www.wolframalpha.com/input/?i=2016-04-13 01:37:06 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/datascience/comments/4e0dwr/easier_to_work_remotely_as_engineer_than_data/d1wt384)[**CLICK THIS LINK**](http://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=[https://www.reddit.com/r/datascience/comments/4e0dwr/easier_to_work_remotely_as_engineer_than_data/d1wt384]%0A%0ARemindMe!  in 3 days) to send a PM to also be reminded and to reduce spam.^(Parent commenter can ) [^(delete this message to hide from others.)](http://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete Comment&message=Delete! d1wt3rv)_____|[^([FAQs])](http://www.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^([Custom])](http://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^([Your Reminders])](http://www.reddit.com/message/compose/?to=RemindMeBot&subject=List Of Reminders&message=MyReminders!)|[^([Feedback])](http://www.reddit.com/message/compose/?to=RemindMeBotWrangler&subject=Feedback)|[^([Code])](https://github.com/SIlver--/remindmebot-reddit)|-|-|-|-|-|
austinjobs;4drfbm;1460041317.0;/r/austinjobs/comments/4drfbm/hiring_data_scientist/;[HIRING] Data Scientist;"    Data Scientist (SQL / Hadoop)    Northwest Austin Texas    PERM - Direct Hire    Salary is OPEN + equity!      We are working directly and exclusively with the President of this Big Data / Hadoop ecosystem / Data Analytics / ETL software company in its early stages of enterprise database management.  They are simply trying to build a better analytics product! Their platform is cloud hosted, so we will be looking for AWS and/or Azure experience. This is an opportunity for a Data Scientist to be part of something totally different. This ETL Software company is headed to paving the way of doing all things ""data"" their way, and even hold several patents for the data based technology used. If you love data and math this job is for you! In additional to a competitive salary there is equity play and a sound group of investors funding them.    Hiring Manager indicated they were looking for ""A Data Scientist who knows modern data management solutions from the outside-in. Number of years of experience is flexible, but the candidate should have a very high level of proficiency in the skills listed below""    What we are looking for in this Data Scientist:	*Data structures and algorithms experience 	*SQL (for analytics)	*Statistics, machine learning, graph analysis	*Experience using technologies within the Hadoop ecosystem	    PLUSES that would put this Data Scientist on top of the list:	*Spark experience	*Scala or other JVM languages 	*Deploying in AWS, Azure, or other cloud infrastructure	*Streaming analytics and event processing 	*Experience with basic data analysis tools, such as RStudio or Pandas is a plus     Education:	*BS in Computer Science, Mathematics, or related field	*MS or PhD in Computer Science or Mathematics is highly desired.    **Have questions? Contact me directly Suzie Jimenez 512.872.2199 or send me your LINKEDIN profile suzie.jimenez@thehtgroup.com**Algorithms, sql, analytics, statistics, machine learning, hadoop, spark, scala, jvm, aws, azure, cloud, analytics";
bigdata;4daa91;1459760365.0;/r/bigdata/comments/4daa91/processing_big_data_using_15kb/;Processing Big Data using 1.5Kb;;
cscareerquestions;4dwswu;1460128121.0;/r/cscareerquestions/comments/4dwswu/accepted_a_software_engineering_internship_but/;Accepted a software engineering internship, but might have an offer for a full time Data Analyst position. What should I do?;So last week I verbally accepted an offer for a software engineering internship (10 weeks full time, paid, 22/hr).  While waiting for the written offer to arrive, I interviewed at another place for a Data Analyst position and was called back for a second interview next week.  It's full time, and I'm thinking it will pay somewhere in the range of 45-50k + full benefits and 5 weeks paid time off (pretty decent for my area, I'm not in some crazy expensive region like the Bay area or NYC).   I'm thinking that I could be getting an offer from this company, the first interview went well.  I still have one semester of school left after this (graduating in December), and I think the company offering the full time position is willing to work with me for that, as my classes would be mostly at night anyway.I'm conflicted as to what I should do:  on one hand, I have a solid internship lined up for the summer, that pays way better than the job I have currently, and is more in line with what I want to do (I went back to school specifically for programming/software engineering), and I'd have to renege on the offer, but at the same time, a real full time job is hard to turn up.  And, I'm not against a big data type job, I just didn't necessarily see myself in those shoes when I went back to school.  It could be lower stress/pressure than doing a programming type job, which might fit my personality better.  I'm just a little conflicted and was wondering if anyone could provide some insight.;go with which ever job better fits your long term career goals and which job will help you get that next job better.#Just as an aside, if you look at the math, your internship will pay about as much as the full-time (they're close enough that over 10 weeks, the difference is pretty negligible).  And generally speaking companies that transition their interns into full-time also give them a compensation boost.  Just something to consider.#I'd keep the internship and finish out your degree.  Tell the analyst company that you're interested in the position, but you're not able to start until after you graduate.  If they really want you, they'll hold the position.  If not, there will be other offers.
SFBayJobs;4dha6a;1459874785.0;/r/SFBayJobs/comments/4dha6a/hiring_housecanary_is_hiring_for_7_jobs_senior/;[Hiring] HouseCanary is hiring for 7 jobs: Senior Software Engineer, Software Engineer, Web Developer, Project Manager, Automation Engineer, Director of DevOps and Senior QA Engineer. All in San Francisco!;Please [send me a message](https://www.reddit.com/message/compose/?to=jungrothmorton) or leave a comment with any questions you have! Click on any job title get the application page for that job. All jobs are not remote, and require being in the appropriate office during normal hours.At HouseCanary, we're using big data and analytics to predict the future of the real estate market in the US. Our goal is to use this data to help people make better real estate decisions. HouseCanary platforms forecast real estate values at a local level, and every month, we forecast 36 months into the future, and our models predict more than 95% of the variation in price over time.# [Data Engineering | Senior Software Engineer](http://www.housecanary.com/careers/?gh_jid=66545&gh_src=82ai1f)San FranciscoWe're seeking a passionate Senior Software Engineer to help build out the dataaggregation and ingestion platform powering the most accurate real estateanalytics tools in the world.**What you'll do:**  * Ingest large amounts of data from numerous sources  * Develop complex queries to solve data mining problems  * Write reliable and efficient programs scaling to massive datasets and large clusters of machines  * Collaborate with talented data scientists to implement predictive models  * Create optimized ETL jobs to power industry-leading front-end applications**What you have:**  * 5+ years software engineering experience  * Expert level Python ability (or willingness to get there)  * Advanced level SQL knowledge  * Excellent communication skills  * Collaborative and proactive personality  * Ability to work through ambiguity and deal with shifting priorities# [Data Engineering | Software Engineer](http://www.housecanary.com/careers/?gh_jid=66933&gh_src=82ai1f)San FranciscoWe're seeking a passionate Software Engineer to help build out the dataaggregation and ingestion platform powering the most accurate real estateanalytics tools in the world.**What you'll do:**  * Ingest large amounts of data from numerous sources  * Develop complex queries to solve data mining problems  * Write reliable and efficient programs scaling to massive datasets and large clusters of machines  * Collaborate with talented data scientists to implement predictive models  * Create optimized ETL jobs to power industry-leading front-end applications**What you have:**  * 2+ years software engineering experience  * Advanced level Python ability  * Strong SQL knowledge  * Excellent communication skills  * Collaborative and proactive personality  * Ability to work through ambiguity and deal with shifting priorities# [HouseCanary Appraiser | Senior Software Engineer](http://www.housecanary.com/careers/?gh_jid=65914&gh_src=82ai1f)San FranciscoWe're seeking a passionate Senior Software Engineer to help build out ourappraiser integrations team.**What you'll do:**  * Manage and build client API integration  * Work with application and big data services to implement business requirements  * Build RESTful APIs to power our HTML5 and iOS applications  * Design and implement scalable features to support growth**What you have:**  * 5+ Years Software Engineering experience  * Advanced level Python preferred  * Advanced level SQL knowledge  * Excellent communication skills  * Collaborative and proactive personality  * Ability to work through ambiguity and deal with shifting priorities**Bonus points for knowledge of:**  * Django and Django REST framework  * Real estate markets  * Complex client integrations # [Web Developer](http://www.housecanary.com/careers/?gh_jid=184660&gh_src=82ai1f)San FranciscoWe're seeking a passionate Web Developer to join our team to help build andmaintain our corporate site, develop internal tools and assist with marketingcontent.**What you'll do:**  * Own HouseCanary.com and associated microsites  * Use bleeding-edge HTML5 features  * Work with design and marketing to build new pages  * Develop world-class email campaigns  * Build internal performance dashboards   * Push the boundaries of modern web technologies**What you have:**  * Mastery of HTML5 and CSS3  * Javascript skills  * Collaborative and proactive personality  * Experience building HTML emails  * Ability to work through ambiguity and deal with shifting priorities**Bonus points for knowledge of:**  * d3 or SVG  * Databases  * Python  * Experience with AngularJS (or any frontend MVC)# [Project Manager](http://www.housecanary.com/careers/?gh_jid=162192&gh_src=82ai1f)San FranciscoWe're seeking a passionate Project Manager to help manage customer projectsuccess and product lifecycle for our world-class products.**What you'll do:**  * Manage timelines, resource planning, quality and delivery for customer engagements  * Lead software projects across HouseCanary to successful completion  * Collaborate with all groups within HC (Appraiser, Pro, data engineering, product, etc.)  * Generate and maintain project documentation  * Organize and direct planning and implementation of all project activities**What you have:**  * A customer-oriented approach  * Experience managing multiple customer projects simultaneously  * Extensive exposure to guiding enterprise projects into production  * An agile and continuous delivery mindset  * Expert-level knowledge of SDLC  * Ability to work cross-functionally   * High level of attention to detail  * Bachelor's degree# [Automation Engineer](http://www.housecanary.com/careers/?gh_jid=63567&gh_src=82ai1f)San FranciscoWe're seeking a passionate Automation Engineer to join our team to helpenhance our test automation environment.**What you'll do:**  * Scale our automated testing framework for end-to-end, integration, API and mobile  * Help instill a testing culture  * Partner with the engineering team to integrate test suites into the continuous integration system  * Improve code coverage metrics**What you have:**  * Experience with modern testing methodologies (BDD, TDD)  * SaaS application testing expertise  * Strong development skills in Python or JavaScript  * Substantial exposure to Selenium  * Agile mindset**Bonus points for knowledge of:**  * AngularJS/Protractor  * Appium  * BrowserStack  * Calabash  * Jenkins or TeamCity  * Databases# [Director of DevOps](http://www.housecanary.com/careers/?gh_jid=140131&gh_src=82ai1f)San FranciscoWe're seeking a passionate Director of DevOps to help manage the softwarerelease process for our world-class products, implement monitoring solutions,and manage our AWS infrastructure.**What you'll do:**  * Own build and release management practices  * Drive infrastructure strategy and operations  * Lead operations service delivery and support  * Implement systems monitoring solutions  * Ensure application and infrastructure security  * Work with an awesome technology team building unmatched products**What you have:**  * Team leadership experience  * An agile and continuous delivery mindset  * Strong Linux skills (RedHat or Ubuntu)  * Deep understanding of AWS  * Experience with infrastructure automation (Salt, Chef, Puppet or Ansible)  * Versed in continuous integration tools (TeamCity, Jenkins, etc.)  * Substantial knowledge of SCM (SVN, Git, Perforce, Mercurial, etc.)  * Experience with application server frameworks, and web servers (Rails, Django, Nginx, Apache HTTP, Flask, etc)  * Monitoring tools expertise (pingdom, nagios, icinga, sensu)  * Relational database mastery (MySQL, PostgreSQL)**Extra credit for:**  * Performance management   * Capacity planning  * Internal office infrastructure experience  * Fantastic sense of humor# [Senior QA Engineer](http://www.housecanary.com/careers/?gh_jid=94664&gh_src=82ai1f)San FranciscoWe're seeking a passionate Senior QA Engineer to help ensure the highest-quality software releases in the industry.**What you'll do:**  * Become an authority on our products  * Perform integration testing with partners  * Test incoming data from partners to ensure accuracy and completeness  * Assist with automated regression testing  * Manage story acceptance testing  * Manually test all components of our apps**What you have:**  * An agile and continuous delivery mindset  * Experience testing web and mobile apps  * Knowledge of relevant tools (Cucumber, Jasmine, etc.)  * Pragmatic attitude and eye for quality  * Experience building test plans  * Excellent soft skills**Extra credit for:**  * Programming experience (Python/JavaScript)  * Previous use of Selenium  * Some understanding of SQL   * Fantastic sense of humor;
datascience;4ehyda;1460492018.0;/r/datascience/comments/4ehyda/question_about_data_frames/;question about data frames;I script all the time in R and Python and was wondering how data frames compare to other data types memory and processing wise. Is the resources need for them higher? Are they slower to iterate through? And would you use them for very big data sets. The biggest data frame I probably ever used was 100mb. When you get to gbs or tbs are they still viable? ;Data frames in R are essentially lists of vectors.  The vectors (one for each column) can all be different types.  R will iterate (including using the apply commands) much more quickly through matrices than through data frames.  A matrix contains data all of the same type, and so the processing overhead is lower.I regularly use R with multi GB data frames (50 GB +), and it works fine.  Although I would recommend you use the data.table package instead, as it's much more efficient in aggregating larger data sets.I may be wrong, but I'd be surprised if vanilla R would cope with a TB data frame.  Even if you have the memory on your server, I would expect the performance to be poor.  R is still not good at utilising more than one core of a processor.  Certain packages use Java or multi-threaded BLAS libraries to use multiple cores, and Microsoft R uses a multi threaded BLAS library for matrix operations (although I tried it, and I'm not sold on the performance).  But in the main, operations are single threaded - not ideal for processing significant quantities of data.I love R.  But it's important to use the right tools for the right job.  If you're processing multi TB datasets, you should probably use something else.#How does a R dataframe compare to a python data frame?#Python can easily handle 10s of GBs.  Although my experience of Python is much less than that of R, so I'm afraid I couldn't advise you on the differences.#Pythons dataframes come via the pandas library and are more akin (in terms of memory and performance) to what you get from data.table in R, with pretty efficient groupby and aggregation methods. I've comfortably used very large dataframes with pandas. If you want to push things the Dask library provides blocked dataframes that mirror the pandas API (and can be passed to many functions that take pandas dataframes) that can do parallel and out of core computation. Using that I've worked with a 60GB dataframe easily enough on a laptop  given a decent multicore server you could easily scale to the TB range. Beyond that you'd start to want Spark or something similar.
homelab;4cnab4;1459378640.0;/r/homelab/comments/4cnab4/can_i_make_a_ghetto_database_server_from_a/;Can I make a ghetto database server from a raspberry pi?;[deleted];"If she has a computer of her own, any computer, she can install it there? I've run MySQL on my Windows desktop just to do some playing around at work before. Don't need something seperate tbh.#I agree with @Matt on this one, a type 2 hypervisor is the way to go here (VirtualBox/Client Hyper-V/VMW Workstation...).Speaking as someone who runs about a dozen Pis between work & home, I imagine any dbms is going to run really poorly on a Pi when you start throwing in the kind of data required for big data analysis.#Why not run it on her laptop? SQLExpress, MySQL, Oracle.#[deleted]#If you want to teach her these things, get her started with VirtualBox or VMWare Fusion.  That'll give her networking, ""remote"" DBs, server type stuff, and she can run whichever databases she wants without the added hardware complexity of a way underpowered external device.Think about the times you've been learning things.  Do you find you learn better when your feedback loop is nearly instantaneous?"
technews;4eb2x8;1460387163.0;/r/technews/comments/4eb2x8/how_big_data_harms_poor_communities/;How Big Data Harms Poor Communities;;
forhire;4e5l4o;1460290412.0;/r/forhire/comments/4e5l4o/for_hire_developer_web_desktop_mobile_and_data/;[FOR HIRE] Developer (web, desktop, mobile) and Data Analyst;[removed];Sorry /u/la_formula_ninguna, your submission has been automatically removed./r/ForHire doesn't allow accounts  that are either newer than 10 days (regardless of karma) or are old but have less than 50 karma, or both new and karma-less, to post [For Hire] posts. Earning karma means getting upvotes on posted links (not text posts) and comments. Please do not contact mods for an exception. *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/forhire) if you have any questions or concerns.*
forhire;4drfon;1460041442.0;/r/forhire/comments/4drfon/for_hire_senior_network_engineer_security/;[For Hire] Senior Network Engineer, Security Engineer/Analyst;CCNP, CCSA, GSECI'm located in North East Ohio, with 18+ years experience in Networking and Security. I'd like to find something remote if possible, since I have 10+ years experience working from home. If not, a 35 minute commute would be tolerable. I'm currently working for a big data firm.Skills: Checkpoint/Cisco firewall administration, IDS/IPS deployment and tuning, Vulnerability assessments/management, SIEM architecture, deployment and analysis, network performance planning, Hadoop data center engineering, Continuous monitoring, Vulnerability remediation, and others.Experience includes: Cisco, Arista, Checkpoint, Tenable Log Correlation Engine/Passive Vulnerability Scanner/Nessus/Security Center CV, Bro IDS, Suricata IDS, Squid, Splunk, Jira/Confluence, Start up firms, Exposure to Agile/Scrum, and others.PM me for a resume.;
tipofmytongue;4dlj7r;1459946099.0;/r/tipofmytongue/comments/4dlj7r/tomtvideo_future_documentary_about_big_data_and/;[TOMT][video] Future documentary about big data and how it could affect our daily lives.;"It's been some years when I saw this documentation but I can't remember which year I saw it nor when it was created.I remember a scene about someone ordering a pizza via phone and they have his whole medical history and say something along the lines of ""your health insurance record shows that your cholesterol level is to high. Are you sure you want extra cheese? That would increase your health insurance fee"" and it goes on and on about how we get enslaved by big data.As far as I can remember the whole thing was animated, no human actors. I remember it to be very blue-ish and ""tron like"". By that I mean futuristic and everything drawn/animated with simple lines.Unfortunately I can't remember any more details :( Does someone have an idea?Thanks in advance!";The Human Face of Big Data?http://www.imdb.com/title/tt3312100/#Wow, I remembered that bit! I don't know who originally created it, but it was [reposted to YouTube here.](https://www.youtube.com/watch?v=RNJl9EEcsoE) Maybe someone else can find the original content creator?#Shikra found the one I was looking for but thanks anyways. This one looks quite interesting as well, gotta watch it soon :)#That's it! Don't know why I remembered it to be a whole movie but that's exactly what I meant :)Thanks mate!
learnpython;4dzz4t;1460175502.0;/r/learnpython/comments/4dzz4t/having_trouble_importing_csv_files_using_pandas/;Having trouble importing CSV files using Pandas;[deleted];"What exactly isn't working? What is the value of `the_csv_file`? Also is your csv formatted properly?#I'm not sure if it is formatted properly. It mean, it opens in excel just fine. the_csv_file is a variable I tried to store it under. As for the CSV file, its stored in that file directory....but I added the \Rodent_Inspection.csv extension because it doesn't show it on the path.#I want to clarify - I think I am not saving the CSV files in the right directory or something. Where should I save my csv data, or future data I want to work with? How can I get pd.read_csv() to read something that is not in the same folder?#Reading in a file not in the same folder is fine - if you want to simplify things you can put your csv file in the same folder though. If you do keep the file in a external folder to the one your script is in make sure you double check your paths. I'm still not sure how you know this isn't working? Are you getting an error?  #>  File ""C:/Users/Kwei/PycharmProjects/untitled3/testest.py"", line 9    the_csv_file = pd.read_csv('E:\Storage 1\NYC Open Data\Rodent_Inspection.csv')                              ^SyntaxError: (unicode error) 'unicodeescape' codec can't decode bytes in position 12-13: malformed \N character escape>Process finished with exit code 1I just got it to work! It wanted me to have two forward slashes for some reason when referring to the directory. Strange. I found the answer after trying some more replies in stackoverflow. I wonder why that is... I guess from here on, I have to figure out how to get the data to look like what I want. Thanks!#Well the \\ is reserved for character escaping (like \\n or \\t), so you have to use either double slashes (\\\\) or forward slash (/) in any path you use in Python"
MachineLearning;4efx2h;1460465199.0;/r/MachineLearning/comments/4efx2h/question_where_can_one_take_their_ml_skills/;[Question] Where can one take their ML skills besides a F500/tech company?;I am an entrepreneur in the Middle East and am intrigued by big data, ML and similar areas. I am considering learning ML skills but am having trouble understanding what benefit I can bring to organizations or markets that do not already have large tech/software companies in place. ;"You could take your skills to non F500 companies #I've heard that abortion clinics like to use ML to predict what the children will grow up to be like so that they can better savor and brag about their ""kills"".  #Astronomy, robotics, medicine and earth sciences all have problems that could benefit from ML. The issue is you need to have an understanding of those problems they are trying to solve. If you are thinking about learning ML, what is your current skill set in?#That sounds like a product you could easily market to anti-abortion groups as well. Win-win!#???#I have broad skills in digital advertising, social media, marketing. My first inclination would be to offer something to the local/regional advertising firms. However, I see a number of software suites popping up that already do that. #For me the difficult part is not picking up the ML skills, it is picking up enough domain knowledge in a given field that you can usefully apply ML skills. If you have insights into digital advertising, maybe look into what those software suites are lacking. What do you bring to the table that others aren't, and then how can you automate that?"
LAjobs;4cs2d0;1459458272.0;/r/LAjobs/comments/4cs2d0/hiring_xpost_from_rgamedevclassifieds_lead_devops/;[Hiring] (x-post from /r/gameDevClassifieds) Lead DevOps - Playa Vista, Los Angeles, CA - Golden Rat Studios - Mobile casino for China/SEA.;[Golden	Rat	Studios](http://www.goldenratstudios.com/)	is	now	hiring	for	its	new	social	gaming	studio	in	Los	Angeles,	California.	Founded	by	industry	veterans,	and	backed	by	a	publicly	traded	company,	we’re	looking	for	experienced,	collaborative	individuals	who	want	to	build	the	next	generation	of	multiplayer social	casino	games	with	a	focus	on	China.**LEAD DEV-OPS**We are looking for a talented DevOps engineer who has a deep understanding of, and solid experience in, building, deploying and running large scale, polyglot, distributed systems with nearly 100% uptime.**Responsibilities*** Define, build and maintain our software deployment pipeline. Use industry best practices to automate our build, deployment and integration test processes.* Own, run and automate our cloud (AWS) infrastructure operations. Implement security best practices.* Play an important role in defining software and systems architecture of our back-end and big data infrastructure.* Plan and implement disaster recovery processes* Implement an effective monitoring infrastructure that observes every important aspect of our systems, helping us stay at 100% uptime.* Support and optimize our application run-time environment.* Be the first line of defense with respect to any environmental issues, and work with developers, as needed, to diagnose and resolve them.* Track infrastructure-centric expenditures and keep our infrastructure cost effective, minimizing wasted resources.* Perform infrastructure capacity planning and ensure system environments are adequately scalable for anticipated growth and availability.**Requirements*** In-depth understanding of Unix operating systems fundamentals, JVM performance (Garbage collection)* Solid knowledge of database performance, sql query optimization Experience with at least one Application Performance Monitoring tool (Newrelic or AppDynamics, etc.)* Strong experience and acumen for automation using scripting languages like Python or Ruby. MUST have at least an intermediate level of scripting experience.* Hands on and solid experience working with Jenkins or other CI tool* Strong experience with AWS cloud infrastructure and services – EC2, S3, SQS, Route53 etc* Experience with at least one relational database and one no-sql datastore* Deep understanding of industry best practices of application and database scalability* Phenomenal team player**Preferred*** Experience with Big Data DevOps* Experience with technologies – Zookeeper, Cassandra, Kafka, Docker**Benefits*** Work with a great team in an organization that is at the early stage of achieving something “big”* A fun place to work ☺* Catered meals* Vacation/personal time off* Flexible work hours* 401K* Health, vision & dental insurance coverage for employees and dependentsAs if you had to ask… Yes, Golden Rat is indeed an equal opportunity employer.Applicants should provide a resume and LinkedIn profile URL to: careers@goldenratstudios.com. Please mention finding this listing here on Reddit.*Edits: Cleanliness*;
PanamaPapers;4dsmlq;1460056353.0;/r/PanamaPapers/comments/4dsmlq/using_big_data_techniques_on_the_panama_papers/;Using Big Data techniques on the Panama Papers Data set to find interesting knowledge?;Just wondering if this is being done or if it is possible. I was just thinking that 2.6tb of data is a lot of data. Mind boggling amounts and that this could be a way to search through it quicker? Has anyone thought about using Big Data or machine learning techniques on the Panama Papers data set? I don't know that much about Big Data techniques but this seem like a perfect place to apply it? Thoughts, comments? ;Xargs + ghostscript + grep would be fine even for 2.6TB of PDF'sThe problem is the documents are not public. #There are probably some software that have been ran on the data set by the journalist. However, we won't have access to the data themselves for a while so no it isn't being done by regular people.From my understanding the leak contains lot of image of paper, like pdf. The final data should be much small, but this is only a guess.#I think i read somewhere that they have used optical character recognition to turn the images or paper into words and hence into searchable form. I just think that maybe the wider computer science and Big data community might have something to offer here. #We all think that, just waiting for the data to go public.
bigdata;4ef9zc;1460451641.0;/r/bigdata/comments/4ef9zc/mastery_of_big_data_cuts_a_competitive_edge_on/;Mastery of big data cuts a competitive edge, on the field as well as in the marketplace.;;
UIUC;4e94td;1460346902.0;/r/UIUC/comments/4e94td/anyone_take_or_hear_of_ece498_networking_for_big/;Anyone take or hear of ECE498: Networking for Big Data?;Sounds interesting but can't find any more information on it.;Email the instructor... #Pramod Viswanath said he may be teaching it next semester and the only pre-req is ECE 313 or the stat equivalent. You could try shooting him an email to ask for more info#I'm taking it right now with Prof. Srikant. Fairly interesting class on a pretty relevant field of ECE/CS. For MPs, you'll get to use Python, MATLAB, and Apache Spark. The math and probability theory in the course can be challenging, but quizzes are graded leniently. Overall, I'd recommend it.#That would be awesome. He's a bro. #Do you think taking it would help with job applications? #Agreed. He's been my favorite professor I've had here, really wish he taught more classes especially outside of probability/statistics#Probably! Python, MATLAB and Apache Spark are very useful for getting jobs, and a lot of companies are looking for people who know about data centers.
SelfDrivingCars;4cvlaq;1459516942.0;/r/SelfDrivingCars/comments/4cvlaq/amazon_microsoft_look_for_big_data_role_in/;Amazon, Microsoft look for big data role in self-driving cars;;> **Renault** and automotive supplier **Continental** have both expressed interest.> Continental said on Thursday a decision on whether to buy a stake in HERE would be made within the next few months.> **Ford** is also among the companies interested in taking a stake in the HERE consortium, a third auto industry source said on Thursday.So Amazon, Renault, Continental and Ford all potentially buying into HERE. 
Sino;4cfhcg;1459259179.0;/r/Sino/comments/4cfhcg/chinese_aircraft_manufacturer_uses_big_data_to/;Chinese aircraft manufacturer uses big data to build safer planes;;"Chinese aircraft manufacturer uses big data to build safer planesUpdated: 2016-03-26 15:58(Xinhua)> ...LOS ANGELES -- With a global focus on how to reduce safety risks caused by anomalous human behavior and how to fully recover data crucial for analyzing an air crash, a Chinese aircraft manufacturer is using big data and cloud technology to build safer airplanes...> ...To minimize such risks caused by human factors, COMAC America Corporation is studying the concept of ""unmanned flight with human supervision"" using a big data-based computer, which operates in an entirely closed environment without influence from outside...> ...In a computer-piloted plane, a hard-drive with big data, which include flight routes, weather information, emergency processing programs, and flight data of 200 pilots accumulated in 20 years, might become the ""pilot"" in the future  human pilots will only need to insert the hard-drive into the cockpit and monitor the flight in a separate compartment...> ...This concept could become a future trend in civil aviation and might be tested on unmanned cargo flights first, according to the company...> http://usa.chinadaily.com.cn/china/2016-03/26/content_24113345.htm"
webdev;4dpzul;1460013344.0;/r/webdev/comments/4dpzul/whats_the_best_place_for_learning_how_to_design/;Whats the best place for learning how to design good UI/UX for big data websites?;Im working on a site that will display financial information about companies to potential investors. Right now the website looks like one big excel spreadsheet with complicated filters. I wanted to know what are some good resources out there for designing user friendly websites like this. Is there any way around this?;https://www.sencha.com/products/extjs/#overviewNot free, but widely used - also comes with a drag and drop builder, which is built on their software.#Elementary School.No really. If an 10 year old can read the result ... you've won.#The user interface for Imply.io's Pivot may provide you with some inspiration: https://github.com/implydata/pivot#Too expensive.#Correct, this would be an end goal, and OP seems to be aware of this. He is asking for the resources to help his design get there.#That looks very good.#Kids are great resources :)
psychology;4cce5p;1459202139.0;/r/psychology/comments/4cce5p/can_big_data_help_psychiatry_unravel_the/;Can Big Data Help Psychiatry Unravel the Complexity of Mental Illness?;;
learnprogramming;4bzhkv;1458957645.0;/r/learnprogramming/comments/4bzhkv/pythonmodifying_global_variables_within_a_function/;[python]Modifying global variables within a function;    x = 3    def inc():        global x        x = x + 1    print inc()I want to modify the variable x within a function. I know i can do this using the above code but I've read this is bad practice so I can only think of another way to solve this problem:    x = 3    def inc(num):        return num + 1    x = inc(x)    print(x)Is this the right way?A thing that bothers me about the ladder solution is that if x was some kind of big variable, wouldn't I be creating a redundant copy of x inside the inc function which might mean a lot of time if x was some kind of big data?;Passing to a parameter to a function doesn't copy it. It just binds another name to the same value. You can see this if you use something mutable like a list:    >>> def append2(lst) :    ...    lst.append(2)    ...    >>> x = []    >>> append2(x)    >>> x    [2]    >>> append2(x)    >>> x    [2, 2]#So the difference with my example is that I'm using integers and integers are not mutable?#The difference in your example is that you're using an assignment. An assignment makes the name on the left hand side refer to a different thing (and just that name- not any other names that might refer to the same object). It doesn't change the object that the name used to be referring to. So this    def replaceVal(lst):        lst = [2]won't change anything.  #And would this change the value of the list outside the function?    def apppend2(lst):        lst[0] += 1Would that increment the value of lst[0] outside the function too?#Yes, because you're re-binding a value inside lst rather than re-binding the name lst. The object-that-used-to-be-lst[0] doesn't get changed, but the object that is lst does.#Ok i really think i get it now, thanks!
MachineLearning;4eojzv;1460593315.0;/r/MachineLearning/comments/4eojzv/interesting_job_requirement_must_have_experience/;Interesting job requirement - must have experience in time travel;"""10+ years of hands on experience with machine learning applied to big data""";Machine learning and big data have been around for decades. Maybe the problem is that you had a weak laptop or computer all this time? #Wow they are stupid. Everyone knows that Machine Learning was invented in 2009.#There are guys in russia who have 50+ years of experience with deep learning.#For some people big data means over 200000 data points. ML has existed for decades. However, odds are the hiring manager is just an idiot. There's a lot of idiots out there...#You'd better hire someone with 2-3 years of experience, but who knows everything there is to know about ML and BD. Honestly that is more realistic than it sounds.  #These kind of requirements are common in early days  of  most technology but it depends how you stretch.   I was playing with neutal networks in the late 80's and working on research in feedback networks using Stella, Lindo,  Fortran and c.... The time in between where I  did nothing but design enterprise business applications is a bit of a problem...  But nothing that couldn't be overcome with a PhD in applied math or statistics with an emphasis on data  )... It's always entertaining when the kids think they have invented something new.   The passion is entertaining.#Everything was invented first by some forgotten Russian guy.
MachineLearning;4d543t;1459662326.0;/r/MachineLearning/comments/4d543t/engineer_with_solid_math_background_and_a_ms_what/;Engineer with solid math background and a MS, what are my chances of getting a ML/Big data job?;I have a BS and MS from top engineering schools, and developed a strong math background on topics that seem to be precursors to machine learning (linear algebra, non-linear optimization, stats, multivariable calc, numerical computation ) and even took an intro to neural nets while in grad school. I was wondering what are my chances of breaking into ML given my background. If it's possible, what's the best way to learn ML for someone with an already decent math background for it?Then, what should a side-project include which would require me to learn everything that a professional ML person would know. ;"ML jobs are a bit chicken and egg: If you really are any good, you don't need to work for someone else haha.Seriously, speaking as a ""ML Professional"", an employer will look at your coding skills and in particular your ability to program fluently in R, Matlab/Octave etc and pertinent maths and visualisation libraries. Evidence of competency in these langauges should also highlight your ability to handle and manipulate data. Cleaning and pre-processing data is just as important as the throwing maths at it. Unix experience is generally preferred imho. Be careful when throwing around terms like ""strong math background"", Maths is a lifetime of total dedication. Same goes for terms like ""neural networks"", ""deep learning"" and ""genetic algorithms"" if you're going to throw these around make sure you know more fundamental stuff like ARMA, GLIMS, Gaussian Process, MCMC, simulated annealing and so on. Otherwise you look like you're trying to run before you can walk.Big data, NLP and deep learning are reasonably popular right now... In fact everything is hot right now. There's money flying at every angle you can think of.#I'd say, very very high. Specially if you can program well.#Don't know if this would help? DataScienceCentral has an apprenticeship program that might be up your alley. Check 9 types data scientist in their book...and there s programs for machine learning...#Can you PM me your resume?#> If you really are any good, you don't need to work for someone else haha.Could elaborate a bit more on this point? Are you saying there are lots of freelancing opportunities?#> your ability to program fluently in R, Matlab/Octave Lol. You mean python, lua, and C++? What you said is appropriate for data science, not machine learning. #dude, do you really want to go there?"
technology;4dz2zn;1460159492.0;/r/technology/comments/4dz2zn/how_big_data_harms_poor_communities/;How Big Data Harms Poor Communities;;
BigDataJobs;4ejzij;1460521547.0;/r/BigDataJobs/comments/4ejzij/3_big_data_areas_for_nonprofits/;3 Big Data Areas For Non-Profits;WHEN YOU SAY Big Data, do you think of charities, donations, and non-profits? Why not? We non-profits have to go through quite a few hoops to get our donations. And to get them, we need to spend our donors’ money in a way the each individual donor feels the most comfortable with. And with a large number of donors we really need to be on our game. And Big Data can help.Here are the three main areas where Big Data best helps us non-profits.http://bizcatalyst360.com/3-big-data-areas-for-non-profits;"Every once in a while, an article comes along that's so bad, it inspires me to log in and down-vote. This is a great example. #djcj88, every once in a while, a comment comes along with the intent to sound clever. This is a great example. Now for the bad. Your comment is an uneventful comment because it's generic and cookie cut. Further, it does not even say why the article is bad. Now for the good. Your comment does help one be productive. We can take your comment and copy and paste it to any article we don't like. And it's awesome to be this productive and efficient. Final analysis, in the name of high efficiency your comment is a stellar comment. I highly recommend your comment to be used by those who wish to be productive by not providing valuable feedback and by not engaging in any constructive debate.#The first third of the page is a horrible piece of clip-art which is blown up ten times and pixelated until it is as unintelligible as the ""content"".The ""article"" is three random reflexive statements that have nothing to do with any application, or even offer any subtle hint of value or insight. The last third of the page is a bio of the author which just lists a bunch of industry-sounding words and doesn't even try to make sentences. Clicking to the author's website brings you to a full page youtube video of a flowchart apparently drawn in paint, boasting nearly a hundred views and no doctype. I can't find anything worth complimenting, except the title.#djcj88... First thank you for the feedback. The image on the top of the page may be a conversion issue from the website ""distributor"". I will need to talk to them to see why the the image is pixalated. Thanks for mentioning this.The article lists out three business outcomes for Big Data for non-profits. Since you called them reflective and did not recognize them as outcomes you most likely are not the article's intended audience. Perhaps this reddit is not a suitable channel either. I will re-review all the channels we use for appropriateness.I'm reaching here, but though the author and you  both do Big Data I don't think you both are in the same line of work. This is based on your description of business outcomes and how you described the bio as industry sounding words. Not sure about your no sentences part. Though this bio has been vetted by at least six people, because of your concerns we will ask someone once again a ""second opinion"" on that bio. I see you provided feedback on the corporate website as well. Our leadership always appreciates any feedback on our content. I will bring up your concerns.Thanks for your feedback. In final analysis, I feel you were not the intended audience for the article and that this reddit may not be a suitable channel for such content. I also see you and the author not being in the same line of work. Thanks for the feedback.On a final note your arguments and how they we're phrased demonstrated a strong confirmation bias. This can make you lose all your credibility as a professional and give others very negative impressions of you. When presenting your feedback I will remove all these negatives so your feedback is heard.Thanks again for your help. Enjoy."
shreveport;4ehere;1460485258.0;/r/shreveport/comments/4ehere/bigdata_analysis_enthusiasts/;Big-data analysis enthusiasts;Hi, are there any big data analysis enthusiasts/hobbyists or groups around Shreveport? If not, let me know if you are interested in forming one. ;
MSOE;4cds56;1459222843.0;/r/MSOE/comments/4cds56/milwaukee_big_data_users_group_meetup_april_5/;Milwaukee Big Data Users Group Meetup April 5;;
simonfraser;4dq1vx;1460014777.0;/r/simonfraser/comments/4dq1vx/sfu_graduate_housing_and_meal_plans/;SFU Graduate Housing and Meal Plans;I recently got an admit to SFU's Professional Masters in Big Data program, Fall 16. The program seems fairly new, but presented good enough facts for me to consider. Considering the place is in one of the most expensive parts of canada, I need some advice regarding living arrangements.* I am an international student from India, what do you guys recommend, off campus or on campus housing?* I found Hamilton Hall prefers Grad students and the rent seems less or equal to what seems to be available off-campus.* The meal plan option looks lucrative too, I saw a couple of youtube tours and it looked very nice. But I am on strict low carb diet, I am doubtful the dining hall would be able to cater to my diet plan, but I may be wrong. Also the grad rooms have their kitchens so no big deal i guess.* The on-campus aquatics center and gym seems like a great opportunity, I am an avid swimmer and would like to make use of this. So I guess living on campus would give me freedom to enjoy these activities?* Travelling would be out of the equation if I opt in for on campus option, I can keep a bike for moving on campus, I guess.This seems to check out all the requirements I guess, but can anyone help me figure out the catch and what I might be missing compared to daily commuters. I have been a daily commuter during my undergrads and was just wondering that this might be betterPS: is the campus smoker friendly?;"First, you should join the New Grad Students Facebook Group because there's lots of information there:https://www.facebook.com/groups/sfugradstudents/**On Campus vs Off Campus**Off campus you'll be able to find a one bedroom basement suites and maybe save ~$200 per month vs Hamilton Hall, or split a basement suite / apartment with multiple people and save even more per month. I know people paying as little as $450 per month for reasonable housing. The downside is the commute, which can be especially problematic if you need to make 8:30am or 9:30am classes each day. There's not enough buses so you'll often have to wait for several buses if you're trying to make those class times.On campus you're paying a bit more, will meet more people, but also have to deal with more noise. The graduate residence faces the massive 1st year dorm towers which will often be noisy. I live on campus, but in the residential development on the east side of campus. Prices there are more expensive than off campus and residence, but it's far more studious than residence.**Getting Around**To get around campus most people just walk (it's about 15 minute walk from Hamilton Hall to the Applied Sciences building). If you live in the residential area on campus it can be as little as a 2 minute walk to Applied Science.**Smoking**Vancouver in general is not smoker friendly. Smoking rates are the lowest in Canada (~10-15%) and there's large exclusion zones around campus buildings where you're not allowed to smoke due to Health and Safety laws. So you can smoke on campus, and there's special metal umbrella things so you can smoke in the rain, but I wouldn't say it's a smoker friendly campus. #The Dining Hall can cater to almost anything. You can always get things without the rice, pasta, potatoes etc. If they dont have anything you like, there's a student kitchen area in the dining hall where they provide all the ingredients and you can cook your own meal the way you like! #Thank You! Tell me more about residences in the east, how can I apply for them?Also, some more info on the dining hall might be helpful.I am also assuming carrying in smokes from duty free shops from my country to canada will not be a noble idea. #The residences on the east side are privately owned, so you'll find them listed on Craigslist. Use the search term ""univercity"" on vancouver.craigslist.ca. Examples:Studio: http://vancouver.craigslist.ca/bnc/apa/5528901611.html2 bedroom: http://vancouver.craigslist.ca/bnc/apa/5527936390.htmlThose prices are pretty typical. I don't know a whole lot about the dining hall, other than it's all you can eat and often pretty carby stuff (pizzas, burgers, stir fries with rice / noodles etc). The weekly menu is posted here: http://dineoncampus.ca/sfuAs far as I know you're allowed to bring in a limited number of cigarettes and many people do purchase cigarettes out of country. You won't be the only one if you do decide to bring some. Here's where you can start to look to find more info:http://www.cbsa-asfc.gc.ca/travel-voyage/ifcrc-rpcrc-eng.html#a5#This is interesting, thanks! Will checkout the housing options there as they seem to make more sense."
BleachBraveSouls;4do4ad;1459981097.0;/r/BleachBraveSouls/comments/4do4ad/question_how_big_the_the_initial_data_download/;Question how big the the initial data download;Hey,I've been wanting to try this game out but I'm on a limited data plan,I have 400mb available to download with,how much will be used if I download the big data download when you first start?;150%+ of your available data. Find wifi.#I recommend using wifi to download it then. The total game size after it's completely downloaded is about 1.2GB.#Also, I recommend only playing on wifi if that is your data allowance. Playing co-op uses a lot of data and anytime there's a character you haven't used or brought with you as a friend or fought against, it has to download the character file. So it's definitely a game you will want to play over wifi.#When i jump in the tutorial, after the big download my ios version says that the actual game from the app store is 122mb while the document and data (the big download) is 918mb . Like everyone said, get yourself some free time and a wi-fi :) Good luck!#Thanks for the reply guys can't reply to comment for some reason my phone reddit doesnt have a reply option.
berkeley;4epqa2;1460611215.0;/r/berkeley/comments/4epqa2/eecs_major_interested_in_big_data_and_machine/;EECS major interested in big data and machine learning. Should I take Stats 134, Stats 135, and/or EE 127;[deleted];"I've taken them all minus 127, and 134/135 was interesting in a math way but might not apply to Big Data.127 might be useful for ML algorithms to solve objective functions.  There isn't really a distributed data class here, some semesters they offer a 194 called Data Science. 186 touches on some Big Data. There might be some new courses out of the info school, or you could take some upper division stats classes. 289A/B also are there but you have to test in.  Andrew Ng at Stanford is doing cool stuff and webcasts his class, so you could watch.  I think asking your adviser this week, or emailing another ML prof might be your best bet. Mess around with some TensorFlow maybe? The distributed ML field is pretty young, so you could get your hands messy! I think the bottom line is that this isn't a mature area like OS so no clear path, you'll have to experiment and do some emailing to figure it out. Hope that helps! #All three courses you mentioned are useful, so it's a question of what you're interested in. Optimization (127) is probably the most directly connected to ""big data"" hype, and is also a cool and useful topic on its own merits. On the other hand, formal probability theory (134) is a solid foundation that will serve you well for an entire career of working with data, and, like most mathy topics, it's much easier to learn in an organized course than to try to pick it up by self-study later on, which might make it a better use of your limited course slots.You should also consider CS281a, which is (IMHO) the natural direct successor to 189, in that it helps you understand some of the unifying principles (ideas in probabilistic modeling and inference) behind many of the methods discussed in 189, and how to apply those to thinking about new problems. #Everything I've heard about 194 (data science) is that it's really bad.EE 127 is kind of painful and boring. Not sure if it's worth taking (maybe auditing?)"
singularity;4dhfw4;1459876744.0;/r/singularity/comments/4dhfw4/singularity_universitys_exponential_manufacturing/;Singularity University’s Exponential Manufacturing conference is coming up this May in Boston!;Hi everyone, I've been a long time lurker and I've really enjoyed this subreddit so I wanted to share with you a Singularity University event, Exponential Manufacturing 2016. I work at Singularity (not on this specific conference) and I want to extend a 15% discounted invitation to Exponential Manufacturing, pm me for the details. The event is a bit pricey but I can assure you that the speaker lineup is awesome. The conference is taking place this May 10-11 in Boston, MA. The conference will touch on topics such as: Internet of Things, Big Data, Advanced Manufacturing, Predictive Analytics, Sharing Economy, Digital Manufacturing and more.Please check out the event here: https://exponential.singularityu.org/manufacturing/;
bigdata;4dvnec;1460107461.0;/r/bigdata/comments/4dvnec/when_big_data_doesnt_equal_big_knowledge/;When big data doesn’t equal big knowledge;;
bigdata;4cfcdt;1459257011.0;/r/bigdata/comments/4cfcdt/mastercard_partners_with_ibm_to_deliver_big_data/;Mastercard Partners with IBM to Deliver Big Data Analytics to Merchants;;
bigdata;4cb1ek;1459184597.0;/r/bigdata/comments/4cb1ek/variety_not_volume_is_driving_big_data_initiatives/;Variety, Not Volume, Is Driving Big Data Initiatives;;
SBU;4esfj0;1460657059.0;/r/SBU/comments/4esfj0/technology_systems_management/;Technology systems management;Anyone here in the TSM program either BS/MS? I'm going to apply for the MS program, would this degree help me get a job in QA Testing or something along those lines? I have a BS in Economics but I want to move into IT. I have learned basic codes, but I don't see myself as a programmer. I want to go more towards Testing or something along the lines of  big data analysis, would this degree help me to progress in my career?;You don't need a tech related degree to get into QA if that's what you want. There's a bunch of QA analyst roles out there you can apply for with any degree. Some companies may vary and require you have a CS degree but you can always get a entry level qa analyst role and work your way up to test engineer or something.Testing and big data analysis are two different things. If you want to go into data science, then you should get something in applied math, math, stats, or computer science.#Talk to Rita Reagan-Redko or Ted Teng in the TSM dept. I can't exactly answer your question but I know you can be broadly qualified for IT positions especially if you pick a specialization that can gear you more towards your intended path.
udub;4eddw0;1460416983.0;/r/udub/comments/4eddw0/infohcde_chances/;INFO/HCDE Chances?;Hey, so i'm pretty set on becoming a data scientist mainly cause the world of big data intrigues me. I know that Info and HCDE a lot about the essay but I've heard that from people who graduated 2-3 years ago. So I'd like to get an update and see what my chances are and how I can write a strong essay that properly conveys my interest. my cum GPA is a 3.26I'm hoping that after spring quarter my GPA will be a 3.30 cause i think i can 4.0 all my classes.CSE 142: 2.9 (withdrew spring cause mom had menopause and had to commute constantly and wanted to do Chem at that time, not an excuse but i couldn't handle the workload)INFO 200: 3.8currently taking Q SCI 381 but thinking 3.6+I'm very worried cause i'm a sophomore and i don't want to enter my junior year without a major. Also, as stated above i would love if someone who's in these majors could help me through the drafts of my essay. Thanks again!;How much do you know about HCDE? Do you have  DRG experience with HCDE and have you taken HCDE 210? Do you know any person (TAs, professors, advisor, lecturers) in HCDE? As far as I know, the last fall admission rate was 23% and this spring was 31% and admission rate tends to go lower for the fall because more people will apply. #Graduated from info last year. I would review your papers for you and chat with you through the process. I am not sure if I have mine around still to compare to. If you want my feedback, PM me#Can attest to Thothsscribe being super helpful - he actually answered a lot of my questions when I was applying for INFO last year, haha.Also! Just to let you know, there's five upcoming INFO application writing workshops this quarter. The first one is this Friday, and although each meeting is limited to 10-15 minutes, you might glean some tips about what the department wants and get some general feedback about your writing from some other INFO majors. :)#I took HCDE 210 last quarter. But in terms of experience, I don't have any. This is why I'm scared. I only have the desire to go into the field of UX or UI for HCDE and big data for Info. #That's exactly what thothsscribe would say if this were his alternate account and he was trying to set up a meeting with OP to murder them!He may also just be a helpful guy though. I give it 50/50.#Are all the info advisers good? I met with Dowell and he was extremely helpful and honest
privacy;4di2m9;1459884746.0;/r/privacy/comments/4di2m9/what_would_your_ideal_privacy_policy_include/;What would your ideal privacy policy include?;I'm drafting a privacy policy for a client that is doing big data/machine learning in Canada (we have jurisdictional privacy laws), and I'm [documenting the process](https://privasectech.com/2016/04/a-pretty-good-privacy-policy/) over the next few weeks to hopefully help others. How can I make the best privacy policy ever, for you?;Include fine grained control. I should be able to delete any arbitrary records about me easily if I choose. I should have absolute control over data about myself.#The [OECD guidelines](http://www.oecd.org/sti/ieconomy/2013-oecd-privacy-guidelines.pdf) are a great place to start.  Any good privacy policy should fulfill all of these requirements.
cscareerquestions;4cx9ug;1459536108.0;/r/cscareerquestions/comments/4cx9ug/leaving_my_job_in_sales_at_it_consulting_firm/;Leaving my job in sales at IT consulting firm;Hi all,Looking for some advice regarding next steps in my career.  I graduated college with a super non-relevant liberal arts degree but have always had an interest in technology.  I ended up taking a position in sales at a MSP/Consulting firm.  I have been pretty successful in my role and my greatest strength is discussing/explaining advanced IT solutions to CEO's/COO's, basically the business side.  I am sick of sales and want to pursue opportunities on the IT side of things.  My major catalyst in needing to act fast is my team is being replaced by a bunch of kids making half the money I am so my quota's get raised every month and they will fire me the first time I miss it.  I have applied for programming boot camps but I don't love the idea of either doing it with a full-time job as I already have other commitments.  Based on my skills and what I am seeing in the market, my thought is to go after SQL/Big Data related jobs.  While my actual professional experience is lacking I am a tinkerer.  I have built a few solid websites in WordPress.  I use a linux OS for most of my computing and have learned a lot troubleshooting personal issues I have run into.  Any insight or advice would be greatly appreciated.  I kind of just rambled there so if there are any questions that I could answer please let me know.  Should I just read and do training available on Lynda to try to get in the door at these jobs?  Is a formal BootCamp the way to go?  Another angle I am missing?Thanks for taking the time to read.;Knowing what the clients are looking for you can work as a product owner or project manager pretty easily as long as you have the technical acumen as to what you were selling. In many cases, you will have to be knowledgeable about the market while your technical lead will own the feature execution. #That is along the lines of what I am seeing right now as an option that doesnt involve too much training.  Right now I sell to to all markets but I could certainly point my resume towards something more specific.  That said, I tailor each pitch to services I know are priorities for the relevent industry.I have an interview for a company that has an ERP system designed for construction companies.  It is a big hard to tell whether the job is more account managment or project managment though.  Any advice for questions to ask during the interview to help distinguish between the two?Thanks for taking the time to reply.#well project management is like account management though your stakeholders many times are internal versus external though they can be both. Questions I would ask: 1 On the job spec does it say to oversee developers and lead them or to work with client to develop requirements? 2. Does the job spec list tools like Jira and MS project or Salesforce and Zen desk instead?  Does it require a PMP /Scrum Master cert ? 3. Look at some of the people at the company now in the same role and check out their backgrounds. If they are product managers/project managers you are fine. If they have held AE/Account Mgmt roles it's probably  a telltale. BUT, from your original post,  you also need to get out of your current gig so figuring you shift companies you will likely have 6 months to camp out/train for your preferred role before you are on the hook. Again you can very easily move to an PM role from sales once you have learned the software very well and how your clients use it to help manage and run features. #Very helpful.  I will spend some time this weekend digging deeper into this.  Thankfully my city has a great job market so candidates with strong people skills and solid experience do well.  Do you mind if I PM you next week with one or two follow up questions?#Feel free to PM me. I have just about every PM cert you can get and happy to help. 
finance;4eyy4l;1460756095.0;/r/finance/comments/4eyy4l/masters_of_science_in_finance_or_applied/;Masters of Science in Finance or Applied Statistics?;[deleted];"[deleted]#Research in the sense that I work for a relatively large company that produces food products. Think of General Mills and all of the companies they own and the products they produce and develop on a yearly basis. Thanks for the solid advice. From another users comment, I am going to run with the more ""technical degree"" and work towards a MS in Applied Statistics. "
sysadmin;4dgppk;1459867404.0;/r/sysadmin/comments/4dgppk/mariadb_corporation_today_announced_the_upcoming/;MariaDB Corporation today announced the upcoming release of its big data analytics engine, MariaDB ColumnStore, another significant milestone for the MariaDB open source community.;;So wait, Monty writes mysql then sells it for a fortune to Oracle. Then he takes his code, names it something else, and starts a company around it? And its backwards compatible with mysql. Uh, what did Oracle buy exactly? Just the name? Monty can keep doing this over and over considering this stuff is all open source.#well oracle bought sun which was the one that bought mysql, I guess sun bought it because mysql was used by 99% of web apps at the time so they could make money via mysql enterprise subscriptions#Exactly that. MySQL has been pretty much replaced by MariaDB in nearly all Linux distros.
urbanplanning;4crtx1;1459455090.0;/r/urbanplanning/comments/4crtx1/watch_elegant_models_of_big_data_is_optimizing/;WATCH: Elegant Models of Big Data is Optimizing City Transit;;
golang;4d15ge;1459596135.0;/r/golang/comments/4d15ge/how_to_move_from_hugo_to_pure_go/;How to move from Hugo to pure go?;"I've been using Hugo to build a site that I'm working on, but am having to bend over backwards to make things work in Hugo. Unfortunately there is very little documentation for adding any complexity beyond a simple blog page (for example multiple nested menus)-- it seems like basic blogs were the only use case envisioned by the developers. I've seen several comments on here recommend starting from the html/template library, and that sounds great except I don't know a whole lot of go beyond ""Hello, World"" and that almost feels like it'd be taking ten steps back at this point. To get to the point-- Working with Hugo has made me really like the idea of building a static site. I work with a guy that has a TON of experience working with big data, and we ended up developing a database to organize and then generate all the different markdown files for the site. If we do decide to move away from Hugo, how would we go about making that database usable? (To be clear, we don't want to actually put the db on a server, we just want to use it as a way to organize all the content before compiling a static site.) Sorry to have rambled on, but if anyone has any advice for me I would really appreciate it. ";"What kind of website do you want to create? Can you give the link to the current site? Any other site that has a similar structure? What does the DB contain?It's hard to recommend anything useful without knowing anything about the project. Here's the basic principle https://play.golang.org/p/gFDz-bDtSy#Are you just looking for a way to serve static files (specifically Markdown)?#Have you tried asking on the Hugo repository/chat? Re-writing this all to achieve a nested menu seems a little crazy  Hugo can definitely achieve that. #It's a website for our buddy's real estate company. [Here](http://www.tamborrel.com/) is a similar example. The db contains each line of markdown that is necessary for Hugo to build it correctly. So for the example site that I linked there would be a folder for the menu item ""buying"" that contained a markdown file for each of the links in the drop down menu. And each home under /buying/featured-listings would have its own markdown file. So the content folder of the site would look something like this:.       |-content      |-Property Search      |-Explore      |-Buying       |-search-for-homes.md       |-featured-listings.md         |-house1.md         |-house2.md      |-Selling      |-... THANK YOU for your help btw#Why even use a database? Just put them in files and run a hugo server. Plus you can create your own layouts if you know html. This isn't even a hugo problem. More of a problem of not understanding how templates work."
Green;4cpf4f;1459419588.0;/r/Green/comments/4cpf4f/how_americas_big_data_centers_are_going_green/;How America’s big data centers are going green;;
dataisbeautiful;4cv0ic;1459507118.0;/r/dataisbeautiful/comments/4cv0ic/interview_with_hadley_wickham_rstudio_on/;interview with hadley wickham (rstudio) on visualization and general deep philosophical implications of big data;;> 1)A post must be a data visualizationPost removed. Maybe /r/statistics or an R related subreddit is a better fit for this post.
Futurology;4ckgsl;1459339686.0;/r/Futurology/comments/4ckgsl/big_data_theres_more_to_meet_the_eyes/;Big Data: there's more to meet the eyes;;Hey everyone,Just wanted to share with you the latest piece in my Exponential Revolution blog series. This installment takes a closer look at Big Data with realistic and relatable examples, and it builds up the theoretical side to keep moving the overarching story along.As always, your feedback and thoughts are more than welcome!Best regards,Pieter
datascience;4ckgn3;1459339605.0;/r/datascience/comments/4ckgn3/any_good_resources_on_issues_associated_with_data/;Any good resources on issues associated with data visualization (especially from a business perspective)?;[deleted];http://www.amazon.com/Visualize-This-FlowingData-Visualization-Statistics/dp/0470944889Took a data viz class last year. This was the textbook. Nathan yau's website flowing data is a good resource as well. Also check out d3.js for an advanced/flexible technology for visualizing data.#http://www.storytellingwithdata.com/gallery/Very accessible and informative. I think she uses Excel for the plots but it's more about the underlying ideas.
SuggestALaptop;4cp7xa;1459414753.0;/r/SuggestALaptop/comments/4cp7xa/7501100_usa_laptop_for_browsingprogramming_and/;750-1100$ USA laptop for browsing,programming and Movies;*    **Total budget and country of purchase:** 750-1100$, USA*    **Do you prefer a 2 in 1 form factor, good battery life or best specifications to your requirements for the money? Pick or include any that apply.** I need*    **How important is weight to you?** Not at all.*    **Which OS do you require? Windows, Linux, Mac.** Doesn't matter.*    **Do you have a preferred screen size? If indifferent, put N/A.** 13 inches or 15 inches*    **Are you doing any CAD/video editing/photo editing/gaming? List which programs/games you desire to run. If you have no requirements, put N/A.** Will be using  chrome with lots of tabs open, Watching Movies, do some Python,C++,Java programming. No big data stuff. Listening to Music.*    **If you're gaming (leave blank if you put N/A above...), do you have certain games you want to play? At what settings and FPS do you want?** Occasional gamer Counter Strike, Age of Empires 2 (provided it has windows OS), otherwise cs on wine in Linux would be enough.*    **Any specific requirements such as good keyboard, reliable business grade build quality, touch-screen, finger-print reader, optical drive or good input devices (keyboard/touchpad)?** SSD/flash drive is a must,preferably 256GB, will be using an external das keyboard so bad laptop keyboard doesn't matter. Touchscreen monitor is not preferred.*    **Leave any finishing thoughts here that you may feel are necessary and beneficial to the discussion.** Basically I'm just looking for a computer with a good processor(thinking of latest gen i5) , SSD and good ram(8gb if in budget) and no dedicated graphic card.     Mac book Air 13 inches fits most of my criteria. Since i am comfortable with both windows and Linux OS, am looking for a similar laptop with a better hardware in the same budget(256Gb SSD over mac's 128 Gb SSD).     Also how different would the screen resolution/look of the normal laptops be compared to Mac's Retina Display (it is making me favor slightly towards Mac although Apple is costly).;"> Also how different would the screen resolution/look of the normal laptops be compared to Mac's Retina Display (it is making me favor slightly towards Mac although Apple is costly).The MacBook Air has not a Retina display. It comes with a 1440x900p TN panel (which is mediocre regarding viewing angles, colour reproduction and so on). There are $500 Windows laptops out there with a better display. You can only find the Retina display on the new 12 inch MacBook and on the MacBook Pro 13 and 15 (just be aware that Apple still offers a MacBook Pro 13 model from 2012 on their website with a 1280x800p display, which certainly doesn't qualify as ""Retina"").Personally I would suggest a Lenovo ThinkPad T460s or T560. You can get them with a decent discount through the [corporate perks offer program](http://shop.lenovo.com/perksoffer/us/en/laptops/thinkpad/t-series/) (passcode is FLEN*2V). I would just take the base model (of each) and configure it with the 1920x1080p IPS display and the backlit keyboard. RAM and SSD upgrade would be cheaper if you do it yourself.#Oh, yeah i forgot that Macbook air doesn't come with a retina display.Although Macbook Pro is pricey.Is Retina display worth the extra money ?I mean how is it compared to QHD+ offered by Dell Xps or the Lenovo's FHD with IPS.Also any specific reason to choose Thinkpad over Dell Xps Ultrabooks ?#> Is Retina display worth the extra money ?If you compare it to the display of the MacBook Air, then yes. Also you can save a bit if you go for a refurbished unit. A Retina MacBook Pro 13 with an Intel i5, 8 GB of RAM and a 256 GB SSD costs $1279.> I mean how is it compared to QHD+ offered by Dell Xps or the Lenovo's FHD with IPS.A display panel can be either a TN panel (which you want to avoid) or an IPS panel (like on the Retina MacBooks, Dell XPS line and so on). If you don't know the difference:This [is a TN panel](http://www.notebookcheck.net/fileadmin/Notebooks/Lenovo/Z51_70/Lenovo_Z51_70_Blickwinkel.jpg).And this is [an IPS panel](http://www.notebookcheck.net/fileadmin/_processed_/csm_Blickwinkel_5e3e57d992.jpg).As for the resolution (FHD = 1920x1080p, QHD+ = 3200x1800p) it depends on you. How good is your eyesight? And how far are you sitting away from the display. There are also some scaling issues. Most people which buy a Dell XPS 13 with the QHD+ display don't run it on this resolution. They scale it back to 1080p or even 900p. Otherwise text and icons could be too small.> Also any specific reason to choose Thinkpad over Dell Xps Ultrabooks ?You can upgrade these easier, but I don't know if you need or want that."
milwaukee;4cj5mu;1459309873.0;/r/milwaukee/comments/4cj5mu/milwaukee_big_data_users_group_meetup_april_5/;Milwaukee Big Data Users Group Meetup April 5;;
bigdata;4expu8;1460740357.0;/r/bigdata/comments/4expu8/what_would_you_do/;What would you do?;<disclaimer>Let me start by saying that everything that follows is hypothetical. A scenario introduced only to gather a small sample of input to use for a later big data experiment. So please, refrain from the conspiracy theory rant's</disclaimer>In this scenario a person who massively mines big data in both white and black hat fashion discovers a file in a far away place on a VOIP voicemail server cached in a junk folder. This file contains a voicemail from A.B. Krongard intended for a recipient that goes by the name Suku Radia. After decryption and playing this voicemail file it becomes clear that this file is a smoking gun of inside knowledge of the events on 9/11 nearly a week before it took place.Given the scenario above, if you have the time, please answer the questions below.1: Seeing as this piece of information was obtained illegally, how would you go about disclosing that you possessed it without jeopardizing your safety and freedom?2: Being a big data insider, how would you go about sharing this file with the goal of ensuring that it does not get lost in a mess of big data generated by botnets to contradict its existence and authenticity?3: If you had found this hypothetical file yourself, would you feel obligated to share it or disclose its existence, or would you feel the need to keep quite for your own security. If you find the time to answer the above questions i want to thank you for helping contribute to the gathering of a small sample set of data to compare to a big data collection.Edit: There are no right or wrong answers here, this is a small data gathering post to compare to a big data set to see if results are similar. ;ill take a shot -1. Maybe use NYT Lockbox which allows you to submit stuff like this anonymously. Otherwise, use public key encryption - it would allow me to prove ownership whenever I wanted by exhibiting the private key. Maybe never if its too risky, but the option is there.  wait actually - post a link on reddit to the original voicemail on the server if possible, otherwise upload a copy somewhere else and post that. That way, i just need to be anonymous for the short time it takes to post that link - after that its on the internet and theres no getting rid of it :)2. If it really was authentic, i assume some kind of voice analysis would prove that. I'm not sure what you mean by data generated by a botnet to contradict it.. there is no contradicting a conversation that happened. I guess it can be discredited as a fake but theres not much i can do about that. hopefully further follow up and investigations would bring out the truth eventually.3. I think i would share it.. Id also try to simply post a link to the original voicemail on the server anonymously - #Thank you for taking the time to reply :)
bigdata;4eqcy2;1460625854.0;/r/bigdata/comments/4eqcy2/article_politics_in_the_age_of_big_data/;Article: Politics in the Age of Big Data;As the race to become the next President of the United States rumbles on, more and more attention is being placed on how Data Science and Analytics are playing an active role in the campaigns of the respective frontrunners. From social media scraping to audience analytics, and an Artificial Intelligence Twitter account that tweets like Donald Trump, political elections and the data that surrounds them are now inextricably linked. The question remains however: could the use of Data Science and Analytics be the key to gaining a majority, and the keys to the Oval Office, in this day and age? Here are several ways in which Data Science and Analytics have been used in the past to sway the undecided voters, and how politicians in the future might use the technology to their advantage.It was during the 2012 re-election campaign for President Barack Obama that Data Science was first utilised during a large-scale political campaign. Using a platform called Narwhal, which was built in-house, Obama’s team were able to monitor every aspect of his campaign, and more importantly, what was being said online about what Obama said in front of the cameras. In near real-time, the team could see whether a message or action from one of the President’s speeches had been received either well or badly, such as ‘Obamacare’, and advise the President on whether to emphasise a popular subject, or steer clear of a less favourable topic in his next address. Furthermore, Narwhal made it possible to create a map of the US based purely on social media activity around the election, meaning the team could anticipate the strength of support in a particular state by studying mined data, and then targeting undecided voters with pre-scripted phone calls and flyers persuading them to vote for Obama. It is reported that in the year prior to the Election Day, there were 100 Data Analysts running upwards of 66,000 data simulations every day to try and push the Obama campaign forward. Retargeter reported that during the October of the presidential campaign, Obama’s team spent nearly double the amount ($52 million) on online advertisements than rival Mitt Romney. In total, over $1.5 billion was invested in the victorious Obama campaign. If Obama’s victory showed anything, it was that this money did not go to waste. Whether Obama’s widespread appeal and charisma would have won him the 2012 election alone is something we will never know, but the impact of studying the raw data from social media and other sources is something that is now being taken into the 2016 presidential election.So looking forward, how might Data Science and Analytics, and their wider fields, be used to map the political spectrum, and influence voters in the decision-making process? One aspect could be the integration of Artificial Intelligence into speech-writing for political leaders. Could an AI platform analyse hundreds of petabytes of raw data from social media, news websites and blogs, interpret what the majority of a given number of people are looking for from their politicians, and then create a speech from scratch? Will traditional speechwriters become obsolete, or will the Artificial Intelligence struggle to create the necessary emotional rollercoaster that is the basis of any successful political address? Also, will the issue of Data Privacy become a topic of interest with the voting population? Will people stay off social media during election weeks in order to avoid targeted marketing calls asking for their support? Will analysts dig further into people’s internet searches past social media, to try and sway their vote from a study of their online shopping habits or which online newspaper they read? Will presidential candidates be focussing too much on targeting the millennial vote through their predictive analytics, when ageing populations worldwide would suggest that a far larger proportion of people won’t be accessible through social media, making the over 50s vote the most important of all?We’ve posed a great deal of questions here. Much like modern politics, under the shiny exterior of Data Analytics, what lurks beneath is a great deal murkier. One only has to watch a few episodes of acclaimed drama House of Cards to understand the lengths that politicians will go to secure power. While there’s an argument to say that it is just television, how can we be so sure that it is far from the truth? If only one thing it is certain, it is that the use of Data Science in politics is set only to expand, rather than diminish, in the coming years.Chris Pearson is a Co-Founder of Big Cloud (www.bigcloud.io) specialist recruiters in the fields of Big Data & Data Science.For more Big Data and Data Science related articles visit our website or get in touch via LinkedIn or Twitter - @bigcloudteam ;Source? #This was written by one of our Directors, Chris Pearson. You can find him on LinkedIn, or email him chris@bigcloud.io - hope this helps!
bigdata;4ei5z2;1460494700.0;/r/bigdata/comments/4ei5z2/3_big_data_areas_for_nonprofits/;3 Big Data Areas For Non-Profits;WHEN YOU SAY Big Data, do you think of charities, donations, and non-profits? Why not? We non-profits have to go through quite a few hoops to get our donations. And to get them, we need to spend our donors’ money in a way the each individual donor feels the most comfortable with. And with a large number of donors we really need to be on our game. And Big Data can help.Here are the three main areas where Big Data best helps us non-profits.http://bizcatalyst360.com/3-big-data-areas-for-non-profits;
bigdata;4co41v;1459391557.0;/r/bigdata/comments/4co41v/understanding_causality_and_big_data_complexities/;Understanding Causality and Big Data: Complexities, Challenges, and Tradeoffs;;
bigdata;4cjl0o;1459318365.0;/r/bigdata/comments/4cjl0o/4_big_data_insights_from_nosql_world/;4 Big Data Insights from NoSQL World;;
SanDiegoJobs;4cnrmb;1459385960.0;/r/SanDiegoJobs/comments/4cnrmb/hiring_sr_big_data_consultant_san_diego_ca_usa/;[Hiring] Sr. Big Data Consultant - San Diego, CA, USA - Ziprecruiter;[deleted];
EngineeringStudents;4eim56;1460500712.0;/r/EngineeringStudents/comments/4eim56/help_deciding_internship/;Help deciding internship?;Hey fellow engies,I'm a freshman mechE student who wants to someday build beautiful planes :) I recently got an opportunity to work at an automotive company and travel to their headquarters in Japan! I will be working in their production engineering department as a precision measurement engineer. Apparently, the skills I'll need are CAD/CAM, IoT, and big data. I'm pretty excited as I really wasn't expecting an internship as a freshman. I've also always wanted to travel to Japan so I hope to explore Tokyo on the weekends! However, I'm in a bit of a dilemma as I hope to one day work in aeronautics, hopefully for Boeing, Nasa, Lockheed, Northrop or any other company in aero. While I don't have an offer I was also considering applying for a JPL internship, however, I decided not to as I realized most of the positions were in computer science doing programming which doesn't interest me very much. However, it could help in obtaining future internships with NASA or other aeronautical engineering companies. Should I stick with the internship that interests me or should I instead try for JPL even though the internship may not be as interesting? Also, is it more important to companies looking through your past internships that you did things similar to what you're applying for or simply that you worked at a company that is closely linked to theirs (regardless of what you actually worked on)? Of course, I plan to intern with JPL sometime through my college career (or at least I hope to) as they do have a few positions (often immediately filled by much more qualified candidates) in aero/mech engineering. I just don't know if it should be as soon as possible (this summer). I would really appreciate some advice. Thank you!;Congrats on the internship, that's a pretty sweet gig right there!You will be more favorable to companies if you intern within the industry you want to work in. It's still possible to get into aerospace even if you don't get an internship in that industry  you'll have to do more networking on your end. #Current JPL intern. JPL does not build planes, so nothing to offer there. As a freshman you will have very few skills to offer any company unless you have done extensive self-teaching outside of the classroom. I would stick with what you have as it sounds like you are interested. In the future, JPL is very heavily programming focused, but there are IoT based projects (which ironically involve extensive programming in addition to electronics work), and some hardware-based internships. JPL is more robotics and misc research, but I have found the internship I am participating in to be extremely fun and intellectually stimulating. Your mileage may very! Good luck, and congrats on getting an internship your freshman year.#It's great to hear from someone who is actually an intern there, thanks so much for the info! I do have an interest in robotics as well, however, as you have noticed, I am not as interested in programming as much as I am in modeling, manufacturing, and more meche/EE related skills than computer science. I guess I'm going to Japan! I'll definitely try my luck at JPL once I get through more coursework and can engage in projects that are more relevant to my interests. Thanks once again!
EngineeringStudents;4dpbju;1459999494.0;/r/EngineeringStudents/comments/4dpbju/technical_college_met_should_i_take_calculus_or/;[Technical College, MET] Should I take calculus or statistics? All opinions, guidance, stories, anecdotes and what have you are welcome.;[deleted];[deleted]#Argreed. Unless you want to go further than Calc 1 I wouldnt bother, it will be a headache and seem abstract, imo calculus requires some considerable time and investment to really appreciate it or be able to do anything with it.Statistics on the other hand is used all the time in manufacturing to model manufacturing defects and stuff like that. However, statistics is also pretty easy stuff imo and you could definitely learn it on your own buying a $8 textbook and doin a couple problems from it.
cscareerquestions;4e91qz;1460345312.0;/r/cscareerquestions/comments/4e91qz/i_accepted_an_internship_offer_but_i_have_three/;I accepted an internship offer, but I have three other companies who want me to continue interviewing still. Should I?;[deleted];Just do the interviews. At worst, you have to turn down offers, at most you find somewhere better than your current choice. #Make sure your school won't give you any penalty for reneging on an offer. #I would not cancel on them within three days of the interview. I did that and got in a bit of trouble (was resolved, but definitely an interesting situation). Unless there's an extremely pressing reason not to, I would just go through with the interivews
cscareerquestions;4c7p62;1459120563.0;/r/cscareerquestions/comments/4c7p62/i_have_two_different_internships_opportunities/;I have two different internships opportunities and I don't know which one to choose .;"Hello guys , next year in parallel of my second year  of studies (Undergraduate Degree of computer science in France) I have the possibility to do a one year long (paid )internship  .One of them is dedicatted to network (security/creation,big data all that ) and the other is a coding internship .The thing is what I really like about computer science is creating ,codes , ""worlds "", softwares , where  I let my creativity and my intelligence free (but I always keep the objective in mind ) ,where I make the rules and understands whats going on and where I am able to add,change , evoluate my creations .I know for sure than coding is my thing , I really love it and I can do it for the rest of my life as a job . But ....but networking seems really cool as well and unfortuantely so far the few classes I had about it were lame classes but I don't want to misjudge it  I know it could be interresting .It's just that I don't want to focus my self and my career on coding and then have regrets like ""Oh I wonder what it would have been if  Iwas into networks "" . Both of the interships are paid the same ,with the same amounts of hours per week , that's not what interrest me anyways . The point of this intership is my self-developpement .Edit : I forgot to tell , my prime factors are money , evolution (in terms of career/jobs)  and the job itself (I would prefer working on stuff that interrest me ) . Which brings me a question, won't Big Data/networking jobs pay more (if they don't already ) than coding jobs in the next 5-20 years?After that 2 year undergraduate degree I plan on doing  a master Degree of Software engineer and I will specialised my self depending the outcome of the internship. Thank you guys for reading my post.";"it sounds like you have a good idea about what you want!computer science is a huge topic and networking is only 1 part of that.  but you have the right idea, developing a specialty/focus is important to your career. i'd say that a lot of the really good money is available in the ""back end"" or ""low level"" stuff so getting close to the hardware and learning about operating systems, networks, databases/SQL, and systems applications is useful.#Thank you !I agree with your points , I will totaly consider them in my choices !"
RealEstateTechnology;4dymth;1460152656.0;/r/RealEstateTechnology/comments/4dymth/big_data_the_manna_for_database_startups/;Big data: The 'manna' for database startups;;
MSAccess;4dx58g;1460132633.0;/r/MSAccess/comments/4dx58g/question_about_ids/;Question about IDs;"RESOLVED! Thanks.Hello... very new to Access and hoping there is an easy answer to this given time issues... Also hope this makes sense as it took me some time to even figure out how to ask my question...I have a database (of course handed down to me) with multiple tables. Table 1 has the primary ID (for example ""Company#"") and a few basic demographic-type columns, to which all other tables associate. However, most (but not all) of the remainder of the tables have a secondary ID (or what I want to be a secondary ID) as well (for example, ""Division#""). Most companies, however, only have 1 division, but a significant minority have multiple divisions.I have some tables that are division specific (ie, the record/data is accurately identified only by both company and division ID, which are in the table as columns) and some tables that are company specific (ie the record/data applies to the whole company, and therefore all divisions, and only company ID is in the table). These subsequent tables (ie, not table 1) all refer to the exact same set of companies/divisions, but contain different bundles of information (perhaps better as one big data sheet, then queried? but not what was given to me).So example numbers, 400 companies, 500 divisions. Most tables have 500 records, some of 400 records, all refer to the same set of companies and divisions.My questions are:1) How do I set up the relationships so this is accurately reflected?2) Will doing #1 fix my attempt at a form: I tried pulling specific columns/data across multiple tables into a form for ease of editing, but noted that my record # more than doubled, and this was specifically because of companies with multiple divisions (example, instead of having 3 records for a company with 3 divisions, I instead had 244 records instead of 3.3) Am I even asking the right questions? Am I missing something?Again, hoping this is a quick and easy... but doubt it =). Would even help if you pointed me to a good ""relationships in Access"" resource  tried a few things but didn't seem to specifically address what I think is the conundrum.";"If I'm understanding your description correctly, you've got a parent Company table that has many child tables to which it relates (""division"" tables with different bits of info).Your company table has a Company# field. Provided that there are no duplicate company entries allowed in this table, make sure that the Company# field is the Primary Key for this table.Each table to which the Company table relates should have the Company# field. The Company# fields must have the same properties in each table. Those tables should have their own Primary Key fields as well.For instance, if a Company may possibly have more than one Division, then you can have a separate Division table. The Division table has a Primary Key field like Division#. The Division table would also have the Company# field.In the database Relationships Manager, choose to show the Company and Division tables. Click on the Company table's Company# field and drag to the Division table's Company# field. This opens a relationship editor window and should detect that you're trying to create a one-to-many relationship between the two tables. This type of relationship allows each individual record in the parent table to be linked to multiple records in the child table. (The order of clicking and dragging matters: go parent to child.)Here's what your Relationship Manager can look like: [Imgur](http://i.imgur.com/0jv8ZjU.jpg)It's the same principle for relating the Division table to any number of ""sub"" Division table children.I'd start there and see how the database you've inherited is set up. Good luck. #Thanks for the reply! This helps my general understanding.In regards to my specific question, I don't think I was very clear and want to try to explain again.For example, table 1 is sort of my ""master table"": Company#, City, State, etc. That sort of data.Table 2, for example, has in one row: company1, division 1, sales q1, sales q2...Then next row, company 2, division 1, sales q1, sales 2...Then next row, company 2, division 2, sales...Then next row, company 3, division 1.Where my ""secondary ID"" was division 1, 2. After having done some more reading and thinking, it sounds like what I'm calling the secondary ID should be the primary ID of table 2. And as such, it needs to be a unique ID and I can't repeat division 1 and division 2.Most subsequent tables also do company 1, division 2, different data 1, different data 2, etc. I was reading something about multiple-field primary keys but I fear that might be beyond me for now.A few subsequent tables only have company 1, data 1, data 2. These I can just link via the ID of company 1, if I'm understanding this correctly.How far off base am I?"
Marquette;4cdqgs;1459222064.0;/r/Marquette/comments/4cdqgs/milwaukee_big_data_users_group_meet_up_april_5/;Milwaukee Big Data Users Group Meet Up April 5;;
ApplyingToCollege;4d9kxv;1459744530.0;/r/ApplyingToCollege/comments/4d9kxv/which_college_to_choose/;Which college to choose;[deleted];This is a tough one OP. It looks to me UT and UTD are your only realistic option financially and while UT seems to be the obvious choice the 80k in debt is a lot of money. Assuming you want to go to UT I would look for a lot of scholarships while attending to cut costs. Also, the cost of attendance some schools have posted can be misleading as sometimes they add costs like a computer or insurance and other things you already pay for so keep that in mind. 
hackernews;4cn7au;1459377390.0;/r/hackernews/comments/4cn7au/using_spark_and_zeppelin_to_process_big_data_on/;Using Spark and Zeppelin to Process Big Data on Kubernetes 1.2;;There is a [discussion on Hacker News](http://news.ycombinator.com/item?id=11392121), but feel free to comment here as well.
ITCareerQuestions;4doh80;1459986360.0;/r/ITCareerQuestions/comments/4doh80/parttime_it_job_while_a_full_time_information/;Part-time IT job while a full time Information Technology Management Masters student?;I recently got my class schedule for my Masters Program in Information Technology Management.  My classes are Tuesday-Thursday, with Monday and Friday completely free, along with large chunks of Tuesday and Thursday.  This leaves with at least two weekdays where I am free.  I currently work in IT as a Helpdesk Tech/ user-facing IT person for the company I work at.  I actually got the job a week before I was accepted into the Master program, so I deferred the Masters for a year to see how I liked IT. I found that really like it.  The Masters sets one up for a Big Data Analytic role, Cybersecurity, IT conultant, Enterprises systems (SAP) or a Healthcare IT roles with a track system.  I'm vacillating between trying for an on-campus job or trying to do something more IT related part time in the local area. Any thoughts?;Have you talked to your current job to see if they can accommodate a part time or off-shift resource? Only two weekdays a week is not a lot to work with for any PT position. I would personally want you on 2nd shift or working weekends to try and get about 30 hours of work out of you anything less than that isn't worth my team's time to have on board.Your best alternative is retail space or on-campus. They are the only ones that immediately come to mind able to accept ~16 hours of availability or offer weekend/evening options.#Yes, I was thinking much the same.As for current job, maybe. However, I'd be community 100 miles a day for that possible position, which equates to a minimum of 2 hours of driving each workday. The issue is that my class schedule isn't all afternoon or all morning, it varies from morning to early afternoon to night.
opensource;4dgpp2;1459867395.0;/r/opensource/comments/4dgpp2/mariadb_corporation_today_announced_the_upcoming/;MariaDB Corporation today announced the upcoming release of its big data analytics engine, MariaDB ColumnStore, another significant milestone for the MariaDB open source community.;;
austinjobs;4dwyx7;1460130319.0;/r/austinjobs/comments/4dwyx7/hiring_java_developers_all_over_austin/;[HIRING] Java Developers! All over Austin;"Java Software Developers (Mid to Architect Level)    Multiple roles open!    Austin Texas area (will help with relocation)    Up to 175k	1. Sr. Java Developer- (Spring, Hibernate)	2. Sr. Java Developers (Healthcare IT)	3. Mid-level Java Engineer (Web Applications)	4. Sr. Java Architect (SOA, Microservices)	5. Sr. Java Developer (Eclipse RCP)	6. Sr. Java Developer (Scala/Hadoop) The HT Group is working closely with several Austin based companies, to find the right talent in this hot JAVA market.  We can expedite the interview and offer process for these roles and other positions that we have open that are similar. The HT Group has over two dozen clients in the Austin area that hire talented Java Developers from Mid-level roles to Architects.	1. Sr. Java Engineer (Spring/Hibernate)	You're fully vested from day one! Great perks and benefits. We are helping build a new development team for this well established, successful financial institution. Looking for a Sr level Java Developer to help lead core platform teams.  The team works in 2-week iterative development cycles with the goal of completing potentially shippable software each sprint. 		• (GoF) Gang of Four- Java Design Patterns 		• Core JAVA, 		• Spring 		• TDD environment 		• Must have strong Automated Continuous Deployment (CI/CD) exp. 			2. Sr. Java Engineers (Healthcare IT) Contract to Hire	One of our clients is a rapidly growing health management solutions company that has already disrupted the way we view the healthcare arena. A part of their arsenal in this good fight is building new technologies that support smarter decision-making for healthcare providers and their patients. They specialize in optimizing predictive analytics that are changing the face of healthcare across the country. We're helping them scale at this point to manage the phenomenal growth. Previous healthcare or managed care industry experience a BIG PLUS. 	3. Mid-Level Java Engineer (Web Applications)	Opportunity to work for a software vendor that provides tools for large companies  we just need some mid-level, very smart, hard-working developers who are full-stack Java EE developers. These are the kids of developers that we need (1 needs more UI experience than the others):		• BSCS Computer Science – A good university is important		• New grad to 5 years’ experience		• Prefer start-up experience		• Full stack development (Java EE) – persistence, mid-tier, UI (HTML/JavaScript)		• Experience with or knowledge of Agile – including TDD		• Very good communication skills and ability to work with a team			4. SOA Java Architect	This consulting firm works with some of the most innovative companies in the world including major ​film​ studios​, production companies,​ and large broadcasters. You should have a strong background in Java and an interest in collaborating with smart and talented engineers. You’ll work directly with leadership to assist in scoping out technical project proposals, present solutions to clients, collaborate/mentor team members and be an active part in the design and coding of impactful software. 		5. Sr. Java Developer (Eclipse RCP)	We are working directly and exclusively with this automated database company whose product is being used by the largest Fortune 500 companies wanting to integrate an Agile development process.  This is an opportunity for a Sr. Java Developer to be a part of a team that is automating changes in databases that helps DBA's minimize harm that can result from downtime when changes are made. They are helping BIG NAME customers stay on top of their competitors by cutting down database deployment time, speeding up their development process and launching applications. 		6. Sr. Java Developer (Scala)	We are working directly and exclusively with the President of this Big Data / Hadoop ecosystem / Data Analytics / ETL software company in its early stages of enterprise database management.  They are simply trying to build a better analytics product! Their platform is cloud hosted, so we will be looking for AWS and/or Azure experience. This is an opportunity for a Software Engineer to be part of something totally different. This ETL Software company is headed to paving the way of doing all things ""data"" their way, and even hold several patents for the data based technology used. If you love data and math this job is for you!  In additional to a competitive salary there is equity play and a sound group of investors funding them.     Apply directly this job, or LinkedIn profile Suzie Jimenez 512.872.2199 Suzie.Jimenez_AT_theHTgroup_com    (NO 3rd party calls)    (NO Visa sponsorship available)";
denverjobs;4dbd4x;1459781158.0;/r/denverjobs/comments/4dbd4x/hiring_mysql_dba/;[HIRING] MySQL DBA;Looking for a MySQL DBA to join our team. Hit me up with any questions or interest!As part of the DBA team, we’ll rely on your experience MySQL to support the design, implementation, and administration of database needs for the commercial and corporate business areas. Your analytical and communication skills will come into play as you collaborate with Business Analysts, Application Developers, Solution Architects, and Database Developers to analyze business requirements and specifications and translate those requirements into database designs and solutions. Your experience with database maintenance will prove useful as you are identifying and resolving production and application development problems, calculating optimum values for parameters, evaluating and integrating/installing new releases, completing maintenance and responding to user questions. If this sounds interesting, keep reading...**Requirements*** 5+ years of hands-on database administration experience on MySQL databases deployed on Linux, covering installation, configuration, patching, supporting and upgrading * Experience with implementing highly available and fault-tolerant MySQL database solutions for multiple projects, including leverage of OS clustering capabilities* Experience with MySQL replication technologies including Master-Master multi-replication, Master-Multiple Slave replication* MySQL administration and support experience including backup and recovery, replication, clustering, performance tuning, and monitoring* Familiar with MySQL Enterprise backup and recovery tools including 3rd party backup solutions* Experience with documentation of standard procedures, architecture, design and deployments* Familiar with MySQL Enterprise Manager* Experience with supporting various MySQL versions and Editions(Part of the OS, Community/Open Source, Standard, and Enterprise)* Strong Linux experience* Release management and deployment of code in different environments using source code control tools such as Git, Perforce, CVS, etc.* Prior support experience with the application stack connecting to the MySQL database back-end* Available for On-Call and After Hours support as needed.* Bachelors degree or equivalent experience* US government position. US citizenship required.* Ability to travel up to 25% **Preferences*** Experience working in a highly segmented network with complex firewall implementations and many security features* Experience with scripting frequently occurring activities* Experience with creation and use of templates, automated installations, etc.* Experience with using HP Data Protector or CommVault tools* Experience with MySQL Partitioning for performance and manageability* Exposure to Oracle Database fundamentals and administration* Experience with Open Source and Big Data databases (relational and non-relational) PostgreSQL, MongoDB, Hadoop, etc.;
bigdata;4erkml;1460646600.0;/r/bigdata/comments/4erkml/job_alert_software_engineer_big_data_san_mateo_ca/;[JOB ALERT] Software Engineer, Big Data (San Mateo, CA);[deleted];
bigdata;4eqcxs;1460625851.0;/r/bigdata/comments/4eqcxs/where_to_find_reliable_statistics_about_big_data/;Where to find reliable statistics about big data;I've seen a lot of infographics about the amount of data created (like this one : http://www.vcloudnews.com/every-day-big-data-statistics-2-5-quintillion-bytes-of-data-created-daily/) but I couldn't find the sources and they're not quite complete, like they only have one year, or only the data created on social networks.Ideally, I would like to find some statistics about the amount of data created each year from every sources during the last 5 years. Do you guys have any idea where to find it ?;"Gah, I just started The Signal and the Noise last night and he mentions it in the introduction with a reference link but I'm currently only on the Kindle sample, so I don't have the page it is wanting to jump to! If anyone has it it is at location ~349 in The Promise and Pitfalls of ""Big Data.""#Uh, so I went to the reference (found the PDF on Google quick) and it's literally just a paragraph on this [IBM page](http://www-01.ibm.com/software/data/bigdata/what-is-big-data.html)... Guess I can't help."
bigdata;4eicae;1460497014.0;/r/bigdata/comments/4eicae/tourcoing_une_ville_riche_en_bigdata/;Tourcoing, une ville riche en #BigData;;
bigdata;4d84cv;1459720409.0;/r/bigdata/comments/4d84cv/i_was_wrong_big_data_isnt_bullshit_sometimes_you/;I was wrong. Big Data isn't bullshit! ... Sometimes you just have to tell it like it is... social media being what it is...;;So much salt. Git gud.#The article is really unoriginal (there have been many articles on big data hype) and too dramatic for its simple point as in the author trying to create a martyr out of themselves.To touch upon the topic - big data are not a magical cure and obviously there is a lot of hype around it, but it brings in some benefits (as well as challenges). #I was wrong!I give in, and I admit it. Big Data isn't bullshit.I was wrong!I have been critical of what I viewed to be unhelpful, misleading and exaggerated claims for Big Data.I was wrong!I was wrong for generalising about the bullshit, boloney and fluff. I was wrong about my veiled condemnation of hype and those who spread it about so liberally and constantly.I was wrong, and I want to publicly admit that I was wrong.
technews;4dvyob;1460115007.0;/r/technews/comments/4dvyob/what_should_we_do_about_big_data_leaks/;What Should We Do About Big Data Leaks?;;
cscareerquestions;4ds4vl;1460050274.0;/r/cscareerquestions/comments/4ds4vl/any_other_developer_fields_besides_web_development/;Any other developer fields besides Web Development?;I've dabbled in web development for a bit but I'm not really a fan of how constrained it is... are there any other fields outside of web development out there?  Do any of those fields delve into AI, Machine Learning, or Big Data?;Depends what you mean by web development. Are you making websites, or full-stack applications?#I particularly love building web services. You could look for jobs that do that. I also like building scraper scripts and cron job scripts in python.#Worked with both and I was more partial to building full-stack applications, but I want to take a turn to something different.
programming;4csnle;1459466342.0;/r/programming/comments/4csnle/understanding_causality_and_big_data_complexities/;Understanding Causality and Big Data: Complexities, Challenges, and Tradeoffs;;
pystats;4cqctx;1459436101.0;/r/pystats/comments/4cqctx/causal_discovery_software_available_for_big_data/;Causal Discovery Software Available for Big Data Analysis;The Center for Causal Discovery (CCD) (www.ccd.pitt.edu) has released the Fast Greedy Search (FGS) algorithm (an optimized version of Chickering's Greedy Equivalence Search algorithm) for use by biomedical investigators who are searching for causal associations in large sets of continuous data.  A technical paper describing the optimization is available at http://arxiv.org/abs/1507.07749.  It is available as free and open source software. This release is just the first step toward providing a suite of algorithms that will assist biomedical researchers in analyzing their data to obtain causal insights.  Using simulated data, FGS was able to learn a causal network on data containing 50,000 variables and 1,000 samples in about 15 minutes on a laptop computer. While FGS does not model hidden variables that cause two or more measured variables, an upcoming release of another algorithm will do so.FGS is available as a command line implementation (Causal-cmd) that calls a local Java library or as a Java web application (Causal-web) that runs the analysis at the Pittsburgh Supercomputing Center  the API’s can also be run through R (R-causal) or Python (Py-causal). Additional details and instructions for downloading both these versions of the software are available at http://www.ccd.pitt.edu/wiki/index.php?title=Tools_and_Software.Our goal is to help the biomedical community use causal modeling to gain novel insights and drive innovative research, so we hope to make these tools as usable and useful as possible.  We welcome any and all feedback that you might have, which will help us improve this and future releases. ;
UWMilwaukee;4cj8dn;1459311152.0;/r/UWMilwaukee/comments/4cj8dn/milwaukee_big_data_users_group_meetup_april_5/;Milwaukee Big Data Users Group Meetup April 5;;
recruitinghell;4eqcop;1460625675.0;/r/recruitinghell/comments/4eqcop/how_big_data_can_help_you_in_tripling_your_talent/;How Big Data Can Help You in Tripling Your Talent Acquisition Capacity?;;
recruitinghell;4epz3x;1460616421.0;/r/recruitinghell/comments/4epz3x/how_big_data_can_help_you_in_tripling_your_talent/;How Big Data Can Help You in Tripling Your Talent Acquisition Capasity;[deleted];Oh man. How many things can we identify in just this article that help to produce the recruiting hell?Let us count the ways.> According to LinkedIn’s Global Talent Trends 2015, For the critical job, 95% of the people you want to hire aren’t looking for a job.Found why people keep getting unsolicited job offers.> Be flexible with being on every platform where you may find the top talents. For example, use Snapchat for recruitment.Employers: They'll follow you everywhere. They want your data from everywhere.Also, the whole thing is an advertisement for social media data mining software.#capa***C***ity 
opensource;4cff3p;1459258234.0;/r/opensource/comments/4cff3p/big_data_20_open_source_becomes_a_converged/;Big Data 2.0: Open Source Becomes A Converged Product;;
PanamaPapers;4dca2x;1459793060.0;/r/PanamaPapers/comments/4dca2x/relating_to_the_panama_leaks_and_other_news/;Relating to the Panama Leaks and other news.;[deleted];
austinjobs;4chg4y;1459284628.0;/r/austinjobs/comments/4chg4y/hiring_android_developer_central_austin_area/;[HIRING] Android Developer, Central Austin area;"Contact me directly if you have any questions: Suzie.Jimenez_at_theHTgroup_com 512.872.2199	Android Developer (Digital Fitness)	Austin Texas area	Perm - Direct Hire	We are working directly with the CEO of an Austin-based digital fitness, well-funded, late stage start-up.  This digital health company is developing connected offerings for the gym! If you are into health/fitness and technology this position is for you…continue to ""Keep Austin Weird"" and ""Healthy""! 		Their mission is to make getting healthy easy, fun and rewarding. Opportunity for this Android Developer to join a startup early where you can contribute and your opinion counts. Work on a platform team that pushes the envelope in all the latest and greatest technologies, including big data and machine learning. Rated 5 star in Consumer Reports!		Android Developer skills we are looking for:		• 3+ years' work experience as a mobile engineer 		• Hands on experience in developing Android applications and releasing apps on Google Play. 		• Strong understanding of Android frameworks and libraries		• Strong understanding of object-oriented programming, algorithms, and data structures	 	Benefits:		• Medical and dental/PTO";
bigdata;4es9ju;1460655084.0;/r/bigdata/comments/4es9ju/a_history_of_streaming_and_big_data/;a history of streaming and big data;;
bigdata;4dxmrk;1460138982.0;/r/bigdata/comments/4dxmrk/big_data_and_the_marijuana_environment_data_talk/;Big Data and The Marijuana Environment - Data Talk Show :: Big Data Podcast;;To have a podcast on Big Data in general is a great idea, do you plan on doing it regularly? 
bigdata;4dspg7;1460057346.0;/r/bigdata/comments/4dspg7/odpi_releases_runtime_specifications_for_big_data/;ODPi Releases Runtime Specifications for Big Data Apps;;
bigdata;4dl1gm;1459935233.0;/r/bigdata/comments/4dl1gm/tap_the_full_potential_of_big_data_in_learning/;Tap the Full Potential of Big Data in Learning;;
bigdata;4dhrb8;1459880784.0;/r/bigdata/comments/4dhrb8/seganndb_fighting_cancer_with_big_data_analytics/;SegAnnDB - Fighting Cancer with Big Data Analytics;;
bigdata;4db10m;1459776016.0;/r/bigdata/comments/4db10m/the_best_thing_you_should_know_about_big_data/;The Best Thing You Should Know about Big Data;;Title gore always reveals utterly shitty articles#Title not expressive of the content...still illustrations are nice.
statistics;4eyv54;1460754911.0;/r/statistics/comments/4eyv54/soon_to_be_graduate_with_bs_in_statistics_i_need/;Soon to be graduate with BS in Statistics. I need career/ graduate school advice.;[deleted];">Thanks, LoganFirst piece of advice: never put personal information on reddit, you never know who could end up reading these posts.If you want to become a quantitative analyst, you are much better off going to the graduate program in Statistics. The reason is simple: you will be doing some heavy computation and employers want to see a graduate degree in a technical field.If you want to get into the quantiative aspects of finance you are much better off with a quantitative degree. Reason being, there are way more mbas than their are degrees in STEM. If you want to ""network,"" feel free to go for an mba or masters in finance. However, those degrees are incrediblely overpriced. >Should I bother with graduate school at the moment?Depends, how much applicable experience do you have? Have you done any interviewing yet. Obviously it would be preferable to go straight into the workforce in your career field of choice, but that is not always possible. Especially, if you are not willing to relocate. My personal advice is go to the cheapest state school you can find if you do decide to go to graduate school. With the key being make sure you get an internship, that is the most important consideration.#Thank you for the honest comment. I ended up deleting the post because of how much personal information I had exposed.I agree with you on the technical aspect of the statistics degree but I also, for some reason, feel like the degree rabbit holes me.Now that I am done with my BS I am gunning for internships somewhere to get my footing using my new degree. Are there any companies in Texas/ San Antonio you would recommend?I am willing to relocate but at this point I am pretty set on getting my masters. I feel it cant do any harm. What do you think?#I don't think a graduate degree in STEM will ever pigeon hole you. I think what will pigeon whole you is if you end up paying tens of thousands of dollars more for an mba or degree in finance and then you are saddled with debt. For what, so you can go to school to learn some key terms? I don't see the value. I feel like mbas are kind of like houses in the late 90's, ""I am going to get this finance degree cause I can sell it to someone at a higher price, not because it is actually valuable""I can't speak to the Texas/ San Anotonio area since I live in CA, but I can say don't limit yourself to one location. A lot of people have family obligations so it is impossible to move out of their locale, so not limiting yourself is a major advantage.The key here reguardless of what you do is to be persistant. Start looking for internships in September, get in a habit. I personally just searched and applied every friday night until I got one. Persistance is key, the job market sucks for everyone. "
Advice;4e7139;1460314383.0;/r/Advice/comments/4e7139/i_am_a_high_school_student_and_i_have/;I am a high school student and I have successfully managed to calculate the function to get the volume of a 4 dimensional sphere. Will I have a good future in mathematics?;[deleted];R/quityourbullshit#/r/Advice prefers that you **flair your post**!  This comment will be deleted once flair has been added.To add flair to your post, open it and click the button labelled ``flair`` beneath your title.  From the menu, select the most appropriate category, and then hit ``save``.  You do *not* need to delete or resubmit your post!*Don't blame me, [I'm just a bot](/28tspq) from [radd.it](http://radd.it)*.
privacy;4dmw8f;1459965066.0;/r/privacy/comments/4dmw8f/what_should_we_do_about_big_data_leaks_the/;What Should We Do About Big Data Leaks? The internet makes critical information accessible. Now let’s make it usable.;;I think this might be the lamest wrap-up I've read in a long time.> I’ll be completely, well, transparent: I don’t think we’re ready for highly searchable, easily accessible, leaks and data dumps. We are not a particularly measured society, and this sort of information actually rewards a sense of historical context and measured analysis. We like to validate assumptions, not explore corpora. But the data keeps falling off the back of the truck, or is released by some august governmental body, or sneaked out of the country on a mislabeled compact disc. A transparent society is one that makes data not just available but usable. What use is a window if you can’t stare through it? #It is there for reporters who have an interest and can pour through it and serve up interesting angles and news. I love snooping through leaks, partly for the voyeur in me, partly because I'm pissed about the lack of transparency, when there really should be some.
cscareerquestions;4dk804;1459916393.0;/r/cscareerquestions/comments/4dk804/soon_to_be_cs_grad_this_may/;Soon to be CS grad this may;[deleted];I recommend taking a look at *Cracking the Coding Interview*. It's really hard to prepare for a specific role and from my own internship experience, most learning is done on the job anyways so the best would be to ace the interview!
forhire;4ei2mv;1460493518.0;/r/forhire/comments/4ei2mv/for_hire_freelance_data_scientist_w10_years/;[For hire] Freelance data scientist w/10+ years experience.;[deleted];
buildapc;4cc17i;1459197347.0;/r/buildapc/comments/4cc17i/data_science_build/;Data science build;"###Build Help/Ready:**Have you read the sidebar and [rules](http://www.reddit.com/r/buildapc/wiki/rules)? (Please do)**Yes**What is your intended use for this build? The more details the better.**Writing & testing programs in Python and R for Kaggle competitions, among other 'data science' projects. **If gaming, what kind of performance are you looking for? (Screen resolution, FPS, game settings)**Not concerned with gaming performance**What is your budget (ballpark is okay)?**1000-1200**In what country are you purchasing your parts?**USA. I live near a Micro Center**Post a draft of your potential build here (specific parts please). [Consider formatting your parts list.](http://www.reddit.com/r/buildapc/wiki/pcpp) Don't ask to be spoonfed a build (read the rules!)**.[PCPartPicker part list](http://pcpartpicker.com/p/mNkVrH) / [Price breakdown by merchant](http://pcpartpicker.com/p/mNkVrH/by_merchant/)Type|Item|Price:----|:----|:----**CPU** | [AMD FX-8350 4.0GHz 8-Core Processor](http://pcpartpicker.com/part/amd-cpu-fd8350frhkbox) | $159.89 @ OutletPC **Motherboard** | [Asus M5A99FX PRO R2.0 ATX AM3+ Motherboard](http://pcpartpicker.com/part/asus-motherboard-m5a99fxpror20) | $119.88 @ OutletPC **Memory** | [G.Skill Ripjaws X Series 32GB (4 x 8GB) DDR3-1600 Memory](http://pcpartpicker.com/part/gskill-memory-f31600c9q32gxm) | $119.99 @ Newegg **Storage** | [Samsung 850 EVO-Series 250GB 2.5"" Solid State Drive](http://pcpartpicker.com/part/samsung-internal-hard-drive-mz75e250bam) | $87.39 @ OutletPC **Storage** | [Seagate Barracuda 2TB 3.5"" 7200RPM Internal Hard Drive](http://pcpartpicker.com/part/seagate-internal-hard-drive-st2000dm001) | $65.99 @ SuperBiiz **Video Card** | [MSI Radeon R7 265 2GB Video Card](http://pcpartpicker.com/part/msi-video-card-r72652gd5oc) |-**Case** | [Fractal Design Define R4 w/Window (Black Pearl) ATX Mid Tower Case](http://pcpartpicker.com/part/fractal-design-case-fdcadefr4blw) | $77.99 @ NCIX US **Power Supply** | [EVGA SuperNOVA G2 650W 80+ Gold Certified Fully-Modular ATX Power Supply](http://pcpartpicker.com/part/evga-power-supply-220g20650y1) | $99.99 @ Amazon **Optical Drive** | [Samsung SH-224DB/BEBE DVD/CD Writer](http://pcpartpicker.com/part/samsung-optical-drive-sh224dbbebe) | $17.89 @ OutletPC **Operating System** | [Microsoft Windows 10 Home OEM (64-bit)](http://pcpartpicker.com/part/microsoft-os-kw900140) | $86.86 @ Amazon **Monitor** | [Asus VX238H 23.0"" Monitor](http://pcpartpicker.com/part/asus-monitor-vx238h) | $109.99 @ Micro Center **Monitor** | [Asus VX238H 23.0"" Monitor](http://pcpartpicker.com/part/asus-monitor-vx238h) | $109.99 @ Micro Center **Keyboard** | [Logitech MK520 Wireless Ergonomic Keyboard w/Laser Mouse](http://pcpartpicker.com/part/logitech-keyboard-920002553) | $30.99 @ Amazon  | *Prices include shipping, taxes, rebates, and discounts* | | Total (before mail-in rebates) | $1141.84 | Mail-in rebates | -$55.00 | **Total** | **$1086.84** | Generated by [PCPartPicker](http://pcpartpicker.com) 2016-03-28 15:52 EDT-0400 |**Provide any additional details you wish below.**This is my first build.  I am aware that anything involving actual big data will require renting computer time from a third party, but most of the stuff I'm interested in doesn't use that much data.I excluded a CPU cooler because the person who gave me this build template said that his runs fine without one.I will install the OS to the SSD, but I don't know what else to put on there and I am a little afraid of wasting storage space.  Speaking of the OS, I didn't have the guts to commit to a switch from Windows to Linux, but I could probably be talked into it by someone with more experience than me.As for antivirus: Based on [this post] (https://www.reddit.com/r/buildapc/comments/3v2q9j/what_is_the_best_free_antivirus/) I am planning on using Avira+uBlock origin.";"Hope I'm not late.[PCPartPicker part list](http://pcpartpicker.com/p/FWtXCJ) / [Price breakdown by merchant](http://pcpartpicker.com/p/FWtXCJ/by_merchant/)Type|Item|Price:----|:----|:----**CPU** | [Intel Core i5-6400 2.7GHz Quad-Core Processor](http://pcpartpicker.com/part/intel-cpu-bx80662i56400) | $179.00 @ B&H **Motherboard** | [Gigabyte GA-H110M-A Micro ATX LGA1151 Motherboard](http://pcpartpicker.com/part/gigabyte-motherboard-gah110ma) | $51.89 @ OutletPC **Memory** | [GeIL EVO POTENZA 16GB (2 x 8GB) DDR4-2400 Memory](http://pcpartpicker.com/part/geil-memory-gpr416gb2400c16dc) | $54.99 @ Newegg **Storage** | [Samsung 850 EVO-Series 250GB 2.5"" Solid State Drive](http://pcpartpicker.com/part/samsung-internal-hard-drive-mz75e250bam) | $87.39 @ OutletPC **Video Card** | [MSI Radeon R7 265 2GB Video Card](http://pcpartpicker.com/part/msi-video-card-r72652gd5oc) |-**Case** | [Cooler Master N200 MicroATX Mid Tower Case](http://pcpartpicker.com/part/cooler-master-case-nse200kkn1) | $39.99 @ Newegg **Power Supply** | [Fractal Design Integra M 450W 80+ Bronze Certified Semi-Modular ATX Power Supply](http://pcpartpicker.com/part/fractal-design-power-supply-fdpsuin3b450w) | $49.99 @ Newegg **Optical Drive** | [Samsung SH-224DB/BEBE DVD/CD Writer](http://pcpartpicker.com/part/samsung-optical-drive-sh224dbbebe) | $17.89 @ OutletPC **Operating System** | [Microsoft Windows 10 Home OEM (64-bit)](http://pcpartpicker.com/part/microsoft-os-kw900140) | $86.86 @ Amazon **Monitor** | [Asus VX238H 23.0"" Monitor](http://pcpartpicker.com/part/asus-monitor-vx238h) | $109.99 @ Micro Center **Monitor** | [Asus VX238H 23.0"" Monitor](http://pcpartpicker.com/part/asus-monitor-vx238h) | $109.99 @ Micro Center **Keyboard** | [Logitech MK520 Wireless Ergonomic Keyboard w/Laser Mouse](http://pcpartpicker.com/part/logitech-keyboard-920002553) | $30.99 @ Amazon  | *Prices include shipping, taxes, rebates, and discounts* | | Total (before mail-in rebates) | $868.97 | Mail-in rebates | -$50.00 | **Total** | **$818.97** | Generated by [PCPartPicker](http://pcpartpicker.com) 2016-03-30 05:40 EDT-0400 |Faster, cheaper, smaller.I5 is much faster than the amd.16gb of ram is necessary for data input and analysis.Strong psu for long tasks and is semi modular.Can add a better gpu, didn't though because I am assuming you have that gpu since there is no price."
Futurology;4dhl6o;1459878620.0;/r/Futurology/comments/4dhl6o/singularity_universitys_exponential_manufacturing/;Singularity University’s Exponential Manufacturing conference is coming up this May in Boston;[removed];Thanks for contributing. However, your [submission](https://www.reddit.com/r/Futurology/comments/4dhl6o/singularity_universitys_exponential_manufacturing/) was removed from /r/Futurology>Rule 4 - No petitions, polls, surveys, fundraisers, crowdfunding, crowdsourcing, or otherwise soliciting the userbase. This is considered spam.*Refer to the [subreddit rules](/r/futurology/wiki/rules), the [transparency wiki](http://www.reddit.com/r/futurology/wiki/transparency#wiki_relevant_material), or the [domain blacklist](http://www.reddit.com/r/Futurology/wiki/domainblacklist#blacklist) for more information**[Message the Mods](https://www.reddit.com/message/compose?to=/r/Futurology&subject=Question regarding the removal of this submission by /u/canihazmoar&message=I have a question regarding the removal of this [submission](https://www.reddit.com/r/Futurology/comments/4dhl6o/singularity_universitys_exponential_manufacturing/\):) if you feel this was in error*
explainlikeimfive;4d7us4;1459716487.0;/r/explainlikeimfive/comments/4d7us4/eli5_what_a_shell_corporation_does_and_how_it/;ELI5: what a shell corporation does and how it works;The big data leak about the rich people is confusing.;A shell company is one set up to hide or delay the discovery of real assets or the source of income or to hide liabilities. They are often set up in foreign countries as it's difficult to trace money moving through them. Let's say I have millions in my bank account and don't want to give them to my soon to be ex-wife. I setup a company in the Bahamas and purchase sea shells from them for millions of dollars. Now I am broke but the company overseas (which you can't prove I control) has the money. Just an example. 
betternews;4evtbg;1460709082.0;/r/betternews/comments/4evtbg/cityu_is_the_ideal_place_to_research_the_use_of/;CityU is the ideal place to research the use of big data;;
Amsterdam;4cvd4n;1459513672.0;/r/Amsterdam/comments/4cvd4n/question_studying_and_working_in_amsterdam/;[Question] Studying and Working in Amsterdam;Hello Reddit,I received an admission offer from VU for MSc in Computer Science (joint degree with UvA). The specialization is Big Data Engineering.I'd like to know a few things before deciding on whether or not to go there - How is the university experience overall ? The professors, the classes, etc.- I plan on learning Dutch as soon as I decide to go but I'd like how difficult/easy is it to get a part-time job in Amsterdam or at the University.- Post-graduation, how is the job market in Amsterdam ? The information on VU says that most of their graduates have jobs just before graduation. How accurate is that ?- How is the living situation ? I guess I'd receive help from VU (maybe UvA too).Thank You.(A 25 year old guy from India);> How is the university experience overall ? The professors, the classes, etc.Pretty similar to other universities I would say. Is there anything specific you were thinking of?> I plan on learning Dutch as soon as I decide to go but I'd like how difficult/easy is it to get a part-time job in Amsterdam or at the University.Several possibilties:* There are some jobs you can get in tourism without speaking Dutch but there is a lot of competition for those jobs.* Assuming you are a good programmer, you could make better money freelancing as(for example) as web designer but it might be hard to get connections.* There are occasionally vacancies for student assistants, which are usually offered to students who have shown to be among the best in their class.> Post-graduation, how is the job market in Amsterdam ? The information on VU says that most of their graduates have jobs just before graduation. How accurate is that ?Good students usually have no problem finding a job. In fact, often the best ones go abroad to companies like Google and Microsoft or continue to get a PhD.> How is the living situation ? I guess I'd receive help from VU (maybe UvA too).With help it should be fine. Without it is very difficult.
AskAcademia;4eky3v;1460543213.0;/r/AskAcademia/comments/4eky3v/have_to_write_a_research_proposal_using_big_data/;Have to write a research proposal using big data, what kind of topics?;[deleted];I have zero knowledge about economics research methods or studies, but the first thing everyone needs to do when thinking about a research proposal in any field is to RESEARCH. Research any academic/scientific papers using big data in the economics field. Use freefullpdf if you don't have access to an online library from your university. Read the abstracts if you don't have much time, and see which are about topics that interest you. Then read those ones very carefully, mainly the Method section to see what exactly they did and how. You can't choose a topic out of your head, you have to research what has already been done, how, why, and what would be useful to your field for you to do. The more you research the better your choice of topic will be.
austinjobs;4cqylh;1459444057.0;/r/austinjobs/comments/4cqylh/hiring/;[HIRING];"    Senior Software Engineer (Scala/Java)    Northwest Austin    PERM - Direct Hire    Salary is OPEN + equity!     We are working directly and exclusively with the President of this Big Data / Hadoop ecosystem / Data Analytics / ETL software company in its early stages of enterprise database management.  They are simply trying to build a better analytics product! Their platform is cloud hosted, so we will be looking for AWS and/or Azure experience. This is an opportunity for a Software Engineer to be part of something totally different. This ETL Software company is headed to paving the way of doing all things ""data"" their way, and even hold several patents for the data based technology used. If you love data and math this job is for you!  In additional to a competitive salary there is equity play and a sound group of investors funding them.    What are we looking for in this Sr. Software Engineer:	· Python experience preferred or be open to learning a new programming language	*Data structures and algorithms	*Scala and Java ecosystem	*BS in Computer Science, Mathematics, or related field    PLUSES that will put this Software Engineer on top of this list:	*Spark 	*AWS, Azure, or other cloud infrastructure 	*Relational and NoSQL databases	*Hadoop ecosystem      Have questions? Contact me directly Suzie Jimenez 512.872.2199 or send me your LINKEDIN profile.#Python #datastructures #algorithms #scala #java #spark #aws  #azure #cloud #nosql  #hadoop #ecosystem #javajobs #itjobs #technicaljobs #austin #texas #atx";
bigdata;4dr232;1460036201.0;/r/bigdata/comments/4dr232/weve_been_hearing_how_big_data_can_solve_business/;We've been hearing how big data can solve business problems. Turns out it can also detect plagiarism, even in the rarefied world of crossword puzzles.;;
bigdata;4dqah1;1460020966.0;/r/bigdata/comments/4dqah1/evolving_technologies_for_driving_big_data/;Evolving Technologies for Driving Big Data;;
bigdata;4dbedy;1459781640.0;/r/bigdata/comments/4dbedy/will_big_data_enhance_3d_printing_association_of/;Will Big Data Enhance 3D Printing? | Association of 3D Printing;;
bigdata;4cvd7r;1459513704.0;/r/bigdata/comments/4cvd7r/despite_potential_benefits_big_data_faces/;Despite potential benefits, big data faces resistance in healthcare;;
bigdata;4ccthx;1459207992.0;/r/bigdata/comments/4ccthx/big_data_fc_and_its_all_gone_quiet_over_there/;Big Data FC: And it's all gone quiet over there!;;Big Data is all pervasive, all seeing and all knowing.Everyone is doing Big Data, and if they aren’t then they will.  It’s inevitable.Big Data will revolutionise the worlds of data, decision making and business.Am I right, or am I right?
UIUC;4dfej3;1459841173.0;/r/UIUC/comments/4dfej3/should_i_take_cs_411_cs_412_cs_467_and_either_cs/;Should I take CS 411, CS 412, CS 467, and either CS 374 or CS 242?;"Little context, I am done with all my gen ed requirements as well the technical core like Phys 214 or STAT 400. I only have CS classes left to take, but I am also aware of how much time commitment these classes take. I have 374, 242, and 421 left to take along with the 8 electives. Does anyone have a good combination of classes I can take that are in the Big Data/ AI track and balance ""well"" with 374 or 242? Open to ideas.";If you haven't already, it'd probably be better to post this on the CS Advising piazza.
transit;4cr4br;1459446047.0;/r/transit/comments/4cr4br/how_your_company_can_use_big_data_analysis_to/;How Your Company Can use Big Data Analysis to Improve Last Mile Deliveries;;
EverythingScience;4ef8ib;1460450497.0;/r/EverythingScience/comments/4ef8ib/12_inspiring_women_in_data_science_big_data/;12 Inspiring Women In Data Science, Big Data;;
EverythingScience;4ccbuy;1459201295.0;/r/EverythingScience/comments/4ccbuy/can_big_data_help_psychiatry_unravel_the/;Can Big Data Help Psychiatry Unravel the Complexity of Mental Illness?;;
compsci;4e3u8h;1460248887.0;/r/compsci/comments/4e3u8h/what_electives_should_i_take/;What electives should I take?;[removed];Hi,I have removed your post from /r/compsci, as per the sidebar we discourage most posts about how to study CS.  I'd recommend /r/askcomputerscience.
learnprogramming;4ddfum;1459808051.0;/r/learnprogramming/comments/4ddfum/lesson_ideas_for_my_schools_computer_science_club/;Lesson ideas for my school's computer science club?;[deleted];
learnprogramming;4cpzq3;1459430719.0;/r/learnprogramming/comments/4cpzq3/what_should_i_read_in_order_to_be_able_to_read/;What should I read in order to be able to read Judea Pearl's Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference?;"I heard good things about the book ""Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference by Judea Pearl"" and want to be able to read it. However, on a first read, it seems way above my level and there's too much jargon. I am learning Computer Science on my own and have completed MIT's online offerings of 6.00.1x (Intro to CompSci), 6.00.2x (Intro to Computational Thinking), 6.041x (Intro to Probability), some data analytics modules, UCB's Big Data with Apache Spark course, among others.Could you please suggest textbooks for me to read before attempting Judea Pearl's book again?Thank you!";
buildapc;4d0ssx;1459586626.0;/r/buildapc/comments/4d0ssx/upgrade_to_haswelle_broadwelle_skylake_or_kaby/;Upgrade to Haswell-E, Broadwell-E, Skylake or Kaby Lake?;[deleted];"6800k is not expected to be a very big increment over 5820k. If you need lot of CPU power, buy a high core Xeon workstation. Even a used one will last for a long time.Best ""future-proof"" plan is to buy best available CPU in your budget. We can discuss it when you are ready to build your PC."
TwoXChromosomes;4eadm4;1460375811.0;/r/TwoXChromosomes/comments/4eadm4/12_inspiring_women_in_data_science_big_data/;12 Inspiring Women In Data Science, Big Data;[deleted];
programming;4eeiiv;1460434394.0;/r/programming/comments/4eeiiv/analytics_yes_big_data_no/;"Analytics Yes; Big Data No!";[deleted];All these gold rushes. Its so hard to stay trendy.  I want a high paying job playing with big clusters of stuff. Big data it is...
dataisbeautiful;4epx6i;1460615188.0;/r/dataisbeautiful/comments/4epx6i/big_data_and_iot_a_perfect_duet/;Big Data and IOT: A perfect Duet;;
dataisbeautiful;4ccg5h;1459202864.0;/r/dataisbeautiful/comments/4ccg5h/can_big_data_help_psychiatry_unravel_the/;Can Big Data Help Psychiatry Unravel the Complexity of Mental Illness?;;> A post must include a [data visualization](http://www.reddit.com/r/dataisbeautiful/wiki/index#wiki_what_is_a_data_visualization.3F).This post has been removed.
Austin;4crl0u;1459451892.0;/r/Austin/comments/4crl0u/hiring_senior_software_engineer_scalajava/;[HIRING] Senior Software Engineer (Scala/Java);[removed];/r/austinjobs #Your submission has been removed for the following reason(s):* It would be a better fit in /r/AustinJobs.For more information please read the [reddit guidelines](http://www.reddit.com/wiki/reddiquette) and the [rules of /r/Austin](https://www.reddit.com/r/Austin/wiki/rulesandmoderating). If you have any questions, [please feel free to message the mods](http://www.reddit.com/message/compose?to=/r/Austin&message=https://www.reddit.com/r/Austin/comments/4crl0u/hiring_senior_software_engineer_scalajava/). If you think your post or comment has been incorrectly removed, send a message, but please remember there's a person on the other end, not some automaton, and be nice about it. Thank you!
MachineLearning;4cq8eb;1459434361.0;/r/MachineLearning/comments/4cq8eb/causal_discovery_software_available_for_big_data/;Causal Discovery Software Available for Big Data Analysis;Causal Discovery Software Available for Big Data Analysis The Center for Causal Discovery (CCD) (www.ccd.pitt.edu) has released the Fast Greedy Search (FGS) algorithm (an optimized version of Chickering's Greedy Equivalence Search algorithm) for use by biomedical investigators who are searching for causal associations in large sets of continuous data.  A technical paper describing the optimization is available at http://arxiv.org/abs/1507.07749.  It is available as free and open source software. This release is just the first step toward providing a suite of algorithms that will assist biomedical researchers in analyzing their data to obtain causal insights.  Using simulated data, FGS was able to learn a causal network on data containing 50,000 variables and 1,000 samples in about 15 minutes on a laptop computer. While FGS does not model hidden variables that cause two or more measured variables, an upcoming release of another algorithm will do so.FGS is available as a command line implementation (Causal-cmd) that calls a local Java library or as a Java web application (Causal-web) that runs the analysis at the Pittsburgh Supercomputing Center  the API’s can also be run through R (R-causal) or Python (Py-causal). Additional details and instructions for downloading both these versions of the software are available at http://www.ccd.pitt.edu/wiki/index.php?title=Tools_and_Software.Our goal is to help the biomedical community use causal modeling to gain novel insights and drive innovative research, so we hope to make these tools as usable and useful as possible.  We welcome any and all feedback that you might have, which will help us improve this and future releases. ;
MachineLearning;4cffbm;1459258321.0;/r/MachineLearning/comments/4cffbm/some_great_curated_posts_on_ml_and_big_data/;Some great curated posts on ML and Big data;;
offbeat;4clxfo;1459360517.0;/r/offbeat/comments/4clxfo/a_recent_analysis_of_big_data_by_central_nippon/;A recent analysis of big data by Central Nippon Expressway Co. (NEXCO Central) has revealed that more and more men tend to prefer cubicles over urinals in restrooms;[deleted];
Music;4dgskj;1459868496.0;/r/Music/comments/4dgskj/big_data_dangerous_oliver_remix_electronic/;Big Data - Dangerous (Oliver Remix) [Electronic];;
technology;4egzm0;1460480026.0;/r/technology/comments/4egzm0/using_big_data_to_understand_the_human_condition/;Using Big Data to Understand the Human Condition: The Kavli HUMAN Project;;
technology;4e228r;1460221779.0;/r/technology/comments/4e228r/big_data_iot_solving_the_worlds_water_woes/;Big Data, IoT: Solving the world's water woes;;
sysadminjobs;4dgr1y;1459867935.0;/r/sysadminjobs/comments/4dgr1y/hiring_senior_sre_for_a_big_data_startup_nyc_sf/;[HIRING] Senior SRE for a Big Data startup - NYC / SF Bay / Remote.;Collective[i] is a big data startup looking for a Senior SRE to join our TechOps team. We are looking for someone who is passionate about automation and scalability. The SRE will work on the implementation of configuration management infrastructure, and must have experience with Puppet, open source monitoring solutions such as Nagios, and Linux/Unix environments. You will also get the opportunity to be exposed to the Hadoop environment!We have offices in NYC and the SF Bay area. We are also open to remote work for this role.For more info see the full [job post](https://boards.greenhouse.io/collectivei/jobs/192943);
bigdata;4e3k3z;1460244193.0;/r/bigdata/comments/4e3k3z/big_data_o_que_é/;Big Data, o que é?;;
bigdata;4e3b8a;1460240266.0;/r/bigdata/comments/4e3b8a/does_big_data_analysis_cost_big_bucks/;Does Big Data Analysis Cost Big Bucks?;;
bigdata;4clrfs;1459358411.0;/r/bigdata/comments/4clrfs/recordspeed_data_transmission_could_make_big_data/;Record-speed data transmission could make big data more accessible;[deleted];
DCJobs;4dfa5w;1459838300.0;/r/DCJobs/comments/4dfa5w/hiring_big_data_architect_washington_dc_usa_dice/;[Hiring] Big Data Architect - Washington, DC, USA - Dice;[deleted];
DCJobs;4cnoba;1459384528.0;/r/DCJobs/comments/4cnoba/hiring_big_data_architect_washington_dc_usa_dice/;[Hiring] Big Data Architect - Washington, DC, USA - Dice;[deleted];
finance;4cyb15;1459546889.0;/r/finance/comments/4cyb15/big_data_speaks_steph_curry_is_a_robot_trump_is/;Big Data Speaks: Steph Curry Is A Robot, Trump Is Pushing Investors To Canada, And Hollywood Fuels AI;[deleted];
sysadmin;4egj7i;1460474084.0;/r/sysadmin/comments/4egj7i/data_lakes_closing_the_gap_between_enterprises/;Data Lakes Closing the Gap Between Enterprises and Big Data;;
sysadmin;4dazws;1459775519.0;/r/sysadmin/comments/4dazws/chinese_red_bull_huawei_attracted_to_big_data_and/;Chinese red bull (Huawei) attracted to Big Data and big network streams. Enterprise IT and networking are closely linked?;[deleted];
videos;4el5n3;1460547692.0;/r/videos/comments/4el5n3/the_weekly_big_data_dont_panic_but_youre_being/;The Weekly: Big Data (Don't panic but .. YOU'RE BEING WATCHED.);[deleted];
technology;4egt7t;1460477722.0;/r/technology/comments/4egt7t/your_face_is_big_data/;Your Face is Big Data;;
